<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Linux:高速缓存</title>
    <link href="/2024/05/12/Linux-%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98/"/>
    <url>/2024/05/12/Linux-%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98/</url>
    
    <content type="html"><![CDATA[<h1 id="CPU高速缓存"><a href="#CPU高速缓存" class="headerlink" title="CPU高速缓存"></a>CPU高速缓存</h1><blockquote><p>本篇作为列存模型的前置内容，主要分析L1,L2,L3 Cache的基本原理</p><p>参考资料：</p><ol><li><a href="https://zhuanlan.zhihu.com/p/102293437">Cache的基本原理</a></li><li><a href="https://zhuanlan.zhihu.com/p/107096130">Cache组织方式</a></li><li><a href="https://zhuanlan.zhihu.com/p/108425561">TLB原理</a></li></ol></blockquote><h3 id="1-Cache"><a href="#1-Cache" class="headerlink" title="1. Cache"></a>1. Cache</h3><div style="text-align:center;">    <img src="cpu缓存架构.png" alt="cpu缓存架构.png" width="475" height="257" class="jop-noMdConv"></div><ul><li>现代的CPU都普遍存在L1、L2、L3三层Cache用于缓解CPU和DRAM之间的较大速度差距</li><li>在Cortex-A53架构上，L1 Cache分为单独的instruction cache（ICache）和data cache（DCache），并且为每个CPU私有；一个cluster内的所有CPU共享一个L2 cache，不区分指令和数据；所有cluster之间共享L3 cache，通过总线和主存相连。</li><li>对Cache的访问只能按照某一特定的块进行，其为Cache Line，一般大小为4-128 Byts。Cache和DRAM之间的数据交换也只能遵守Cache Line的大小。</li></ul><p><strong>硬件访问速度</strong></p><table><thead><tr><th align="center">存储器</th><th align="center">介质</th><th align="center">随机访问时延</th></tr></thead><tbody><tr><td align="center">L<sub>1</sub> Cache</td><td align="center">SRAM</td><td align="center">0.5ns</td></tr><tr><td align="center">L<sub>2</sub> Cache</td><td align="center">SRAM</td><td align="center">4ns</td></tr><tr><td align="center">L<sub>3</sub> Cache</td><td align="center">SRAM</td><td align="center">20ns</td></tr><tr><td align="center">Memory</td><td align="center">DRAM</td><td align="center">100ns</td></tr><tr><td align="center">NVM</td><td align="center"></td><td align="center">1us</td></tr><tr><td align="center">Disk</td><td align="center">SSD</td><td align="center">150us</td></tr><tr><td align="center">Disk</td><td align="center">HDD</td><td align="center">10ms</td></tr></tbody></table><h4 id="1-1-映射模式"><a href="#1-1-映射模式" class="headerlink" title="1.1 映射模式"></a>1.1 映射模式</h4><h5 id="直接映射缓存-Direct-mapped-cache"><a href="#直接映射缓存-Direct-mapped-cache" class="headerlink" title="直接映射缓存(Direct mapped cache)"></a>直接映射缓存(Direct mapped cache)</h5><div style="text-align:center;">    <img src="直接映射.webp" alt="直接映射.webp" width="572" height="293" class="jop-noMdConv"></div><ul><li>首先假设Cache Size为64byte，Cache Line为8byte。在这种情况下我们可以算得一共有8个Cache Line，因此需要3bit对Cache Line进行索引。因此对于一个32位内存地址<code>bit&lt;31:0&gt;</code>，<code>bit&lt;2:0&gt;</code>称为offset用于指定Cache Line中的某个具体字节，<code>bit&lt;5:3&gt;</code>称为index用于索引某个Cache Line</li><li>而每个Cache Line都对应着一个<code>tag</code>，用于存放<code>bit&lt;31:6&gt;</code>，每当对一个地址通过index查询到Cache Line之后需要与<code>tag</code>进行对比以确定该Cache Line中确实存放的这个内存地址中的数据。</li></ul><p><strong>优缺点</strong></p><ul><li>硬件设计最为简单，成本最低</li><li>很显然一个内存地址只会被映射到一个固定的Cache Line位置上，如果反复访问的两个列存地址其index指向同一个Cache Line，那么会造成对这一个缓存位置的争抢，从而造成对缓存的反复排出和读入，即使缓存还有大量的空间。这种现象叫做缓存颠簸（cache thrashing）</li></ul><h5 id="两路组相连缓存-Two-way-set-associative-cache"><a href="#两路组相连缓存-Two-way-set-associative-cache" class="headerlink" title="两路组相连缓存(Two-way set associative cache)"></a>两路组相连缓存(Two-way set associative cache)</h5><div style="text-align:center;">    <img src="两路组相连.webp" alt="两路组相连.webp" width="710" height="251" class="jop-noMdConv"></div><ul><li>为了缓解缓存颠簸的问题，我们可以将缓存进行分组（分成多路），我们依然通过index查询到Cache Line，但是我们此时有多路可以选择，因此需要同时比较多路所对应的多个<code>tag</code>，找到真正对应的那个Cache Line</li><li>从某种程度上来说，直接映射缓存是组相连缓存的一种特殊情况，每个组只有一个cache line而已。因此，直接映射缓存也可以称作单路组相连缓存</li></ul><h5 id="全相连缓存-Full-associative-cache"><a href="#全相连缓存-Full-associative-cache" class="headerlink" title="全相连缓存(Full associative cache)"></a>全相连缓存(Full associative cache)</h5><div style="text-align:center;">    <img src="全相连.webp" alt="全相连.webp" width="480" height="272" class="jop-noMdConv"></div><h4 id="1-2-更新策略"><a href="#1-2-更新策略" class="headerlink" title="1.2 更新策略"></a>1.2 更新策略</h4><h5 id="写直通-write-through"><a href="#写直通-write-through" class="headerlink" title="写直通(write through)"></a>写直通(write through)</h5><ul><li>当CPU执行store指令并在cache命中时，我们更新cache中的数据并且更新主存中的数据。<strong>cache和主存的数据始终保持一致</strong>。</li></ul><h5 id="写回-write-back"><a href="#写回-write-back" class="headerlink" title="写回(write back)"></a>写回(write back)</h5><ul><li>当CPU执行store指令并在cache命中时，我们只更新cache中的数据。并且每个cache line中会有一个bit位记录数据是否被修改过，称之为dirty bit，我们将dirty bit置位。</li><li>主存中的数据只会在cache line被替换或者显示的clean操作时更新。因此，主存中的数据可能是未修改的数据，而修改的数据躺在cache中。<strong>cache和主存的数据可能不一致。</strong></li></ul><h4 id="1-3-组织方式"><a href="#1-3-组织方式" class="headerlink" title="1.3 组织方式"></a>1.3 组织方式</h4><ul><li>以上在讲通过内存地址查询缓存时，绕开了虚拟地址(virtual address，VA)和物理地址(physical address，PA)的问题。</li><li>CPU在发出对某个地址的数据访问，这个地址其实是虚拟地址，虚拟地址经过MMU转换成物理地址，最终从这个物理地址读取数据。</li></ul><h5 id="虚拟高速缓存-VIVT"><a href="#虚拟高速缓存-VIVT" class="headerlink" title="虚拟高速缓存(VIVT)"></a>虚拟高速缓存(VIVT)</h5><div style="text-align:center;">    <img src="VIVT.webp" alt="VIVT.webp" width="556" height="287" class="jop-noMdConv"></div><ul><li><code>Virtually Indexed Virtually Tagged</code>：通过虚拟地址形成<code>tag</code>和<code>index</code></li><li>优点是不需要每次读取或者写入操作的时候把虚拟地址经过MMU转换为物理地址，这在一定的程度上提升了访问cache的速度。</li><li>但是很显然同一个虚拟地址在不同的线程中可能表示了不同的物理地址，这导致操作系统面临歧义(ambiguity)和别名(alias)两个问题</li></ul><p><strong>歧义</strong></p><ul><li>指不同物理地址中的数据在cache中具有相同的tag和index，这个问题肯定只发生在不同的进程中</li><li>操作系统的解决方案是在切换进程时，选择flush所有的Cache Line，然后在清空Cache，保证切换后的进程不会错误的命中上一个进程的缓存数据（但是对于那些多核共享的Cache，这种方法似乎依然不能解决问题）</li><li>但是这样会导致切换后的进程刚开始执行的时候，将会由于大量的cache miss导致性能损失</li></ul><p><strong>别名</strong></p><ul><li>指不同的虚拟地址映射相同的物理地址，相同的物理地址会具有不同的tag和index，这种问题发生在共享数据时</li><li>操作系统的解决方案为对这种共享的页面采用nocache映射，直接绕过缓存访问DRAM。</li><li>还可以有另一种解决方案。这种方法只针对直接映射高速缓存，并且使用了写分配机制有效。在建立共享数据映射时，保证每次分配的虚拟地址都索引到相同的cacheline。</li></ul><h5 id="物理高速缓存-PIPT"><a href="#物理高速缓存-PIPT" class="headerlink" title="物理高速缓存(PIPT)"></a>物理高速缓存(PIPT)</h5><div style="text-align:center;">    <img src="PIPT.webp" alt="PIPT.webp" width="544" height="307" class="jop-noMdConv"></div><ul><li><code>Physically Indexed Physically Tagged</code>：通过物理地址形成<code>tag</code>和<code>index</code></li><li>CPU发出的虚拟地址经过MMU转换成物理地址，物理地址发往Cache控制器查找确认是否命中Cache。但是MMU地址转换会影响到整体的性能</li><li>为了加快MMU翻译虚拟地址的速度，硬件上也会加入一块cache，作用是缓存虚拟地址和物理地址的映射关系，这块cache称之为TLB(Translation Lookaside Buffer)</li></ul><h5 id="物理标记的虚拟高速缓存-VIPT"><a href="#物理标记的虚拟高速缓存-VIPT" class="headerlink" title="物理标记的虚拟高速缓存(VIPT)"></a>物理标记的虚拟高速缓存(VIPT)</h5><div style="text-align:center;">    <img src="VIPT.webp" alt="VIPT.webp" width="537" height="305" class="jop-noMdConv"></div><ul><li><code>Virtually Indexed Physically Tagged</code>：物理地址形成<code>tag</code>，虚拟地址形成<code>index</code>。这样做的主要好处在于查index和MMU可以并行完成，从而提升性能。</li><li>首先<code>VIPT</code>不存在歧义。前面在讲<code>tag</code>的时候，我们都是说对于一个内存地址除去用于定位Cache中位置的<code>index</code>和<code>offset</code>之后，剩下的地址位用于<code>tag</code>。但是对于<code>VIPT</code>我们并不遵守这一规则，而是对内存映射的页（<code>page size 32KB --&gt; bit&lt;11:0&gt;</code>）剩下的位<code>bit&lt;32:12&gt;</code>用于<code>tag</code>。因为虚拟地址到物理地址的映射是按照page的单位进行的，因此必然不会出现歧义问题</li><li>其次<code>VIPT</code>可能存在别名。Linux系统中映射最小的单位是页，一页大小是4KB。那么意味着虚拟地址和其映射的物理地址的<code>bit&lt;11:0&gt;</code>是一样的，如果index取的位刚好在这个范围内，就可以保证虚拟地址的<code>index</code>和<code>offset</code>其实和物理地址的一样。换一种说法其实保证Cache Size小于等于Page Size就可以了</li><li>解决方案其实也很简单，当Cache Size大于Page Size是，我们可以使用分路的方案，可以天然的降低index取的最高位，让其适配Page Size所占的位数</li></ul><h4 id="1-4-TLB"><a href="#1-4-TLB" class="headerlink" title="1.4 TLB"></a>1.4 TLB</h4><div style="text-align:center;">    <img src="TLB.png" alt="TLB.png" width="561" height="275" class="jop-noMdConv"></div><ul><li><p>全称<code>translation lookaside buffer</code>，用于缓存MMU进行地址转换的结果。64位系统一般都是3~5级。分别是PGD、PUD、PMD、PTE四级页表。MMU就是根据页表基地址寄存器从PGD页表一路查到PTE，最终找到物理地址(PTE页表中存储物理地址)。</p></li><li><p>TLB采用了和前文讲的Cache相同的缓存构建方式，但是在也存在些许不同之处：1.假设地址映射的页大小为4KB，那么虚拟地址的<code>bit&lt;11:0&gt;</code>和物理地址是完全相同的，因此这部分可以不用缓存；2.<code>index</code>的位数选择则只由需要缓存多少对地址映射决定了；3.通过index找到的不在是Cache Line，而是映射的物理地址<code>bit&lt;47:12&gt;</code></p></li><li><p>TLB本质是通过虚拟地址查找一个结果，其实属于<code>VIVT Cache</code>，因此依然存在别名和歧义问题。但是因为映射的地址并不会发生修改，别名并不会影响正确性。</p></li></ul><p><strong>ASID</strong></p><ul><li>歧义问题则依然存在，解决方案是我们在<code>tag</code>添加了一个用于区分进程空间的ASID (Address Space ID)。ASID和进程ID肯定是不一样的，进程ID取值范围很大。但是ASID一般是8或16 bit。所以只能区分256或65536个进程</li><li>所以我们不可能将进程ID和ASID一一对应，我们必须为每个进程分配一个ASID，进程ID和每个进程的ASID一般是不相等的。当ASID分配完后，flush所有TLB，重新分配ASID。</li></ul><p><strong>non-global</strong></p><ul><li>内核空间和用户空间是分开的，并且内核空间是所有进程共享。既然内核空间是共享的，进程A切换进程B的时候，如果进程B访问的地址位于内核空间，完全可以使用进程A缓存的TLB。但是现在由于ASID不一样，导致TLB miss。</li><li>针对内核空间这种全局共享的映射关系称之为global映射。针对每个进程的映射称之为non-global映射。</li><li>我们在最后一级页表中引入一个bit(non-global (nG) bit)代表是不是global映射。当虚拟地址映射物理地址关系缓存到TLB时，将nG bit也存储下来。当判断是否命中TLB时，当比较tag相等时，再判断是不是global映射，如果是的话，直接判断TLB hit，无需比较ASID。当不是global映射时，最后比较ASID判断是否TLB hit。</li></ul><h3 id="2-一致性"><a href="#2-一致性" class="headerlink" title="2. 一致性"></a>2. 一致性</h3><ul><li>因为缓存的使用，会在很多地方出现一致性问题，比如：<ol><li>DMA可以帮我们在I&#x2F;O和主存之间搬运数据，且不需要CPU参与。高速缓存是CPU和主存之间的数据交互的桥梁。而DMA如果和cache之间没有任何关系的话，可能会出现数据不一致。</li><li>iCache和dCache一致性问题。对于某些self-modifying code，在执行的时候会修改自己的指令。修改指令时将需要修改的指令数据加载到dCache中，修改成新指令并写回dCache。如果旧指令已经缓存在iCache中。那么对于程序执行来说依然会命中iCache。</li></ol></li><li>这些一致性问题都会通过一些简单的硬件或者软件方案保证一致性，并不是我们的重点。我们核心还是关注多核下的缓存一致性。</li></ul><h4 id="2-1-多核缓存一致性"><a href="#2-1-多核缓存一致性" class="headerlink" title="2.1 多核缓存一致性"></a>2.1 多核缓存一致性</h4><ul><li>其实问题非常简单，及每个CPU内都用单独的缓存，当两个线程需要访问同一块内存地址时，如果不对两个CPU的缓存做同步操作，就会造成多个副本的问题</li><li>多核的一致性问题其实是可以通过软件来解决的，但是因为软件方案的性能极差，因而现在的系统都是通过硬件来维护的</li></ul><h5 id="缓存同步要求"><a href="#缓存同步要求" class="headerlink" title="缓存同步要求"></a>缓存同步要求</h5><ul><li>某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为写传播（Wreite Propagation）</li><li>某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为事务的串形化（Transaction Serialization）。这里其实涉及到TSO模型了，在x86的架构下是要求指令执行结果要能够满足全局有序的</li></ul><h5 id="Bus-Snooping-Protocol"><a href="#Bus-Snooping-Protocol" class="headerlink" title="Bus Snooping Protocol"></a>Bus Snooping Protocol</h5><ul><li>总线嗅探（Bus Snooping）的工作机制是，当CPU修改自己私有的Cache时，硬件就会广播通知到总线上其他所有的CPU</li><li>每个CPU来说会有特殊的硬件监听广播事件，并检查是否有相同的数据被缓存在自己的CPU。如果私有Cache已经缓存这个即将修改的数据，那么该私有Cache也需要更新对应的cache line</li><li>这种bus snooping方法简单，但要需要每时每刻监听总线上的一切活动。不管别的CPU私有Cache是否缓存相同的数据，都需要发出一次广播事件。这在一定程度上加重了总线负载，也增加了读写延迟</li></ul><h5 id="MESI-Protocol"><a href="#MESI-Protocol" class="headerlink" title="MESI Protocol"></a>MESI Protocol</h5><ul><li><p>需要说明，MESI协议是在总线嗅探的基础上进行构建的，它的核心思想是去标明每一个Cache Line的状态，然后只在需要通知别的核的情况下才去广播事件。在大部分只需要修改自己的私有内存的情况下就不需要通知别的核，自己对缓存的修改情况了。</p></li><li><p>全称来源于四种状态，分别是：</p><ul><li><code>Modified</code>：已修改，表示Cache Line中的数据已经被更改，但是还没有写进内存中，可以直接进行数据更改不通知其他CPU</li><li><code>Exclusive</code>：独占，和内存中的数据是保持一致的，但仅存储于当前CPU的缓存中，可以修改数据并且切换状态，但是不需要通知其他CPU</li><li><code>Shared</code>：共享，和内存中的数据是保持一致的，被多个CPU的缓存所持有，修改数据时需要通知其他CPU将相同位置的缓存改为失效状态</li><li><code>Invalid</code>：已失效，数据已经失效，不可以读取也不可以修改</li></ul></li></ul><div style="text-align:center;">    <img src="mesi.png" alt="mesi.png" width="520" height="281" class="jop-noMdConv"></div><h5 id="伪共享"><a href="#伪共享" class="headerlink" title="伪共享"></a>伪共享</h5><ul><li>如果我们有两个全局变量<code>global_A</code>和<code>global_B</code>，它们同时被存放在了一个CacheLine的范围内。但这两个变量分别只被<code>task_A</code>和<code>task_B</code>两个进程访问</li><li>尽管这两个变量是完全不共享的，但是它们所存放的Cache Line却需要被共享，从而造成了不必要的缓存同步，从而影响性能。这种现象被称为伪共享(false sharing)</li><li>解决方案也很简单，按照Cache Line进行对齐就可以了，在Linux kernel中存在<code>__cacheline_aligned_in_smp</code>宏定义用于解决false sharing问题</li></ul><h4 id="2-2-atomic实现原理"><a href="#2-2-atomic实现原理" class="headerlink" title="2.2 atomic实现原理"></a>2.2 atomic实现原理</h4><ul><li>问题很简单，本质就是要求对多个变量的多个操作是同时完成的。比如对一个整形执行加一操作，需要先读出数据，再进行加一，最后回写。如果不是一次性完成会存在正确性问题，因此需要原子操作保证其正确性</li></ul><h5 id="Bus-Lock"><a href="#Bus-Lock" class="headerlink" title="Bus Lock"></a>Bus Lock</h5><ul><li>当CPU发出一个原子操作时，可以先锁住Bus（总线）。这样就可以防止其他CPU的内存操作。等原子操作结束，释放Bus</li><li>但是锁住Bus会导致后续无关内存操作都不能继续。实际上，我们只关心我们操作的地址数据</li></ul><h5 id="CacheLine-Lock"><a href="#CacheLine-Lock" class="headerlink" title="CacheLine Lock"></a>CacheLine Lock</h5><ul><li>借助多核Cache一致性协议MESI实现原子操作，Cache line的状态处于Exclusive或者Modified时，可以说明该变量只有当前CPU私有Cache缓存了该数据。所以我们可以直接修改Cache line即可更新数据。并且MESI协议可以帮我们保证互斥</li><li>但这不能保证多步操作期间不被打断，因此我们还需要再添加一个locked标志</li><li>当$CPU_0$试图执行原子递增操作时。$CPU_0$发出”Read Invalidate”消息，其他CPU将原子变量所在的缓存无效，并从Cache返回数据。$CPU_0$将Cache line置成Exclusive状态。然后将该<strong>cache line标记locked</strong>。然后$CPU_0$读取原子变量，修改，最后写入cache line。完成所有操作之后将cache line置位unlocked</li><li>如果$CPU_1$尝试执行一个原子递增操作，$CPU_1$会发送一个”Read Invalidate”消息，$CPU_0$收到消息后，检查对应的cache line的状态是locked，暂时不回复消息（$CPU_1$会一直等待$CPU_0$回复Invalidate Acknowledge消息）。直到cache line变成unlocked</li></ul><h4 id="2-3-spinlock"><a href="#2-3-spinlock" class="headerlink" title="2.3 spinlock"></a>2.3 spinlock</h4><ul><li>Linux kernel中常见的互斥原语，适用于不可睡眠上下文环境访问共享数据的互斥，是一种自旋锁</li><li>看上去似乎通过atomic操作可以简单的实现，但其实经历了较多的优化，而这些复杂的优化是和CPU缓存的一致性协议息息相关的</li></ul><h5 id="wild-spinlock"><a href="#wild-spinlock" class="headerlink" title="wild spinlock"></a>wild spinlock</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">spinlock</span> &#123;<br>        <span class="hljs-type">int</span> locked;<br>&#125;;<br><br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">spin_lock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> spinlock *lock)</span></span><br><span class="hljs-function"></span>&#123;<br>        <span class="hljs-keyword">while</span> (<span class="hljs-built_in">test_and_set</span>(&amp;lock-&gt;locked));<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">spin_unlock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> spinlock *lock)</span></span><br><span class="hljs-function"></span>&#123;<br>        lock-&gt;locked = <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>首先我们需要知道<code>test_and_set</code>是无条件置1操作，并且返回原来的值，这个操作在MESI协议中需要发送invalid消息给其他CPU，然后再修改自己缓存中的值。</li><li>当多个CPU竞争时，因为两边都在反复的执行写操作，这块内存空间需要在多个缓存之间来回颠簸，导致的带宽压力和性能损失。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">spin_lock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> spinlock *lock)</span></span><br><span class="hljs-function"></span>&#123;<br>        <span class="hljs-keyword">while</span> (lock-&gt;locked || <span class="hljs-built_in">test_and_set</span>(&amp;lock-&gt;locked));<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>解决方案也非常简单，我们提前读锁的状态，当处于被锁住的状态时，多个CPU缓存因为只在读该变量，因此一直保持<code>shared</code>状态，避免了缓存颠簸</li><li>但这种方式其实依然存在饥饿的问题，可能某个CPU一直无法获得锁</li></ul><h5 id="ticket-spinlock"><a href="#ticket-spinlock" class="headerlink" title="ticket spinlock"></a>ticket spinlock</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">spinlock</span> &#123;<br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">short</span> owner;<br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">short</span> next;<br>&#125;;<br><br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">spin_lock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> spinlock *lock)</span></span><br><span class="hljs-function"></span>&#123;<br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">short</span> next = <span class="hljs-built_in">xadd</span>(&amp;lock-&gt;next, <span class="hljs-number">1</span>);<br>        <span class="hljs-keyword">while</span> (lock-&gt;owner != next);<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">spin_unlock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> spinlock *lock)</span></span><br><span class="hljs-function"></span>&#123;<br>        lock-&gt;owner++;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>主要问题在于，当我们目前有多个CPU在while循环的等待中时，<code>lock-&gt;owner</code>明显是处于<code>shared</code>状态的。而当持有锁的CPU释放锁的时候会执行<code>lock-&gt;owner++</code>，修改这个值会同时将多个CPU中的缓存置为<code>Invalid</code>；之后这多个CPU又会请求释放锁的CPU获取修改后的缓存</li><li>随着CPU数量的增多，总线带宽压力很大。而且延迟也会随着增长，性能也会逐渐下降。而且$CPU_0$释放锁后，$CPU_1 - CPU_7$也只有一个CPU可以获得锁，理论上没有必要影响其他CPU的缓存，只需要影响接下来应该获取锁的CPU（按照FIFO的顺序）。这说明ticket spinlock不具备可扩展性</li></ul><h5 id="qspinlock"><a href="#qspinlock" class="headerlink" title="qspinlock"></a>qspinlock</h5><ul><li>前面的两种spinlock的根本原因就是每个CPU都spin在共享变量上。所以我们只需要保证每个CPU spin的变量是不同的就可以避免这种情况了。这其实就是MCS锁的实现原理。qspinlock的实现是建立在MCS锁的理论基础上</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">mcs_spinlock</span> &#123;<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">mcs_spinlock</span> *next;<br><span class="hljs-type">int</span> locked; <span class="hljs-comment">/* 1 if lock acquired */</span><br><span class="hljs-type">int</span> count;  <span class="hljs-comment">/* nesting count, see qspinlock.c */</span><br>&#125;;<br><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">mcs_spin_lock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> mcs_spinlock **lock, <span class="hljs-keyword">struct</span> mcs_spinlock *node)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">mcs_spinlock</span> *prev;<br><br><span class="hljs-comment">/* Init node */</span><br>node-&gt;locked = <span class="hljs-number">0</span>;<br>node-&gt;next   = <span class="hljs-literal">NULL</span>;<br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * We rely on the full barrier with global transitivity implied by the</span><br><span class="hljs-comment"> * below xchg() to order the initialization stores above against any</span><br><span class="hljs-comment"> * observation of @node. And to provide the ACQUIRE ordering associated</span><br><span class="hljs-comment"> * with a LOCK primitive.</span><br><span class="hljs-comment"> */</span><br>prev = <span class="hljs-built_in">xchg</span>(lock, node);<br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">likely</span>(prev == <span class="hljs-literal">NULL</span>)) &#123;<br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * Lock acquired, don&#x27;t need to set node-&gt;locked to 1. Threads</span><br><span class="hljs-comment"> * only spin on its own node-&gt;locked value for lock acquisition.</span><br><span class="hljs-comment"> * However, since this thread can immediately acquire the lock</span><br><span class="hljs-comment"> * and does not proceed to spin on its own node-&gt;locked, this</span><br><span class="hljs-comment"> * value won&#x27;t be used. If a debug mode is needed to</span><br><span class="hljs-comment"> * audit lock status, then set node-&gt;locked value here.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">return</span>;<br>&#125;<br><span class="hljs-built_in">WRITE_ONCE</span>(prev-&gt;next, node);<br><br><span class="hljs-comment">/* Wait until the lock holder passes the lock down. */</span><br><span class="hljs-built_in">arch_mcs_spin_lock_contended</span>(&amp;node-&gt;locked);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">mcs_spin_unlock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> mcs_spinlock **lock, <span class="hljs-keyword">struct</span> mcs_spinlock *node)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">mcs_spinlock</span> *next = <span class="hljs-built_in">READ_ONCE</span>(node-&gt;next);<br><br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">likely</span>(!next)) &#123;<br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * Release the lock by setting it to NULL</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">likely</span>(<span class="hljs-built_in">cmpxchg_release</span>(lock, node, <span class="hljs-literal">NULL</span>) == node))<br><span class="hljs-keyword">return</span>;<br><span class="hljs-comment">/* Wait until the next pointer is set */</span><br><span class="hljs-keyword">while</span> (!(next = <span class="hljs-built_in">READ_ONCE</span>(node-&gt;next)))<br><span class="hljs-built_in">cpu_relax</span>();<br>&#125;<br><br><span class="hljs-comment">/* Pass lock to next waiter. */</span><br><span class="hljs-built_in">arch_mcs_spin_unlock_contended</span>(&amp;next-&gt;locked);<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>加锁操作只需要将所属自己CPU的mcs_spinlock结构体加入单链表尾部，然后spin，直到自己的mcs_spinlock的locked成员置1（locked初始值是0）</li><li>解锁操作只需要将解锁的CPU对应的mcs_spinlock结构体的next域的lock成员置1，相当于通知下一个CPU退出循环</li></ul>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>memory model</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>协程库</title>
    <link href="/2024/05/12/%E5%8D%8F%E7%A8%8B%E5%BA%93/"/>
    <url>/2024/05/12/%E5%8D%8F%E7%A8%8B%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h1 id="一、协程"><a href="#一、协程" class="headerlink" title="一、协程"></a>一、协程</h1><h2 id="1-1-基本概念"><a href="#1-1-基本概念" class="headerlink" title="1.1 基本概念"></a>1.1 基本概念</h2><ul><li><p>协程可以理解为一种用户态的轻量级线程，一个线程里跑多个协程。</p></li><li><p>协程分为<strong>对称协程</strong>和<strong>非对称协程</strong>，对称协程就是当协程切换的时候他可以切换到任意其他的协程，比如<code>goroutine</code>；而非对称协程只能切换到调用他的调度器。</p></li><li><p><code>C20</code>以前，<code>c/c++</code>不直接支持协程语义，但有不少开源的协程库， 目前大概有三种实现协程的方式：</p><ul><li>利用<code>glibc</code>的<code>ucontext</code>组件：<a href="https://github.com/cloudwu/coroutine/">coroutine</a></li><li>利用汇编代码来切换上下文：<a href="https://github.com/Tencent/libco">libco</a></li><li>利用C语言的<code>setjmp</code>和<code>longjmp</code>：<a href="https://github.com/sustrik/libmill">libmill</a></li></ul></li><li><p>当然在<code>C20</code>的新特性中在语言级别支持了协程</p></li></ul><h2 id="1-2-解决的问题"><a href="#1-2-解决的问题" class="headerlink" title="1.2 解决的问题"></a>1.2 解决的问题</h2><ul><li>在IO密集型的程序中，CPU等待IO结果往往是非常频繁的事情，如果按照我们常规的思维写处理IO的代码，如：<code>accept --&gt; read --&gt; process --&gt; write</code>。这个流程当中三个地方将会面临CPU的阻塞等待问题（如果使用的是阻塞IO的话），而一台服务器是需要处理成千上万的连接请求的，所以这里的阻塞等待是万万不能接受的。</li><li>最早的解决方案就是开新的线程来处理每一个连接请求，这样即使发生阻塞也是在各自的线程中发生阻塞，而不会影响服务器相应别的请求。但是这样带来的问题就是连接多起来之后需要申请很多的线程资源，许多线程发生阻塞之后也会给系统带来额外的负担。</li><li>接着出现的方案是使用<code>epoll</code>在单个线程内同时监听多个连接，当监听到指定的信号之后再执行相应的处理逻辑。这样通过较少的线程就能处理大量的连接，此方案的性能也非常的优秀。但是这种基于事件的异步处理方案的处理流程是打散，我们不能按照顺序思维写整个处理流程。</li><li>最后协程其实就是为了解决异步处理逻辑混乱的方案，可以用顺序思维流程的代码写出异步处理的代码。</li></ul><h1 id="二、coroutine实现"><a href="#二、coroutine实现" class="headerlink" title="二、coroutine实现"></a>二、<code>coroutine</code>实现</h1><blockquote><p>参考资料：</p><p><a href="https://blog.csdn.net/LMFQYJ/article/details/79211084">云风coroutine源码分析</a></p><p><a href="https://blog.csdn.net/qq910894904/article/details/41911175">ucontext-人人都可以实现的简单协程库</a></p></blockquote><ul><li><code>glibc</code>中提供了<code>ucontext</code>库函数用于操作上下文，基于这组提供的函数可以实现上下文的切换，从而可以实现协程。</li></ul><h2 id="2-1-ucontext"><a href="#2-1-ucontext" class="headerlink" title="2.1 ucontext"></a>2.1 <code>ucontext</code></h2><ul><li>在类<code>System V</code>环境中，头文件<code>&lt;ucontext.h&gt;</code>中定义了一个核心结构体和四个函数用以支持用户级的线程切换。</li><li>核心结构体是<code>ucontext_t</code>，它是保存上下文信息的核心数据结构，基本结构如下：<ul><li><code>uc_link</code>的类型是<code>ucontext_t*</code>，其存储的是当前上下文运行完成之后或者被挂起时，应退出到的位置；</li><li><code>uc_sigmask</code>为该上下文中的阻塞信号集合；</li><li><code>uc_stack</code>为该上下文中使用的栈；</li><li><code>uc_mcontext</code>保存上下文的特定机器表示，包括调用线程的特定寄存器等。</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">ucontext</span> &#123;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">ucontext</span> *uc_link;       <span class="hljs-comment">// 该上下文执行完时要恢复的上下文</span><br>    <span class="hljs-type">sigset_t</span>         uc_sigmask;  <br>    <span class="hljs-type">stack_t</span>          uc_stack;      <span class="hljs-comment">//使用的栈</span><br>    <span class="hljs-type">mcontext_t</span>       uc_mcontext;  <br>    ...  <br>&#125; <span class="hljs-type">ucontext_t</span>;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span><br>  &#123;<br>    <span class="hljs-type">void</span> *ss_sp;<br>    <span class="hljs-type">int</span> ss_flags;<br>    <span class="hljs-type">size_t</span> ss_size;<br>  &#125; <span class="hljs-type">stack_t</span>;<br></code></pre></td></tr></table></figure><ul><li>然后是核心的四个函数：<ul><li><code>getcontext</code>：初始化<code>ucp</code>结构体，将当前的上下文保存到<code>ucp</code>中。</li><li><code>makecontext</code>：修改通过<code>getcontext</code>取得的上下文<code>ucp</code>（这意味着**调用<code>makecontext</code>前必须先调用<code>getcontext</code>**）。然后给该上下文指定一个栈空间<code>ucp-&gt;stack</code>，设置后继的上下文<code>ucp-&gt;uc_link</code>。如果这里设置的要返回的上下文为<code>NULL</code>，则当前线程会直接退出。</li><li><code>setcontext</code>：设置当前的上下文为<code>ucp</code>，这里的<code>ucp</code>应该通过<code>getcontext</code>或者<code>makecontext</code>取得，如果调用成功则不返回。其实很好理解这里的直接设置上下文操作，就是直接将执行流程跳转到<code>ucp</code>，这里也没有去保存当前上下文，所以当前的运行环境一定是直接丢失的，也就不会返回了。当然跳转的上下文中可能设置了后继上下文<code>ucp-&gt;uc_link</code>，如果当前运行完之后会返回到这里记录的后继上下文。</li><li><code>swapcontext</code>：不同于前者直接进行跳转，<code>swapcontext</code>会将当前的上下文信息换出并存储到<code>oucp</code>，而我们可以将要跳转的上下文的后继<code>ucp-&gt;uc_link</code>提前设置成<code>oucp</code>（注意这里是写指针，<code>oucp</code>里面当前保存的上下文其实还不是真正的返回位置），然后在调用<code>swapcontext</code>时第一个参数就填<code>oucp</code>，那就将当前上下文写入到<code>oucp</code>中了，于是在<code>ucp</code>上下文挂起或者退出的时候自然能返回当前调用<code>swapcontext</code>的位置了。</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">getcontext</span><span class="hljs-params">(<span class="hljs-type">ucontext_t</span> *ucp)</span></span>; <span class="hljs-comment">//将当前上下文保存到ucp</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">makecontext</span><span class="hljs-params">(<span class="hljs-type">ucontext_t</span> *ucp, <span class="hljs-type">void</span> (*func)(), <span class="hljs-type">int</span> argc, ...)</span></span>; <span class="hljs-comment">//修改上下文入口函数</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">setcontext</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">ucontext_t</span> *ucp)</span></span>; <span class="hljs-comment">//切换到上下文ucp</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">swapcontext</span><span class="hljs-params">(<span class="hljs-type">ucontext_t</span> *oucp, <span class="hljs-type">ucontext_t</span> *ucp)</span></span>; <span class="hljs-comment">//保存当前上下文到oucp，切换到上下文ucp</span><br></code></pre></td></tr></table></figure><ul><li>上下文的核心其实就是当前寄存器状态（这包含了<code>pc, sp</code>以及各种通用寄存器），以及栈空间（每个线程&#x2F;协程都是需要有单独的栈空间的）。当利用<code>ucontext</code>创建新的上下文的时候是需要我们创建新的栈空间的，而栈的大小设置是件很困难的事情。</li></ul><h2 id="2-2-协程库实现"><a href="#2-2-协程库实现" class="headerlink" title="2.2 协程库实现"></a>2.2 协程库实现</h2><ul><li><code>coroutine</code>是云风在2012年利用<code>ucontext</code>实现的一个非常简单的非对称协程库，其只提供了如下的几个函数接口：</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> COROUTINE_DEAD 0  <span class="hljs-comment">//协程状态</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> COROUTINE_READY 1</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> COROUTINE_RUNNING 2</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> COROUTINE_SUSPEND 3</span><br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">schedule</span>; <span class="hljs-comment">//协程调度器</span><br><br><span class="hljs-function"><span class="hljs-keyword">typedef</span> <span class="hljs-title">void</span> <span class="hljs-params">(*coroutine_func)</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule *, <span class="hljs-type">void</span> *ud)</span></span>; <span class="hljs-comment">//协程执行函数</span><br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">schedule</span> * <span class="hljs-built_in">coroutine_open</span>(<span class="hljs-type">void</span>); <span class="hljs-comment">//创建协程调度器</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">coroutine_close</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule *)</span></span>; <span class="hljs-comment">//关闭协程调度器</span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">coroutine_new</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule *, coroutine_func, <span class="hljs-type">void</span> *ud)</span></span>; <span class="hljs-comment">//用协程调度器创建一个协程</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">coroutine_resume</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule *, <span class="hljs-type">int</span> id)</span></span>; <span class="hljs-comment">//恢复id号协程</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">coroutine_status</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule *, <span class="hljs-type">int</span> id)</span></span>; <span class="hljs-comment">//返回id号协程的状态</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">coroutine_running</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule *)</span></span>; <span class="hljs-comment">//返回正在执行的协程id</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">coroutine_yield</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule *)</span></span>; <span class="hljs-comment">//保存上下文后中断当前协程执行</span><br></code></pre></td></tr></table></figure><ul><li>这是一个非对称的协程库，我们创建的协程在运行完之后会退出到<code>&quot;main&quot;</code>的运行流程中，然后再在主流程中选择需要恢复运行的协程。</li></ul><p><strong><code>schedule</code></strong></p><ul><li>首先是<code>schedule</code>结构体，其实就用于操作协程调度的类：<ul><li><code>stack</code>是公共使用的栈空间，每个运行的协程最终都是在这个公共的栈空间中运行的，所以协程切换的时候会涉及到栈的拷贝，后面会详细说明；</li><li><code>main</code>其实就是用于保存主流程上下文的，便于协程发生切换的时候退出到主流程；</li><li><code>co</code>存储协程的数组，<code>nco, cap</code>记录当前数组的容量和使用情况；</li><li><code>running</code>存储当前正在运行的协程。</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">schedule</span> &#123;<br>    <span class="hljs-type">char</span> stack[STACK_SIZE];<br>    <span class="hljs-type">ucontext_t</span> main;<br>    <span class="hljs-type">int</span> nco;<br>    <span class="hljs-type">int</span> cap;<br>    <span class="hljs-type">int</span> running;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">coroutine</span> **co;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong><code>coroutine</code></strong></p><ul><li>然后是<code>coroutine</code>结构体，用于存储协程的基本信息：<ul><li><code>func</code>是这个协程的函数入口，函数的定义必须符合<code>coroutine_func</code>类型定义，<code>ud</code>是入参；</li><li><code>ctx</code>用于保存当前协程上下文，便于在挂起之后能够恢复到协程挂起的位置继续执行；</li><li><code>stack</code>是在协程发生挂起的时候，暂存当前协程的栈信息的。</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">coroutine</span> &#123;<br>    coroutine_func func;<br>    <span class="hljs-type">void</span> *ud;<br>    <span class="hljs-type">ucontext_t</span> ctx;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">schedule</span> * sch;<br>    <span class="hljs-type">ptrdiff_t</span> cap;<br>    <span class="hljs-type">ptrdiff_t</span> size;<br>    <span class="hljs-type">int</span> status;<br>    <span class="hljs-type">char</span> *stack;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong><code>coroutine_new</code></strong></p><ul><li>功能比较简单，其实就是把一个函数注册成协程，并且返回协程标识符。这里可能遇到<code>co</code>数组空间不足的可能需要扩容。</li></ul><p><strong><code>coroutine_resume</code></strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> </span><br><span class="hljs-function"><span class="hljs-title">coroutine_resume</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule * S, <span class="hljs-type">int</span> id)</span> </span>&#123;<br>    <span class="hljs-built_in">assert</span>(S-&gt;running == <span class="hljs-number">-1</span>);<br>    <span class="hljs-built_in">assert</span>(id &gt;=<span class="hljs-number">0</span> &amp;&amp; id &lt; S-&gt;cap);<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">coroutine</span> *C = S-&gt;co[id];<br>    <span class="hljs-keyword">if</span> (C == <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span>;<br>    <span class="hljs-type">int</span> status = C-&gt;status;<br>    <span class="hljs-keyword">switch</span>(status) &#123;<br>    <span class="hljs-keyword">case</span> COROUTINE_READY:<br>        <span class="hljs-built_in">getcontext</span>(&amp;C-&gt;ctx);<br>        C-&gt;ctx.uc_stack.ss_sp = S-&gt;stack;<br>        C-&gt;ctx.uc_stack.ss_size = STACK_SIZE;<br>        C-&gt;ctx.uc_link = &amp;S-&gt;main;<br>        S-&gt;running = id;<br>        C-&gt;status = COROUTINE_RUNNING;<br>        <span class="hljs-type">uintptr_t</span> ptr = (<span class="hljs-type">uintptr_t</span>)S;<br>        <span class="hljs-built_in">makecontext</span>(&amp;C-&gt;ctx, (<span class="hljs-built_in">void</span> (*)(<span class="hljs-type">void</span>)) mainfunc, <span class="hljs-number">2</span>, (<span class="hljs-type">uint32_t</span>)ptr, (<span class="hljs-type">uint32_t</span>)(ptr&gt;&gt;<span class="hljs-number">32</span>));<br>        <span class="hljs-built_in">swapcontext</span>(&amp;S-&gt;main, &amp;C-&gt;ctx);<br>        <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">case</span> COROUTINE_SUSPEND:<br>        <span class="hljs-built_in">memcpy</span>(S-&gt;stack + STACK_SIZE - C-&gt;size, C-&gt;stack, C-&gt;size);<br>        S-&gt;running = id;<br>        C-&gt;status = COROUTINE_RUNNING;<br>        <span class="hljs-built_in">swapcontext</span>(&amp;S-&gt;main, &amp;C-&gt;ctx);<br>        <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">default</span>:<br>        <span class="hljs-built_in">assert</span>(<span class="hljs-number">0</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>恢复指定协程的运行，这里可能遇到两种情况：一种是该协程第一次运行，走<code>COROUTINE_READY</code>分支；第二种情况是该协程被挂起之后再运行，走<code>COROUTINE_SUSPEND</code>分支。</li><li>首次运行需要我们设置<code>ucontext</code>相关的信息，所以需要调用<code>getcontext</code>并设置栈以及返回位置的上下文，然后通过<code>makecontext</code>设置协程的入口函数为<code>mainfunc</code>。这里并没有直接设置成用户注册的函数，是因为需要额外做一些诸如运行后释放资源的操作，所以这里包了一层函数。最后通过<code>swapcontext</code>切换到协程运行。</li><li>如果是挂起之后的恢复，则需要恢复栈数据，就是把<code>coroutine-&gt;stack</code>中暂存的栈数据复制到<code>schedule-&gt;stack</code>公共栈空间中，然后再通过<code>swapcontext</code>切换到协程运行。</li></ul><p><strong><code>coroutine_yield</code></strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span></span><br><span class="hljs-function"><span class="hljs-title">coroutine_yield</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule * S)</span> </span>&#123;<br>    <span class="hljs-type">int</span> id = S-&gt;running;<br>    <span class="hljs-built_in">assert</span>(id &gt;= <span class="hljs-number">0</span>);<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">coroutine</span> * C = S-&gt;co[id];<br>    <span class="hljs-built_in">assert</span>((<span class="hljs-type">char</span> *)&amp;C &gt; S-&gt;stack);<br>    _save_stack(C,S-&gt;stack + STACK_SIZE);<br>    C-&gt;status = COROUTINE_SUSPEND;<br>    S-&gt;running = <span class="hljs-number">-1</span>;<br>    <span class="hljs-built_in">swapcontext</span>(&amp;C-&gt;ctx , &amp;S-&gt;main);<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>挂起操作是在协程流程中调用的，挂起之前需要暂存当前协程的栈空间数据，这是通过<code>_save_stack</code>函数的实现的。</li><li>然后就是更新状态，并通过<code>swapcontext</code>切换到主流程中。</li><li>简单说一下<code>_save_stack</code>函数，用了一个很巧妙的方法，在函数内部定义了一个局部变量<code>dummy</code>，此时<code>dummy</code>的地址应该是栈顶，而栈底是已知的，这样我们就知道当前协程使用的栈的大小。</li></ul><h1 id="三、libco实现"><a href="#三、libco实现" class="headerlink" title="三、libco实现"></a>三、<code>libco</code>实现</h1><ul><li><code>libco</code>是微信后台大规模使用的<code>c/c++</code>协程库，2013年至今稳定运行在微信后台的数万台机器上。</li><li>通过提供<code>socket</code>族函数的<code>hook</code>，使得后台逻辑服务几乎不用修改逻辑代码就可以完成异步化改造。</li><li>上下文切换采用的汇编实现方案，手动保存当前CPU的寄存器状态。</li></ul><h2 id="3-1-动态链接实现hook"><a href="#3-1-动态链接实现hook" class="headerlink" title="3.1 动态链接实现hook"></a>3.1 动态链接实现<code>hook</code></h2><blockquote><p>参考资料：</p><p><a href="https://blog.csdn.net/MOU_IT/article/details/115050472">libco源码阅读（八）：hook机制</a></p><p><a href="http://kaiyuan.me/2017/05/03/function_wrapper/">动态链接黑魔法: Hook 系统函数</a></p></blockquote><h3 id="3-1-1-why…"><a href="#3-1-1-why…" class="headerlink" title="3.1.1 why…?"></a>3.1.1 why…?</h3><ul><li>对于线程来说，当某些系统调用发生阻塞时会被系统自动挂起并等待特定的信号到来，并且把当前的CPU调度给另外的线程，这个过程对用户是完全无感的。</li><li>但协程是用户态的概念，操作系统并不知道它的存在，如果我们在协程中调用了某个会阻塞的接口，则会直接将当前线程阻塞，并不会讲CPU调度给别的协程。协程系统中想要让渡CPU需要手动调用<code>co_resume</code>或<code>co_yield</code>这样的方法。</li><li>因此我们如果想要在原来的代码中引入协程，肯定是需要做很多<strong>侵入式</strong>改造的，即在原来的业务逻辑中加入很多协程相关的调用。</li><li>而基于动态链接实现的<code>hook</code>方案可以在不更改原代码的基础上修改要调用的函数的逻辑。基于此原理我们可以修改各种系统调用函数（<code>libco</code>主要是修改了<code>socket</code>函数族），从而实现非侵入式的异步化改造。</li></ul><h3 id="3-1-2-hook机制"><a href="#3-1-2-hook机制" class="headerlink" title="3.1.2 hook机制"></a>3.1.2 <code>hook</code>机制</h3><ul><li><p><code>hook</code>机制本质上是一种函数的劫持技术，比如我们通常需要调用<code>malloc</code>函数来进行内存分配，那么能不能我们自己封装一个同名、同入参和同返回值的<code>malloc</code>函数来替代系统的<code>malloc</code>函数，在我们自己封装的<code>malloc</code>函数中实现一些特定的功能，而且也能回调系统的<code>malloc</code>，这就是<code>hook</code>机制。</p></li><li><p>系统提供给我们的<code>dlopen</code>、<code>dlsym</code>族函数可以用来操作动态链接库，比如我们要<code>hook</code>系统调用函数<code>read</code>，我们可以使用<code>dlsym</code>族函数获取<code>hook</code>前函数的地址，这样就可以在自己实现的<code>read</code>中回调原函数，并加上一些额外的逻辑，并且在运行是会调用我们的版本了。</p></li></ul><h3 id="3-1-3-动态链接"><a href="#3-1-3-动态链接" class="headerlink" title="3.1.3 动态链接"></a>3.1.3 动态链接</h3><ul><li>动态链接是指在程序编译时并不会被连接动态库到目标代码中，而是在程序运行是才被载入。不同的应用程序如果调用相同的库，那么在内存里只需要有一份该共享库的实例，规避了空间浪费问题。</li><li>动态库在程序运行是才被载入，也解决了静态库对程序的更新、部署和发布页会带来麻烦。用户只需要更新动态库即可。</li><li>在<code>Linux</code>中动态链接库是<code>.so</code>结尾的文件，本质和我们编译生成的<code>.o</code>文件是类似的，在加载程序或者运行程序发现需要访问动态链接库中的函数实现时，会在所有的库空间中去寻找对应的实现。<strong>而如果同一个函数接口在多个动态库中都被实现过，那么到底调用哪个实现就取决于先查找到谁。</strong></li></ul><h3 id="3-1-4-环境变量LD-PRELOAD"><a href="#3-1-4-环境变量LD-PRELOAD" class="headerlink" title="3.1.4 环境变量LD_PRELOAD"></a>3.1.4 环境变量LD_PRELOAD</h3><ul><li><code>LD_PRELOAD</code>是<code>Linux</code>系统的一个环境变量，它可以影响程序的运行时的链接<code>(Runtime linker)</code>，允许你定义在程序运行前优先加载的动态链接库。</li><li>这个功能主要就是用来有选择性的载入不同动态链接库中的相同函数。通过这个环境变量，我们可以在主程序和其动态链接库的中间加载别的动态链接库，甚至覆盖正常的函数库。一方面，我们可以以此功能来使用自己的或是更好的函数（无需更改别人的源码）；而另一方面，我们也可以向别人的程序注入程序，从而达到特定的目的。</li><li>系统寻找动态库时加载顺序为：<ol><li><code>LD_PRELOAD</code></li><li><code>LD_LIBRARY_PATH</code></li><li><code>/etc/ld.so.cache</code></li><li><code>/lib</code></li><li><code>/usr/lib</code></li></ol></li></ul><h3 id="3-1-5-示例"><a href="#3-1-5-示例" class="headerlink" title="3.1.5 示例"></a>3.1.5 示例</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// hookread.cpp</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;dlfcn.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;unistd.h&gt;</span></span><br> <br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br> <br><span class="hljs-function"><span class="hljs-keyword">typedef</span> <span class="hljs-title">ssize_t</span> <span class="hljs-params">(*<span class="hljs-type">read_pfn_t</span>)</span><span class="hljs-params">(<span class="hljs-type">int</span> fildes, <span class="hljs-type">void</span> *buf, <span class="hljs-type">size_t</span> nbyte)</span></span>;<br> <br><span class="hljs-type">static</span> <span class="hljs-type">read_pfn_t</span> g_sys_read_func = (<span class="hljs-type">read_pfn_t</span>)<span class="hljs-built_in">dlsym</span>(RTLD_NEXT,<span class="hljs-string">&quot;read&quot;</span>);<br> <br><span class="hljs-function"><span class="hljs-type">ssize_t</span> <span class="hljs-title">read</span><span class="hljs-params">( <span class="hljs-type">int</span> fd, <span class="hljs-type">void</span> *buf, <span class="hljs-type">size_t</span> nbyte )</span></span>&#123;<br>    std::cout &lt;&lt; <span class="hljs-string">&quot;进入 hook read\n&quot;</span>;<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">g_sys_read_func</span>(fd, buf, nbyte);<br>&#125;<br> <br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">co_enable_hook_sys</span><span class="hljs-params">()</span></span>&#123;<br>    std::cout &lt;&lt; <span class="hljs-string">&quot;可 hook\n&quot;</span>;<br>&#125;<br> <br><span class="hljs-comment">// main.cpp</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;sys/socket.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;netinet/in.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;arpa/inet.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;unistd.h&gt;</span></span><br> <br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br> <br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>    <span class="hljs-type">int</span> fd = <span class="hljs-built_in">socket</span>(PF_INET, SOCK_STREAM, <span class="hljs-number">0</span>);<br>    <span class="hljs-type">char</span> buffer[<span class="hljs-number">10000</span>];<br>    <br>    <span class="hljs-type">int</span> res = <span class="hljs-built_in">read</span>(fd, buffer ,<span class="hljs-number">10000</span>);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">g++ -o main main.cpp<br>g++ -o hookread.so -fPIC -shared -D_GNU_SOURCE hookread.cpp -ldl<br>LD_PRELOAD=./hookread.so ./main<br></code></pre></td></tr></table></figure><ul><li><p>但是libco并不是这样做的，整个<code>libco</code>中你都看不到<code>LD_PRELOAD</code>，<code>libco</code>使用了一种特殊的方法，即通过在用户代码中包含<code>co_hook_sys_call.cpp</code>中定义的函数，这样也可以做到使用我们自己的库去替换系统的库。</p></li><li><p>实现也很简单，就是单独编译得到<code>hookread.o</code>文件，然后再编译<code>main.cpp</code>： <code>g++ main.cpp -ldl hookread.o</code>。但这种方法需要在用户代码中引入头文件<code>hookread.h</code>。</p></li></ul><h2 id="3-2-函数调用过程"><a href="#3-2-函数调用过程" class="headerlink" title="3.2 函数调用过程"></a>3.2 函数调用过程</h2><blockquote><p>参考资料：</p><p><a href="https://cs.pynote.net/hd/asm/202212111/#x64">学习x86-64寄存器（x64 Register Set）</a></p><p><a href="https://zhuanlan.zhihu.com/p/440016053#112-intel-x64%E5%AF%84%E5%AD%98%E5%99%A8">x86-64寄存器和栈帧</a></p><p><a href="https://blog.csdn.net/MOU_IT/article/details/114791921">libco源码阅读（四）：协程的上下文环境</a></p></blockquote><h3 id="3-2-1-栈帧"><a href="#3-2-1-栈帧" class="headerlink" title="3.2.1 栈帧"></a>3.2.1 栈帧</h3><div style="text-align:center;">    <img src="stack-frame.png" alt="stack-frame.png" width="208" height="240" class="jop-noMdConv"></div><ul><li>首先在Linux程序的虚拟地址空间中，栈段是从高地址向低地址增长的，而堆是从低地址向高地址增长，所以我们的手动申请的栈空间是需要设置成从最高地址开始使用的。</li><li>在<code>x86_64</code>架构的CPU中有两个专门用来管理函数栈帧的寄存器，分别是<code>rbp</code>, <code>rsp</code>。前者是当前栈帧的底部（高地址），后者是当前栈帧的顶部（低地址）。</li><li>栈帧需要完成的主要工作是为局部变量开辟空间，此外还需要处理调用函数的一些相关工作。</li></ul><p><strong>函数调用</strong></p><ul><li>首先说函数调用（<code>caller</code>方的工作），我们需要完成的工作主要包括传递参数以及记录函数跳转之后的返回地址。写入参的过程是以当前的<code>rsp</code>为基地址向高地址写入的，并且参数是从右往左以此写入，所以上图青色部分是<code>param N ... param 1</code>。注意这里是以栈顶往高地址写数据，即存储参数的空间是调用者的栈帧空间，这里是需要提前预留出来的。</li><li>参数写完之后紧接的指令就是<code>call func</code>调用跳转，这条指令除了将<code>rip</code>更换成目标函数入口位置还会同时保存函数调用后的返回位置，这个过程是完全自动完成的设置<code>rip</code>的操作没有体现在汇编代码中。返回地址是紧接着在栈顶位置写入。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs assembly">call foo; 等价于下面的指令<br><br>pushq %rip     ; 保存下一条指令（第41行的代码地址）的地址，用于函数返回继续执行<br>jump foo ; 跳转到函数foo<br></code></pre></td></tr></table></figure><p><strong>函数进入</strong></p><ul><li>进入一个新的函数之后首先需要保存当前寄存器中的数据，方便调用完成之后恢复状态。因为每个函数需要用到的寄存器是不同的，所以要保存那些寄存器根据需要决定。但<code>rbp</code>和<code>rsp</code>是肯定需要更改的，所以进入函数和推出时固定需要保存和恢复<code>rbp</code>与<code>rsp</code>。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs asm">push rbp       ; 函数最开始，保存rbp到stack<br>mov  rbp, rsp  ; 扩展stack之前，保存此值，作为新stack frame的底<br>; ...<br>mov  rsp, rbp  ; 最后恢复<br>pop  rbp  <br></code></pre></td></tr></table></figure><ul><li>然后需要扩展当前函数的栈帧空间，即让<code>rsp</code>减去一个值，局部变量需要用到的空间就分配完成了。</li></ul><p><strong>函数退出</strong></p><ul><li>退出的时候需要注意将之前保存过的寄存器值进行恢复，再恢复<code>rbp</code>和<code>rsp</code>；然后调用<code>ret</code>，会自动根据当前<code>sp</code>地址存储的返回位置进行跳转。此时一个函数的调用就完成了。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs assembly">ret; 等价于下面的指令<br><br>popq %rip ; 恢复指令指针寄存器<br></code></pre></td></tr></table></figure><h3 id="3-2-2-传参优化"><a href="#3-2-2-传参优化" class="headerlink" title="3.2.2 传参优化"></a>3.2.2 传参优化</h3><ul><li>根据前面的描述，当我们在为调用函数设置传入参数的时候是通过栈来存储的，但实际上函数的参数比较少的时候会使用寄存器来完成传参，比如函数只有两个参数<code>func(int* arg1, int* arg2)</code>的时候，会使用<code>rdi</code>存<code>arg1</code>，使用<code>rsi</code>存<code>arg2</code>。</li></ul><h2 id="3-3-关键数据结构"><a href="#3-3-关键数据结构" class="headerlink" title="3.3 关键数据结构"></a>3.3 关键数据结构</h2><h3 id="3-3-1-协程实体"><a href="#3-3-1-协程实体" class="headerlink" title="3.3.1 协程实体"></a>3.3.1 协程实体</h3><ul><li><code>stCoRoutine_t</code>相当于<code>Linux</code>中管理线程&#x2F;进程的<code>task_struct</code>结构体，保存这协程的私有数据和协程切换时的上下文信息。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stCoRoutine_t</span><br>&#123;<br>    stCoRoutineEnv_t *env; <span class="hljs-comment">// 协程的执行环境, 运行在同一个线程上的各协程是共享该结构</span><br>    <span class="hljs-type">pfn_co_routine_t</span> pfn;  <span class="hljs-comment">// 一个函数指针, 指向实际待执行的协程函数 </span><br>    <span class="hljs-type">void</span> *arg;             <span class="hljs-comment">// 函数的参数</span><br>    <span class="hljs-type">coctx_t</span> ctx;           <span class="hljs-comment">// 用于协程切换时保存CPU上下文（context）的,即 esp、ebp、eip 和其他通用寄存器的值</span><br>    <span class="hljs-type">char</span> cStart;           <span class="hljs-comment">// 协程是否执行过resume</span><br>    <span class="hljs-type">char</span> cEnd;             <span class="hljs-comment">// 协程是否执行结束</span><br>    <span class="hljs-type">char</span> cIsMain;          <span class="hljs-comment">// 是否为主协程修改</span><br>    <span class="hljs-type">char</span> cEnableSysHook;   <span class="hljs-comment">// 此协程是否hook库函数，即用自己实现的函数替代库函数</span><br>    <span class="hljs-type">char</span> cIsShareStack;    <span class="hljs-comment">// 是否开启共享栈模式</span><br> <br>    <span class="hljs-type">void</span> *pvEnv;           <span class="hljs-comment">// 保存程序系统环境变量的指针</span><br> <br>    <span class="hljs-comment">//char sRunStack[ 1024 * 128 ];</span><br>    stStackMem_t* stack_mem; <span class="hljs-comment">// 协程运行时的栈内存</span><br> <br>    <span class="hljs-comment">//save satck buffer while confilct on same stack_buffer;</span><br>    <span class="hljs-type">char</span>* stack_sp;         <span class="hljs-comment">// 保存栈顶指针sp</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> save_size; <span class="hljs-comment">// 保存协程的栈的buffer的大小</span><br>    <span class="hljs-type">char</span>* save_buffer;      <span class="hljs-comment">// 使用共享栈模式时，用于保存该协程的在共享栈中的内容</span><br> <br>    stCoSpec_t aSpec[<span class="hljs-number">1024</span>];<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="3-3-2-协程上下文信息"><a href="#3-3-2-协程上下文信息" class="headerlink" title="3.3.2 协程上下文信息"></a>3.3.2 协程上下文信息</h3><ul><li><code>coctx_t</code>保存协程的上下文，实际就是寄存器的值，<code>C/C++</code>都没有函数可以直接接触寄存器，所以操作这个参数的时候需要嵌入一点汇编代码。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">coctx_t</span><br>&#123;<br><span class="hljs-meta">#<span class="hljs-keyword">if</span> defined(__i386__)</span><br>    <span class="hljs-type">void</span> *regs[ <span class="hljs-number">8</span> ];  <span class="hljs-comment">// X86 32位架构下有8个通用寄存器</span><br><span class="hljs-meta">#<span class="hljs-keyword">else</span></span><br>    <span class="hljs-type">void</span> *regs[ <span class="hljs-number">14</span> ]; <span class="hljs-comment">// x86 64位下有16个寄存器，这里保存14个</span><br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>    <span class="hljs-type">size_t</span> ss_size;  <span class="hljs-comment">// 栈的大小</span><br>    <span class="hljs-type">char</span> *ss_sp;     <span class="hljs-comment">// 栈顶指针esp</span><br>    <br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="3-3-3-私有栈和共享栈"><a href="#3-3-3-私有栈和共享栈" class="headerlink" title="3.3.3 私有栈和共享栈"></a>3.3.3 私有栈和共享栈</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stStackMem_t</span><br>&#123;<br>    stCoRoutine_t* ocupy_co; <span class="hljs-comment">// 执行时占用的那个协程实体,也就是这个栈现在是那个协程在用</span><br>    <span class="hljs-type">int</span> stack_size;          <span class="hljs-comment">// 当前栈上未使用的空间</span><br>    <span class="hljs-type">char</span>* stack_bp;          <span class="hljs-comment">// stack_buffer + stack_size</span><br>    <span class="hljs-type">char</span>* stack_buffer;      <span class="hljs-comment">// 栈的起始地址,当然对于主协程来说这是堆上的空间</span><br> <br>&#125;;<br> <br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stShareStack_t</span><br>&#123;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> alloc_idx; <span class="hljs-comment">// stack_array中我们在下一次调用中应该使用的那个共享栈的index</span><br>    <span class="hljs-type">int</span> stack_size;         <span class="hljs-comment">// 共享栈的大小，这里的大小指的是一个stStackMem_t*的大小</span><br>    <span class="hljs-type">int</span> count;              <span class="hljs-comment">// 共享栈的个数，共享栈可以为多个，所以以下为共享栈的数组</span><br>    stStackMem_t** stack_array; <span class="hljs-comment">// 栈的内容，这里是个数组，元素是stStackMem_t*</span><br>&#125;;<br></code></pre></td></tr></table></figure><ul><li><code>stStackMem_t</code>是运行协程私有栈的结构，<code>stShareStack_t</code>则是共享栈的结构。<code>libco</code>有两种协程栈的策略：<ul><li>一种是一个协程分配一个栈，这也是默认的配置，因为默认大小为<code>128KB</code>，如果1024个协程就是<code>128MB</code>，这会带来较大空间的浪费。</li><li>另一种策略为共享栈，即所有协程使用同一个栈，然后每个协程使用一个<code>buffer</code>来保存自己的栈内容，这个<code>buffer</code>大小根据具体的需要进行申请，因此可以节省内存。libco在进行协程切换的时候，先把共享栈的内容复制到要换出的协程实体的结构体buffer中，再把即将换入的协程实体的结构体中的buffer内容复制到共享栈中。这种方法是多个协程共用一个栈，但缺点是在协程切换的时候需要拷贝已使用的栈空间。</li></ul></li></ul><h3 id="3-3-4-线程环境"><a href="#3-3-4-线程环境" class="headerlink" title="3.3.4 线程环境"></a>3.3.4 线程环境</h3><ul><li><code>stCoRoutineEnv_t</code>是一个非常关键的结构，是一个线程内所有协程共享的结构。其中存放了一些协程调度相关的数据，当然叫调度有些勉强，因为<code>libco</code>实现的非对称式协程实际上没有什么调度策略，完全就是协程切换会用到。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stCoRoutineEnv_t</span><br>&#123;<br>    stCoRoutine_t *pCallStack[ <span class="hljs-number">128</span> ]; <span class="hljs-comment">// 协程的调用栈</span><br>    <span class="hljs-type">int</span> iCallStackSize;               <span class="hljs-comment">// 调用栈的栈顶指针</span><br>    stCoEpoll_t *pEpoll;              <span class="hljs-comment">// epoll的一个封装结构</span><br> <br>    <span class="hljs-comment">//for copy stack log lastco and nextco</span><br>    stCoRoutine_t* pending_co;       <span class="hljs-comment">// 目前占用共享栈的协程</span><br>    stCoRoutine_t* ocupy_co;         <span class="hljs-comment">// 与pending在同一个共享栈上的上一个协程</span><br>&#125;;<br></code></pre></td></tr></table></figure><ul><li><code>pCallStack</code> ： 如果将协程看成一种特殊的函数，那么这个 <code>pCallStack</code> 就时保存这些函数的调用链的栈。非对称协程最大特点就是协程间存在明确的调用关系；甚至在有些文献中，启动协程被称作 <code>call</code>，挂起协程叫 <code>return</code>。非对称协程机制下的被调协程只能返回到调用者协程，这种调用关系不能乱，因此必须将调用链保存下来。</li><li><code>pending_co</code>和<code>ocupy_co</code>：对上次切换挂起的协程和嵌套调用的协程栈的拷贝，为了减少共享栈上数据的拷贝。在不使用共享栈模式时 <code>pending_co</code> 和 <code>ocupy_co</code> 都是空指针。（大概就是有的情况下共享栈中上次留下来的数据和现在将要重新写入的是一样的，可以省略恢复过程）</li></ul><h3 id="3-3-5-协程属性"><a href="#3-3-5-协程属性" class="headerlink" title="3.3.5 协程属性"></a>3.3.5 协程属性</h3><ul><li>协程属性的结构体<code>stCoRoutineAttr_t</code>标记了栈的大小和是否使用共享栈。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stCoRoutineAttr_t</span><br>&#123;<br>    <span class="hljs-type">int</span> stack_size;   <span class="hljs-comment">// 协程的私有栈或者共享栈大小</span><br>    stShareStack_t*  share_stack; <span class="hljs-comment">// 指向协程的共享栈</span><br>    <span class="hljs-built_in">stCoRoutineAttr_t</span>()<br>    &#123;<br>        stack_size = <span class="hljs-number">128</span> * <span class="hljs-number">1024</span>;<br>        share_stack = <span class="hljs-literal">NULL</span>;<br>    &#125;<br>&#125;__attribute__ ((packed));<br></code></pre></td></tr></table></figure><h2 id="3-4-协程的基本操作"><a href="#3-4-协程的基本操作" class="headerlink" title="3.4 协程的基本操作"></a>3.4 协程的基本操作</h2><blockquote><p>参考文献：</p><p><a href="https://blog.csdn.net/MOU_IT/article/details/114683197">libco源码阅读（三）：协程的创建和运行</a></p><p><a href="https://blog.csdn.net/MOU_IT/article/details/114791921">libco源码阅读（四）：协程的上下文环境</a></p><p><a href="http://kaiyuan.me/2017/07/10/libco/">libco 分析(上)：协程的实现</a></p></blockquote><ul><li>协程的基本操作不外乎创建、恢复运行、挂起切换，这三个操作分别是由<code>co_create, co_resume, co_yield</code>三个函数完成的。</li></ul><h3 id="3-4-1-协程创建"><a href="#3-4-1-协程创建" class="headerlink" title="3.4.1 协程创建"></a>3.4.1 协程创建</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">co_create</span><span class="hljs-params">(stCoRoutine_t **ppco, <span class="hljs-type">const</span> stCoRoutineAttr_t *attr, <span class="hljs-type">pfn_co_routine_t</span> pfn, <span class="hljs-type">void</span> *arg)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">co_get_curr_thread_env</span>()) <br>    &#123;<br>        <span class="hljs-built_in">co_init_curr_thread_env</span>();<br>    &#125;<br>    stCoRoutine_t *co = <span class="hljs-built_in">co_create_env</span>(<span class="hljs-built_in">co_get_curr_thread_env</span>(), attr, pfn, arg);<br>    *ppco = co;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li><code>ppco</code>：是协程的主体结构，存储着一个协程所有的信息；</li><li><code>attr</code>：其实和线程一样，是我们希望创建的协程的一些属性，不过libco中这个参数简单一点，只是标记了栈的大小和是否使用共享栈，传入为NULL时表示不使用共享栈；</li><li><code>pfn</code>：是我们希望协程执行的函数，当然实际执行的是一个封装后的函数；</li><li><code>arg</code>：是传入函数的参数。</li></ul><p><strong><code>co_get_curr_thread_env</code></strong></p><ul><li>用于获取当前线程绑定的协程环境（这里暗含一个线程下的所有协程都是一起管理的，不会出现两个管理单元）。为了保证每个线程下运行时都能拿到指定的<code>stCoRoutineEnv_t</code>，是使用线程私有化实现的。</li></ul><p><strong><code>co_init_curr_thread_env</code></strong></p><ul><li>如果发现当前还没有设置过<code>stCoRoutineEnv_t</code>，则说明是第一次创建此线程下的协程，这个函数用于初始化线程的环境变量，即初始化<code>stCoRoutineEnv_t</code>这个结构，并且创建一个主协程，主协程是线程环境栈中的第一个协程，该协程不执行任何函数。</li><li>会完成几个关键的任务：初始化<code>stCoRoutineEnv_t</code>；调用<code>co_create_env</code>创建主协程实体；并且将其放入协程调用栈中<code>env-&gt;pCallStack</code>；创建<code>epoll对象</code>（本质上<code>libco</code>还是为网络IO服务的，所以在设计上就是和<code>epoll</code>绑定的）</li></ul><p><strong><code>co_create_env</code></strong></p><ul><li>真正创建<code>stCoRoutine_t</code>对象的函数，主要是初始化对象并且分配私有栈或者公共栈</li></ul><h3 id="3-4-2-协程运行"><a href="#3-4-2-协程运行" class="headerlink" title="3.4.2 协程运行"></a>3.4.2 协程运行</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">co_resume</span><span class="hljs-params">( stCoRoutine_t *co )</span></span><br><span class="hljs-function"></span>&#123;<br>    stCoRoutineEnv_t *env = co-&gt;env;<br> <br>    <span class="hljs-comment">/* 获取线程环境中的栈顶协程实体 */</span><br>    stCoRoutine_t *lpCurrRoutine = env-&gt;pCallStack[ env-&gt;iCallStackSize - <span class="hljs-number">1</span> ];<br>    <br>    <span class="hljs-keyword">if</span>( !co-&gt;cStart ) <span class="hljs-comment">// 如果协程没有执行过resume</span><br>    &#123;<br>        <span class="hljs-built_in">coctx_make</span>( &amp;co-&gt;ctx,(<span class="hljs-type">coctx_pfn_t</span>)CoRoutineFunc,co,<span class="hljs-number">0</span> );<br>        co-&gt;cStart = <span class="hljs-number">1</span>;<br>    &#125;<br>    env-&gt;pCallStack[ env-&gt;iCallStackSize++ ] = co; <span class="hljs-comment">// 把当前协程压入线程环境的栈中</span><br>    <span class="hljs-built_in">co_swap</span>( lpCurrRoutine, co ); <span class="hljs-comment">// 进行两个协程的上下文切换</span><br>&#125;<br></code></pre></td></tr></table></figure><ul><li>大概流程就是从<code>env-&gt;pCallStack</code>调用栈中查找到当前协程，然后把要恢复运行的协程写入到调用栈中，最后调用<code>co_swap</code>完成协程的切换。（如果这个这个协程是第一次运行需要我们通过<code>coctx_make</code>创建上下文）</li></ul><p><strong><code>coctx_make</code></strong></p><ul><li>要理解初始化上下文函数的工作需要结合<code>coctx_swap</code>的工作原理，在<code>libco</code>中实现的协程切换是建立在模仿函数调用和返回上实现的，可以注意<code>coctx_swap</code>的最后一条指令是<code>ret</code>，所以为了在<code>coctx_swap</code>返回时跳转到目标函数位置，只需要提前将目标函数入口地址填到<code>sp</code>指向的位置即可。</li><li>当然除了去设置跳转位置外，还需要设定好栈的位置以及入参等，所以这个函数的本质就是初始化<code>coctx_t</code>，后面调用<code>coctx_swap</code>时会将存储在<code>coctx_t</code>中的数据恢复到寄存器中。</li></ul><p><strong><code>coctx_swap</code></strong></p><ul><li>首先<code>coctx_swap</code>的定义是<code>void coctx_swap(coctx_t*, coctx_t*)</code>，两个入参会被放置<code>rdi</code>（第一个参数）和<code>rsi</code>（第二个参数）</li><li>实际在调用的时候是<code>co_swap( lpCurrRoutine, co )</code>，即<code>rdi</code>存当前协程的<code>ctx</code>，<code>rsi</code>存将要切换到的协程的<code>ctx</code>。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs assembly">coctx_swap:<br>    leaq (%rsp),%rax        ; 将栈指针 %rsp 中存储的地址加载到 %rax 中，注意是寄存器中值的copy<br>    movq %rax, 104(%rdi)    ; regs[13]: rsp<br>    movq %rbx, 96(%rdi)     ; regs[12]: rbx<br>    movq %rcx, 88(%rdi)     ; regs[11]: rcx<br>    movq %rdx, 80(%rdi)     ; regs[10]: rdx<br>    movq 0(%rax), %rax      ; 这一句就是将 %rsp 指向的内存中的返回地址取出并存储到 %rax 中<br>    movq %rax, 72(%rdi)     ; regs[9]: ret<br>    movq %rsi, 64(%rdi)     ; regs[8]: rsi<br>    movq %rdi, 56(%rdi)     ; regs[7]: rdi<br>    movq %rbp, 48(%rdi)     ; regs[6]: rbp<br>    movq %r8, 40(%rdi)      ; regs[5]: r8<br>    movq %r9, 32(%rdi)      ; regs[4]: r9<br>    movq %r12, 24(%rdi)     ; regs[3]: r12<br>    movq %r13, 16(%rdi)     ; regs[2]: r13<br>    movq %r14, 8(%rdi)      ; regs[1]: r14<br>    movq %r15, (%rdi)       ; regs[0]: r15<br>    xorq %rax, %rax         ; 清空 %rax<br><br>    movq 48(%rsi), %rbp     ; 后半部分其实就是将第二个参数coctx中缓存的数据重新加载到寄存器中<br>    movq 104(%rsi), %rsp<br>    movq (%rsi), %r15<br>    movq 8(%rsi), %r14<br>    movq 16(%rsi), %r13<br>    movq 24(%rsi), %r12<br>    movq 32(%rsi), %r9<br>    movq 40(%rsi), %r8<br>    movq 56(%rsi), %rdi<br>    movq 80(%rsi), %rdx<br>    movq 88(%rsi), %rcx<br>    movq 96(%rsi), %rbx<br>    leaq 8(%rsp), %rsp<br>    pushq 72(%rsi)<br><br>    movq 64(%rsi), %rsi<br>    ret<br></code></pre></td></tr></table></figure><ul><li><p>注意<code>x86_64</code>架构的CPU其实是有很多寄存器的，但是这里其实只存储了一部分的寄存器值，这是和寄存器的使用规则有关系：如果寄存器遵循被调用者使用规则，那么被调用的函数内部如果需要使用这些寄存器就需要自己去缓存；如果寄存器遵循调用者使用规则，那么调用方要决定在调用前是否需要提前缓存这部分数据。</p><ol><li><code>%rax</code> 作为函数返回值使用。</li><li><code>%rsp</code> 栈指针寄存器，指向栈顶</li><li><code>%rbp</code> 栈桢指针，指向栈基</li><li><code>%rdi，%rsi，%rdx，%rcx，%r8，%r9</code> 用作函数参数，依次对应第1参数，第2参数……</li><li><code>%rbx，%r12，%r13，%14，%15</code> 用作数据存储，遵循<strong>被调用者使用规则</strong>，简单说就是随便用，调用子函数之前要备份它，以防他被修改</li><li><code>%r10，%r11</code> 用作数据存储，遵循<strong>调用者使用规则</strong>，简单说就是使用之前要先保存原值</li><li><code>%rip</code>: 相当于PC指针指向当前的指令地址，指向下一条要执行的指令</li></ol></li><li><p>所有寄存器中<code>%rax, %r10, %r11</code>是永远不需要被调用函数内部做缓存的，如果需要缓存是在调用函数之前就缓存了；而其他的寄存器如果函数内需要使用，则函数内要自己缓存。</p></li></ul><p><strong><code>co_swap</code></strong></p><ul><li>这个函数是<code>co_resume</code>中直接调用的函数，除了在内部调用<code>coctx_swap</code>之外还需要在切出之前和切回之后完成保存栈和恢复栈两个工作。</li></ul><h3 id="3-4-3-协程挂起"><a href="#3-4-3-协程挂起" class="headerlink" title="3.4.3 协程挂起"></a>3.4.3 协程挂起</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">co_yield_env</span><span class="hljs-params">( stCoRoutineEnv_t *env )</span></span><br><span class="hljs-function"></span>&#123;<br>    <br>    stCoRoutine_t *last = env-&gt;pCallStack[ env-&gt;iCallStackSize - <span class="hljs-number">2</span> ];<br>    stCoRoutine_t *curr = env-&gt;pCallStack[ env-&gt;iCallStackSize - <span class="hljs-number">1</span> ];<br><br>    env-&gt;iCallStackSize--;<br><br>    <span class="hljs-built_in">co_swap</span>( curr, last);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">co_yield_ct</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><br>    <span class="hljs-built_in">co_yield_env</span>( <span class="hljs-built_in">co_get_curr_thread_env</span>() );<br>&#125;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">co_yield</span><span class="hljs-params">( stCoRoutine_t *co )</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-built_in">co_yield_env</span>( co-&gt;env );<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>挂起当前协程，并切换到协程栈中的上一个协程，这里的上一个协程其实是恢复当前要挂起的这个协程的协程，每当执行<code>co_resume</code>这个函数的时候，是会将恢复的协程写入到这个协程栈中的。</li><li>挂起操作会将当前协程从这个协程栈中<code>pop</code>出来。</li><li>这里协程栈的操作涉及到了协程实现方案的问题，前面有提到<code>libco</code>实现的协程是非对称的，即有栈协程。协程之间的调用关系是需要协程栈保存下来的，也就意味着协程挂起进行切换的时候必须恢复到调用方；</li><li>还有一种协程的实现是对称的，即无栈协程。那么所有协程之间是平等的，相互之间可以任意进行切换。</li></ul><h2 id="3-5-协程调度"><a href="#3-5-协程调度" class="headerlink" title="3.5 协程调度"></a>3.5 协程调度</h2><h3 id="3-5-1-协程间调度框架"><a href="#3-5-1-协程间调度框架" class="headerlink" title="3.5.1 协程间调度框架"></a>3.5.1 协程间调度框架</h3><ul><li>协程是构建在用户态的一种机制，所有协程的恢复运行和挂起操作都是需要显示在代码中调用相关函数才能实现的，这一点相较于线程是有很大不同的，同时一个协程如果一直不让出CPU，也不会有时间片机制让别的协程有机会开始执行。</li><li>因此在代码中是需要存在一个调度器来在合适的时候让指定的协程恢复运行的，也就是根据事件触发对应协程的恢复运行，这就是<code>libco</code>这个协程框架的基本调度思路了。</li><li>题外话：因为协程的设计本来就是为了解决网络编程中的问题，所以<code>libco</code>的核心是围绕多路复用<code>epoll</code>以及网络套接字<code>socket</code>来实现的。<code>libco</code>实现了对相关的网络编程接口的<code>hook</code>，在<code>hook</code>函数中添加<code>co_yield</code>以及一些封装，比如将<code>epoll</code>封装成<code>poll</code>来对外提供服务，等等。</li><li><code>libco</code>总共支持三种事件：网络事件、超时事件、同步事件。调用<code>libco</code>为我们提供的特定接口并需要进入等待时会自动注册这些事件，然后将当前协程挂起并等待主协程处理事件以及调度。主协程调度功能是由<code>co_eventloop</code>函数支持的。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">co_eventloop</span><span class="hljs-params">( stCoEpoll_t *ctx,<span class="hljs-type">pfn_co_eventloop_t</span> pfn,<span class="hljs-type">void</span> *arg )</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">for</span>(;;)<br>    &#123;<br>        <span class="hljs-type">int</span> ret = <span class="hljs-built_in">co_epoll_wait</span>( ctx-&gt;iEpollFd,result,stCoEpoll_t::_EPOLL_SIZE, <span class="hljs-number">1</span> );<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>;i&lt;ret;i++)<br>        &#123;<br>            item-&gt;<span class="hljs-built_in">pfnPrepare</span>( item,result-&gt;events[i],active );<br>        &#125;<br><br>        <span class="hljs-built_in">TakeAllTimeout</span>( ctx-&gt;pTimeout,now,timeout );<br><br>        <span class="hljs-built_in">Join</span>&lt;stTimeoutItem_t,stTimeoutItemLink_t&gt;( active,timeout );<br><br>        lp = active-&gt;head;<br>        <span class="hljs-keyword">while</span>( lp )<br>        &#123;<br>            lp-&gt;<span class="hljs-built_in">pfnProcess</span>( lp );<br>            lp = active-&gt;head;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>这里只保留了核心逻辑代码，首先<code>co_eventloop</code>函数是一个无限循环，不断等待新的事件到达，然后根据到达的事件恢复运行对应的协程。<ul><li>第一步是调用<code>co_epoll_wait</code>获取满足条件的网络事件，其实内部就是调用<code>epoll_wait</code>获取指定事件已经到达的<code>socket fd</code>。注意这里设置的超时时间是<code>1 ms</code>，这是利用超时机制实现超时事件的触发。</li><li>第二步是对已经准备好的<code>socket fd</code>调用提前设定的<code>pfnPrepare</code>函数，这个和一些统计工作有关系，不是核心逻辑。</li><li>第三步是通过<code>TakeAllTimeout</code>获得已经超时的事件，这里就是简单对比时间完成的。</li><li>第四步会将超时事件和网络事件两个链表合并，然后依次执行提前注册的回调函数<code>pfnProcess</code>，其实回调函数很简答，就是恢复事件绑定的协程，即内部调用<code>co_resume</code>。</li></ul></li><li>以上就是主要逻辑了，会发现缺失了同步事件的处理，这和同步事件的实现有关系。因为条件变量的触发需要另外一个协程在执行流程中调用<code>co_cond_signal</code>完成。这里会完成将该事件激活并放到<code>pstActiveList</code>中。那么下一次<code>co_eventloop</code>的循环就会一并将该事件处理。</li><li>分析源码后我们便清楚了，<code>libco</code>的调度就是建立在<code>epoll</code>之上的，基于事件的一个模型。因此我们使用<code>libco</code>框架写协程代码的时候是必须在主协程（也就是原线程执行流程）的最后调用<code>co_eventloop</code>函数的。在此之前应该把协程创建好并且先运行一些，否则一个刚创建的协程没有等待任何事件，永远不会被调度到。当然一个协程内部也是可以再创建新的协程的，但也是同样的道理，创建完之后要先运行。</li></ul><h3 id="3-5-2-Timeout事件"><a href="#3-5-2-Timeout事件" class="headerlink" title="3.5.2 Timeout事件"></a>3.5.2 <code>Timeout</code>事件</h3><ul><li><code>co_eventloop</code>的第一个参数是<code>stCoEpoll_t</code>，这就是辅助调度的结构体，所以只有一份。其内部的<code>stTimeout_t</code>存储了所有超时等待事件，是用来查询超时事件的结构。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stCoEpoll_t</span><br>&#123;<br>    <span class="hljs-type">int</span> iEpollFd;<br>    <span class="hljs-type">static</span> <span class="hljs-type">const</span> <span class="hljs-type">int</span> _EPOLL_SIZE = <span class="hljs-number">1024</span> * <span class="hljs-number">10</span>;<br><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">stTimeout_t</span> *pTimeout;<br><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">stTimeoutItemLink_t</span> *pstTimeoutList;<br><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">stTimeoutItemLink_t</span> *pstActiveList;<br><br>    co_epoll_res *result; <br><br>&#125;;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stTimeoutItemLink_t</span><br>&#123;<br>    stTimeoutItem_t *head;<br>    stTimeoutItem_t *tail;<br>&#125;;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stTimeout_t</span><br>&#123;<br>    stTimeoutItemLink_t *pItems;<span class="hljs-comment">// 链表头的数组（有多个链表，然后以数组形式存储了所有的链表头）</span><br>    <span class="hljs-type">int</span> iItemSize;<span class="hljs-comment">// 数组大小</span><br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> ullStart;<span class="hljs-comment">// 记录时间</span><br>    <span class="hljs-type">long</span> <span class="hljs-type">long</span> llStartIdx;<span class="hljs-comment">// 记录时间所对应的数组中的位置</span><br>&#125;;<br></code></pre></td></tr></table></figure><ul><li>具体存储超时事件的结构体是<code>stTimeoutItem_t</code>，这是一个双向链表的节点，较为关键的是<code>void *pArg</code>，以及两个回调函数。前者其实<code>stCoRoutine_t*</code>，我们要在回调函数中恢复对应协程运行需要从这里拿到协程。</li><li>回调函数是核心，当<code>co_eventloop</code>拿到已触发的事件了后续该做的事（一般就是恢复对应协程运行）都定义在回调函数中。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stTimeoutItem_t</span><br>&#123;<br><br>    <span class="hljs-keyword">enum</span><br>    &#123;<br>        eMaxTimeout = <span class="hljs-number">40</span> * <span class="hljs-number">1000</span> <span class="hljs-comment">//40s</span><br>    &#125;;<br>    stTimeoutItem_t *pPrev;<br>    stTimeoutItem_t *pNext;<br>    stTimeoutItemLink_t *pLink;<br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> ullExpireTime;<br><br>    OnPreparePfn_t pfnPrepare;<span class="hljs-comment">// 预处理回调函数，在epoll_loop中被调用，只有epoll_wait触发的事件会调用这个回调函数，超时和同步事件都不会调用</span><br>    OnProcessPfn_t pfnProcess;<span class="hljs-comment">// 正式的回调函数，在epoll_loop中被调用</span><br><br>    <span class="hljs-type">void</span> *pArg; <span class="hljs-comment">// routine 指向协程实体</span><br>    <span class="hljs-type">bool</span> bTimeout;<br>&#125;;<br></code></pre></td></tr></table></figure><ul><li>提一下<code>TakeAllTimeout</code>函数，其实就是更新<code>stTimeout_t</code>中的时间记录，然后把已经超时的<code>stTimeoutItem_t</code>取出来。另外将其添加到<code>pstTimeoutList</code>中，等待后面统一处理。</li><li>还有注册超时事件的<code>AddTimeout</code>函数，就是把<code>stTimeoutItem_t</code>添加到 到期时间 对应的链表中。</li></ul><h3 id="3-5-3-Poll事件"><a href="#3-5-3-Poll事件" class="headerlink" title="3.5.3 Poll事件"></a>3.5.3 <code>Poll</code>事件</h3><ul><li><code>libco</code>对网络编程需要用到的接口都做了相应的<code>hook</code>，关键接口主要有三类：<code>read, write, poll</code>，读写都是对一个<code>socket fd</code>的操作，所以一个事件对应一个协程，用<code>stPollItem_t</code>表示：</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stPollItem_t</span> : <span class="hljs-keyword">public</span> stTimeoutItem_t<br>&#123;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">pollfd</span> *pSelf;<br>    stPoll_t *pPoll;<br><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">epoll_event</span> stEvent;<br>&#125;;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stPoll_t</span> : <span class="hljs-keyword">public</span> stTimeoutItem_t <br>&#123;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">pollfd</span> *fds;<br>    <span class="hljs-type">nfds_t</span> nfds; <span class="hljs-comment">// typedef unsigned long int nfds_t;</span><br>    stPollItem_t *pPollItems;<br>    <span class="hljs-type">int</span> iAllEventDetach;<br>    <span class="hljs-type">int</span> iEpollFd;<br>    <span class="hljs-type">int</span> iRaiseCnt;<br>&#125;;<br></code></pre></td></tr></table></figure><ul><li>因为网络事件往往是存在超时时间的，网络事件一般是丢到<code>epoll</code>中内核自己维护，但是超时机制需要我们自己来管理。所以网络事件必须同时也是超时事件，被丢到<code>stTimeout_t</code>中管理。所以<code>stPollItem_t</code>是继承实现的，一些别的变量是处理<code>poll</code>到<code>epoll</code>转换的。（小纠正：其实<code>stPollItem_t</code>是不会被当作超时任务丢到<code>stTimeout_t</code>中的，真正丢进去的是<code>stPoll_t</code>，但这里依然选择继承的原因是能用上回调函数等变量）</li><li>还存在一种接口是对<code>poll</code>的处理，这个接口是需要同时等待多个网络事件，但是这多个网络事件和在一起等待一个超时事件。所以用了<code>stPoll_t</code>存储这一组<code>stPollItem_t</code>（数组<code>pPollItems[nfds]</code>），同时本身又继承<code>stTimeoutItem_t</code>，于是可以被当作是一个超时事件丢到<code>stTimeout_t</code>中管理。</li><li><code>poll</code>还有一个特点是，当任意一个事件触发之后，同一批等待的所有事件都应该退出，这一点和<code>epoll</code>的实现是不同的。而<code>stPollItem_t</code>中注册的<code>pfnPrepare</code>预处理函数就是解决这个问题的，当一个<code>stPollItem_t</code>事件到达之后，需要将注册的<code>stPoll_t</code>超时任务删除。</li><li>关于网络事件的注册，<code>libco</code>库的实现方案是统一使用<code>hook</code>后的<code>poll</code>函数完成注册。这样可以尽量做到用户代码的无侵入性。所有读写接口的<code>hook</code>内部也是先调用<code>poll</code>等到事件到达之后开始真正执行。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">co_poll_inner</span><span class="hljs-params">( stCoEpoll_t *ctx,<span class="hljs-keyword">struct</span> pollfd fds[], <span class="hljs-type">nfds_t</span> nfds, <span class="hljs-type">int</span> timeout, <span class="hljs-type">poll_pfn_t</span> pollfunc)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-comment">//1.struct change</span><br>    stPoll_t&amp; arg = *((stPoll_t*)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(stPoll_t)));<br>    <br>    <span class="hljs-comment">//2. add epoll</span><br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">nfds_t</span> i=<span class="hljs-number">0</span>;i&lt;nfds;i++)<br>    &#123;<br>        <span class="hljs-type">int</span> ret = <span class="hljs-built_in">co_epoll_ctl</span>( epfd,EPOLL_CTL_ADD, fds[i].fd, &amp;ev );<br>    &#125;<br><br>    <span class="hljs-comment">//3.add timeout</span><br>    <span class="hljs-type">int</span> ret = <span class="hljs-built_in">AddTimeout</span>( ctx-&gt;pTimeout,&amp;arg,now );<br>    <span class="hljs-type">int</span> iRaiseCnt = <span class="hljs-number">0</span>;<br>    <br>    <span class="hljs-built_in">co_yield_env</span>( <span class="hljs-built_in">co_get_curr_thread_env</span>() );<br><br>    <span class="hljs-comment">//4.clear epoll status and memory</span><br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">nfds_t</span> i = <span class="hljs-number">0</span>;i &lt; nfds;i++)<br>    &#123;<br>        <span class="hljs-type">int</span> fd = fds[i].fd;<br>        <span class="hljs-built_in">co_epoll_ctl</span>( epfd,EPOLL_CTL_DEL,fd,&amp;arg.pPollItems[i].stEvent );<br>    &#125;<br>    <span class="hljs-keyword">return</span> iRaiseCnt;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li><code>poll</code>函数内部核心是<code>co_poll_inner</code>，其完成三个主要步骤：<ul><li>首先创建<code>stPoll_t</code>对象，并填充对应参数；</li><li>然后把入参的<code>fds</code>依次添加到<code>epoll</code>中；</li><li>接着根据超时时间，将<code>stPoll_t</code>添加到超时事件中，并让出CPU等待事件触发之后回来；</li><li>最后在等到事件到达恢复运行之后，需要将这些<code>fds</code>从<code>epoll</code>中删除，本质上是为了契合<code>poll</code>接口的定义。</li></ul></li></ul><h3 id="3-5-4-Cond事件"><a href="#3-5-4-Cond事件" class="headerlink" title="3.5.4 Cond事件"></a>3.5.4 <code>Cond</code>事件</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stCoCondItem_t</span> <br>&#123;<br>    stCoCondItem_t *pPrev;<br>    stCoCondItem_t *pNext;<br>    stCoCond_t *pLink;<br><br>    stTimeoutItem_t timeout;<br>&#125;;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stCoCond_t</span><br>&#123;<br>    stCoCondItem_t *head;<br>    stCoCondItem_t *tail;<br>&#125;;<br></code></pre></td></tr></table></figure><ul><li>其实实现很简单，对同一个条件变量<code>stCoCond_t</code>的等待<code>co_cond_timedwait</code>会创建一个<code>stCoCondItem_t</code>并插入到等待链表中。可以注意到这里<code>stTimeoutItem_t</code>是作为成员变量出现的，而不是和之前的<code>stPollItem_t</code>保持一致采用继承的方法。显然同步事件是后来添加的新功能😆</li><li><code>co_cond_signal</code>或者<code>co_cond_broadcast</code>触发等待条件变量的协程，就是把<code>stTimeoutItem_t</code>取出来，并添加到<code>pstActiveList</code>当中，注意这里是用的尾插法<code>AddTail</code>，所以在本轮<code>co_eventloop</code>调度中是可以被调度运行到的。（但我不明白为啥不就地恢复运行，而一定要让<code>co_eventloop</code>去调度。或许是有公平性问题，先来的事件应该先运行？）</li></ul>]]></content>
    
    
    <categories>
      
      <category>插件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>协程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RocksDB:事务管理</title>
    <link href="/2024/05/12/RocksDB-%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86/"/>
    <url>/2024/05/12/RocksDB-%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="一、隔离性（Isolation）"><a href="#一、隔离性（Isolation）" class="headerlink" title="一、隔离性（Isolation）"></a>一、隔离性（Isolation）</h1><h2 id="1-1-隔离所导致的问题"><a href="#1-1-隔离所导致的问题" class="headerlink" title="1.1 隔离所导致的问题"></a>1.1 隔离所导致的问题</h2><p><strong>脏读</strong></p><ul><li>读取到了没有提交的数据，如果之前的事务回滚了，就读到了脏数据</li><li>注意这里的重点是：读取到了<strong>没有提交</strong>的事务的数据</li></ul><p><strong>不可重复读</strong></p><ul><li>一个事务对同一共享数据读取了两次，发现前后两次的数据不一致</li><li>不可重复读主要是针对<code>update</code>操作的描述，即表中的字段值发生了改变</li></ul><p><strong>幻读</strong></p><ul><li>一个事务内读取到了别的事务插入的数据，导致前后读取不一致</li><li>幻读主要用于描述的<code>insert</code> <code>delete</code>这样的操作所造成的影响，即前后两次查询获得的数据量不同</li></ul><h2 id="1-2-事务的隔离级别"><a href="#1-2-事务的隔离级别" class="headerlink" title="1.2 事务的隔离级别"></a>1.2 事务的隔离级别</h2><ul><li>不同的事务隔离级别可以在不同程度上解决在并发执行事务时的问题</li></ul><table><thead><tr><th>隔离级别</th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>未提交读</td><td>✔️</td><td>✔️</td><td>✔️</td></tr><tr><td>提交读</td><td>❌</td><td>✔️</td><td>✔️</td></tr><tr><td>可重复读</td><td>❌</td><td>❌</td><td>✔️</td></tr><tr><td>可串行化</td><td>❌</td><td>❌</td><td>❌</td></tr></tbody></table><h1 id="二、事务实现的基本框架"><a href="#二、事务实现的基本框架" class="headerlink" title="二、事务实现的基本框架"></a>二、事务实现的基本框架</h1><h2 id="2-1-MVCC"><a href="#2-1-MVCC" class="headerlink" title="2.1 MVCC"></a>2.1 MVCC</h2><h3 id="2-1-1-传统并发方案"><a href="#2-1-1-传统并发方案" class="headerlink" title="2.1.1 传统并发方案"></a>2.1.1 传统并发方案</h3><ul><li>以前没有使用多版本控制的时候，在同一个事务中的读取操作是需要加读锁的，而不同的隔离级别就包含着不同的上锁和释放锁策略：<ul><li>未提交读，我们只需要对事务中当前的读写操作进行加锁，单条操作完成之后立刻释放对应的锁；</li><li>提交读，我需要在此基础上对写操作加的写锁进行保留，直到事务完成时进行释放，从而保证了事务中间的修改状态不会被别的事务读取到；</li><li>可重复读，我们就需要延长读锁的释放时间了直到事务结束了，这样可以保证同一个事务的多次读取中间不会出现别的事务修改数据；</li><li>解决幻读问题需要更进一步的间隙锁的支持，本质来说是加大了锁的范围。</li></ul></li></ul><h3 id="2-1-2-MVCC的优势"><a href="#2-1-2-MVCC的优势" class="headerlink" title="2.1.2 MVCC的优势"></a>2.1.2 MVCC的优势</h3><ul><li>需要注意上面讲的加锁策略是对读事务和写事务都适用的，读操作依然需要进行加锁，而MVCC解决的问题就是对于只有读操作的事务可以不再需要加锁。</li><li>MVCC带来了一个非常重要的性质，就是版本快照。通过这项技术的支持我们可以在事务中进行读取操作的时候，设定一个版本号，那么一切的读取操作都是基于这个版本号进行读取的。因此在前面章节所讨论的隔离级别所带来的三种问题其实就都不存在了，一个快照版本所包含的内容永远是不变的。</li><li>但是MVCC其实仅仅解决了读事务的问题，对于写事务（往往既包含读操作又包含写操作）依然是需要进行加锁操作的，而且和传统的加锁模式是相同的。</li></ul><h3 id="2-1-3-MVCC下的并发"><a href="#2-1-3-MVCC下的并发" class="headerlink" title="2.1.3 MVCC下的并发"></a>2.1.3 MVCC下的并发</h3><ul><li>但是MySQL为了更好的性能做了一些实现上的调整，使得用户可以根据需要来进行加锁的操作。首先在MySQL的事务中，所有的普通select操作都是基于版本快照的无锁读操作，当一个事务中的第一条普通select开始时会获取到一个快照，之后当前事务内的所有普通查询都会基于这个快照返回查询结果。如果这期间发生rollback，快照将会清零。</li><li>但是一条insert、delete、update操作的语句是不能在快照的基础上完成的，必须在最新版本的基础上去完成增删改的操作，因此这部分的操作依然会存在加锁。</li><li>我们重新回到前文中提到的三种并发下的问题：脏读、不可重复读、幻读，其描述都是说在一个事务中的两次读操作产生了不同的结果（我们已知这在MVCC下不可能）。但是数据库的很多写入数据是需要基于原来的状态进行变更的，比如经典的银行转账问题。需要先读出数据库中的余额，减去一定金额，再将结果写回数据库。这个过程其实是需要我们保证在写入的时候原数据中的那个金额和我们先前读出的金额保持一致的。而这才是真正内涵的需要两次读操作结果相同，这个例子对应的是可重复读这个隔离级别。</li><li>这样的写事务流程需要根据原数据库中的一些基本状态来完成修改，insert、delete、update是必须在最新版本上进行操作的。但其实，读出的原始状态也是应该保证为最新版本的，为了区分普通的select操作，MySQL提供了两种查询中上锁的机制：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span><span class="hljs-operator">*</span><span class="hljs-operator">*</span> <span class="hljs-keyword">for</span> <span class="hljs-keyword">update</span>;<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span><span class="hljs-operator">*</span><span class="hljs-operator">*</span> lock <span class="hljs-keyword">in</span> share mode;<br></code></pre></td></tr></table></figure><ul><li>前者适用于要对读出的行进行修改，例如转账的事务，因此会加互斥锁。</li><li>后者适用于读这一段数据，但是是用这个结果修改别的地方，因此是加共享锁。</li></ul><h3 id="2-1-4-MVCC的隔离级别"><a href="#2-1-4-MVCC的隔离级别" class="headerlink" title="2.1.4 MVCC的隔离级别"></a>2.1.4 MVCC的隔离级别</h3><ul><li>在多版本机制的支持下，可以轻松的避免脏读、不可重复读、幻读这些问题，但我们的隔离级别是对数据的返回结果存在明确规定的，不能在任何隔离级别下都对读事务采用最高等级的隔离机制</li><li>MVCC由于其实现原理，只支持read committed和repeatable read隔离等级，在读事务下实现两种隔离机制的返回其实也很简单，（猜测是）RC下每条select都开启新的快照，RR下一个事务下的select共用一个快照</li></ul><h2 id="2-2-RocksDB的实现方法"><a href="#2-2-RocksDB的实现方法" class="headerlink" title="2.2 RocksDB的实现方法"></a>2.2 RocksDB的实现方法</h2><h3 id="2-2-1-Read-Uncommitted"><a href="#2-2-1-Read-Uncommitted" class="headerlink" title="2.2.1 Read Uncommitted"></a>2.2.1 Read Uncommitted</h3><ul><li>这个其实很简单，使用没有事务API就可以实现了，任何操作都会直接被写入到数据库中，并可以被所有别的进程查询到</li></ul><h3 id="2-2-2-Read-Committed"><a href="#2-2-2-Read-Committed" class="headerlink" title="2.2.2 Read Committed"></a>2.2.2 Read Committed</h3><ul><li>通过Rocksdb内部WriteBatch实现的，针对不同事务Rocksdb会为其分配对应的WriteBatch，由WriteBatch来处理具体的写入。</li><li>同时针对同一个事务的读操作，会优先从当前事务的WriteBatch中读，来保证能够读到当前写操作之前未提交的更新。提交的时候则依次写入WAL和memtable之中，保证ACID的原子性和一致性。</li><li>那么只要读操作全部都基于最新的版本进行读取就是RC隔离机制下的行为了。</li></ul><p><strong>WBWI(write batch with index) &amp; WB(write batch)</strong></p><ul><li>Put这样的更新接口被调用后会组织成一个WriteBatch 数据结构，将多个更新操作合并成一个请求，从而能够进行原子提交。整体是一个string-buf，将一个一个KV请求拼接进去。因此WB也就是提供了一个存放当前事务写入数据的内存块。</li><li>WBWI用于支持事务功能，其在WriteBatch 基本结构的基础上构造了一个skiplist，用来提供事务操作过程中的 read-your-write 以及 savepoint&#x2F;rollback 等这样的基本功能。</li><li>当前事务内，后续的 txn-&gt;Get 就能够有效得读到之前写入但是还没有提交的请求。</li></ul><div style="text-align:center;">    <img src="WBWI.png" alt="WBWI.png" width="550" height="224" class="jop-noMdConv"></div><ul><li><p>txn-&gt;SetSavePoint 函数会将当前 WriteBatchWithIndex 中的信息保存到一个 <code>std::stack&lt;SavePoint, autovector&lt;SavePoint&gt;&gt; stack</code>中。当前事务经过若干操作之后，后续的 txn-&gt;RollbackToSavePoint() 会进行弹栈，并将之前保存的状态信息更新到现在的WBWI 之中，从而达到事务的回滚的目的。</p></li><li><p>SetSavePoint 和 RollbackToSavePoint 函数的逻辑分别在：<code>WriteBatch::SetSavePoint()</code> ,<code>WriteBatch::RollbackToSavePoint()</code></p></li><li><p>因为WBWI 是在BeginTransaction 的时候构造的，所以每一个事务会有一个自己独立的WBWI，其内部的数据结构不需要考虑同步问题。</p></li></ul><h3 id="2-2-3-Repeatable-Read"><a href="#2-2-3-Repeatable-Read" class="headerlink" title="2.2.3 Repeatable Read"></a>2.2.3 Repeatable Read</h3><ul><li>其实在SQL指定标准之前，可重复读是用<strong>快照隔离</strong>来描述的，通用的关系型数据库都使用MVCC机制来进行多版本管理，多版本的访问也就是通过快照来进行的。</li><li>Rocksdb这里的实现是通过为每一个写入的key-value请求添加一个LSN(Log Sequence Number)，最初是0，每次写入+1，达到全局递增的目的。同时当实现快照隔离时，通过Snapshot设置其与一个LSN绑定，则该snapshot能够访问到小于等于当前LSN的KV数据，而大于该LSN的KV是不可见的。</li><li>注意如果只是普通的Get接口，则是根据我们设定的snapshot或者内部自动产生的snapshot来进行查询；但是要是用GetForUpdate这样的接口，我们是需要根据当前的最新状态来执行修改的，这时返回的是最新版本的值，并且会对查询的KV在后台进行加锁。</li></ul><p><strong>SetSnapshot</strong></p><ul><li>Rocksdb对于加锁的时机是在需要读写某个key之前才加锁，这样的方式可以满足绝大多数的事务隔离场景，当然在有些极端场景下，用户希望在事务一开始就对所有接下来需要读写key加锁，直到事务结束后再释放。这个该如何实现呢？并且无法在事务一开始就知道接下来要读写哪些key，所以无法提前对它们加锁。</li><li>Rocksdb通过SetSnapshot来间接解决，BeginTransaction后，用户可以立刻调用SetSnapshot，这样该事务会记录当前DB的最新Sequence，然后再接下来事务的每一次Put操作时，会检查DB中该key的最新Sequence是否大于事务之前记录的Sequence，如果大于，则证明事务外部有对该key做了写操作，那么事务对应的Put则会返回失败。</li><li>这里查询该key的最新版本是从version系统中取一个local_version ，直接暴力遍历这个version 中的 mem&#x2F;imm,imm-list&#x2F;sst ，拿到当前冲突key 一个最新的seq即可。（这里感觉会要较大的性能开销，因为可能涉及到磁盘IO，当然在RocksDB的内部，会去判断一下我们在事务开始设置的snapshot的LSN是否依然完全在内存中，如果还没有被刷到SST中，那我们在查询时就会只查到imm为止）</li><li>因此Rocksdb采用相对乐观的处理方式，通过对Snapshot来取代提前对所有需要的key加锁，不过这样的处理方式可能会造成事务最终失败（事务外部修改某个key后会导致接下来事务内部修改失败）。</li></ul><h2 id="2-3-SnapShot"><a href="#2-3-SnapShot" class="headerlink" title="2.3 SnapShot"></a>2.3 SnapShot</h2><ul><li>snapshot可以有多个，它的创建和删除是通过操作一个全局的双向链表来进行，天然得根据创建的时间来进行排序SetSnapShot()函数创建一个快照。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SnapshotImpl</span> : <span class="hljs-keyword">public</span> Snapshot &#123;<br> <span class="hljs-keyword">public</span>:<br>  <span class="hljs-comment">//lsn number</span><br>  SequenceNumber number_;  <br>  ......<br>  SnapshotImpl* prev_;<br>  SnapshotImpl* next_;<br>  SnapshotList* list_;                 <span class="hljs-comment">// 链表头指针</span><br>  <span class="hljs-type">int64_t</span> unix_time_; <span class="hljs-comment">//时间戳</span><br>  <span class="hljs-comment">// 用于写冲突的检查</span><br>  <span class="hljs-type">bool</span> is_write_conflict_boundary_;<br>&#125;;<br></code></pre></td></tr></table></figure><ul><li>当前系统中存在的快照会影响compaction时，是否保留某些之前版本的KV，这个后面补充</li></ul><h2 id="2-4-PessimisticTransaction"><a href="#2-4-PessimisticTransaction" class="headerlink" title="2.4 PessimisticTransaction"></a>2.4 PessimisticTransaction</h2><ul><li>使用 TransactionDB 进行事务操作，默认是 PessimisticTransactionDB，每次事务更新操作都会进行加锁，会去检测是否和其他事务有冲突。即 txn1 更新一个key1时会对当前key加锁，事务txn2 在 txn1 提交前尝试更新这个key1 则会失败。</li><li>事务对Key的加锁逻辑是：<code>PessimisticTransaction::TryLock --&gt; PessimisticTransactionDB::TryLock --&gt; PointLockManager::TryLock</code></li><li>比较老的版本 ，最后key 的加锁过程入口是 <code>TransactionLockMgr::TryLock</code>，这里重构成了 <code>LockManager::TryLock</code>，然后两种锁实现了<code>LockManager</code>接口，第三节详细介绍。死锁检测的机制也在第三节介绍。</li></ul><h2 id="2-5-OptimisticTransaction"><a href="#2-5-OptimisticTransaction" class="headerlink" title="2.5 OptimisticTransaction"></a>2.5 OptimisticTransaction</h2><ul><li><p>在乐观事务下，不同事务之间的冲突检测不会在每次更新操作时候进行检测，而是在事务提交的时候进行。</p></li><li><p>在PessimisticTransaction下检测的方法其实就是加锁，而采用OptimisticTransaction的方案是在我们提交的时候进行检测，所以我们需要把事务过程中所有需要加的锁都记录下来。对于一般的点锁，那就是记录key值，如果是范围锁就是记录加锁的范围。</p></li><li><p>需要注意虽然OptimisticTransaction不需要在执行过程中加锁，但是我们应该把他当作是普通的事物流程，其Put、GetForUpdate这些函数内部依然是有TryLock函数的，只是TryLock内部行为变成了将要更新的 key的信息添加到 <code>LockTracker</code> 中。</p></li></ul><p><strong>总结</strong></p><ul><li>悲观事务 和 乐观事务主要就是冲突检测的位置不同，所以悲观事务 在事务冲突概率较高的场景下能够保证提前发现冲突而更早的触发冲突事务的回滚。在冲突概率不高的情况下，悲观事务每一个更新（Put,Delete,Merge,GetForUpdate）都会做冲突检测，会引入较多的竞争开销，从而降低性能，所以冲突概率不高的场景可以尝试乐观事务DB。</li></ul><h1 id="三、锁"><a href="#三、锁" class="headerlink" title="三、锁"></a>三、锁</h1><ul><li>RocksDB中共支持两种锁，分别是点锁<code>PointLockManager</code>和范围锁<code>RangeTreeLockManager</code>。点锁是原生支持的，可以在项目中找到完整的项目代码；范围锁是直接使用了TokuDB中的KV存储引擎<a href="https://github.com/percona/PerconaFT">PerconaFT</a>中的范围锁实现，进行接口封装之后进行使用的</li><li>两者都继承自<code>LockManager</code>，其为C++的虚类，提供了一个通用的锁管理接口，用于在多线程&#x2F;多进程环境下管理对数据的并发访问</li><li>需要注意，范围锁也是能够提供点锁能力的，并且当我选择提供范围锁能力的时候必须选择使用<code>RangeTreeLockManager</code>，两种锁同时使用是不能保证互斥的</li></ul><h2 id="3-1-PointLock"><a href="#3-1-PointLock" class="headerlink" title="3.1 PointLock"></a>3.1 PointLock</h2><ul><li>在以前的实现版本中，因为只支持<code>PointLock</code>，这里不是通过继承<code>LockManager</code>实现的，而是使用<code>TransactionLockMgr</code>完成加锁的操作</li><li>但是后来因为支持了<code>RangeLock</code>，不得已将这里设计成接口的方式，方便两种锁都可以使用，点锁的实现类为<code>PointLockManager</code></li></ul><h3 id="3-1-1-条件变量"><a href="#3-1-1-条件变量" class="headerlink" title="3.1.1 条件变量"></a>3.1.1 条件变量</h3><ul><li>这里需要先提一个问题，多个线程在竞争同一个互斥资源的时候是使用互斥锁来实现互斥访问的，同时<code>Mutex</code>其实顺带完成了排队的工作，当一个线程释放锁时会自然触发一个在该锁上等待的线程恢复运行</li><li>但是如果现在这个互斥的资源更加复杂，不能使用一个简单的互斥锁来实现互斥访问和排队的操作，并且在某些情况需要我们需要唤醒在这个资源上阻塞的线程，那么应该使用什么实现呢？</li><li>这时需要使用条件变量来完成同步操作，<code>C++</code>中提供了两种接口，分别是<code>std::condition_variable</code>和<code>pthread_cond_t</code>，目前查到的区别是<code>pthread_cond_t</code>需要我们在<code>wait</code>之前手动加锁，而<code>std::condition_variable</code>在<code>wait</code>接口中自动完成加锁操作（个人感觉<code>std::condition_variable</code>是对<code>pthread_cond_t</code>的封装，本质上是相同的功能实现）</li><li>在条件变量的帮助下，我们可以让线程对某一个条件进行等待，并形成等待队列，从而可以在未来满足条件的时候唤醒之前等待的线程</li></ul><h3 id="3-1-2-整体结构"><a href="#3-1-2-整体结构" class="headerlink" title="3.1.2 整体结构"></a>3.1.2 整体结构</h3><div style="text-align:center;">    <img src="LockMaps.png" alt="LockMaps.png" width="509" height="240" class="jop-noMdConv"></div><ul><li>整体结构从实现类<code>PointLockManager</code>开始，这里包含了最关键的成员对象<code>LockMaps</code>（其实是<code>UnorderedMap&lt;uint32_t, std::shared_ptr&lt;LockMap&gt;&gt;</code>），每次需要进行加锁时，我们通过<code>ColumnFamilyId</code>查找对应列簇下的<code>LockMap</code>（这里有使用线程私有存储进行优化，在别的章节解释了）</li><li>然后<code>LockMap</code>内部是<code>LockMapStripe</code>的数组，这其实可以认为是哈希桶，每当我们需要对一个<code>key</code>进行加锁时，是通过哈希函数将<code>key</code>映射到其中一个<code>桶(LockMapStripe)</code>中，然后对这个桶进行加锁操作</li><li>注意，这里并不是说对每个桶进行加锁之后，就完成对这个<code>key</code>的上锁操作了，这样是有可能造成某些<code>key</code>同时被锁上而造成意外的死锁的。同时这样的上锁机制粒度显然是非常粗的，不利于高并发的场景</li><li>当对桶上锁完成之后，我们要做的是将上锁的key写入到<code>LockMapStripe</code>中的<code>UnorderedMap&lt;std::string, LockInfo&gt;</code>中，然后释放桶锁，这时才是完成了对某个<code>key</code>的上锁操作。下次有线程对某个key进行上锁时，需要查找<code>UnorderedMap</code>中是否已经存在这个<code>key</code>了。这样在共享<code>mutex</code>的情况下对所有未知可能的<code>key</code>都能进行上锁操作了</li><li>但是这里有一个问题，如果上锁时发现已经被上锁了，我们需要先释放桶的锁，然后等待那个key被释放，即从<code>UnorderedMap</code>中被删除。这里需要用到条件变量来进行等待，对桶中的<code>CondVar</code>进行等待，当某个桶发生释放key的操作时，需要唤醒所有等待的线程</li></ul><h2 id="3-2-RangeLock"><a href="#3-2-RangeLock" class="headerlink" title="3.2 RangeLock"></a>3.2 RangeLock</h2><ul><li>RocksDB一开始并没有支持范围锁，因此在Read Repeatable模式下并不能避免幻读的情况，后来是在直接使用了TokuDB的存储引擎<a href="https://github.com/percona/PerconaFT">PerconaFT</a>的范围锁实现</li><li>PerconaFT提供的locktree是使用二叉树的形式来组织整个锁结构的。需要注意当我们选择支持范围锁时，就不能同时使用PointLock，点锁也需要在RangeLock中完成。因为在真实的负载下点锁和范围锁显然是共存的，并且两者之间是需要实现互斥的</li></ul><h3 id="3-2-1-基本结构"><a href="#3-2-1-基本结构" class="headerlink" title="3.2.1 基本结构"></a>3.2.1 基本结构</h3><p><strong><code>treenode</code>:</strong></p><ul><li>主要包括四个关键部分：<ul><li><code>mutex</code>，并发操作二叉树时保证正确性</li><li><code>keyrange</code>，当前这个<code>node</code>所表示的键范围，左右都是闭区间，当左右值相等时表示<code>pointlock</code></li><li><code>m_txnid</code>和<code>m_owners</code>，表示占用当前这个锁的事务ID；当有多个事务同时持有这个范围的度锁时，<code>m_txnid</code>为一个特殊值，持有共享锁的事务ID集合在<code>m_owners</code>中</li><li><code>m_left_child</code>和<code>m_right_child</code>，构建二叉树的指针</li></ul></li></ul><p><strong><code>concurrent_tree</code>:</strong></p><ul><li>成员变量只有一个根节点<code>treenode m_root</code>，内部类<code>locked_keyrange</code>封装了实现并发访问二叉树的细节。所以<code>concurrent_tree</code>类没有太多东西</li></ul><p><strong><code>locktree</code>:</strong></p><ul><li>局部变量比较多，核心部分是：<ul><li><code>m_dict_id</code>，表示当前这个<code>locktree</code>属于哪一个字典，其实就是属于哪一个<code>ColumnFamily</code></li><li><code>m_rangetree</code>，这个就是<code>concurrent_tree</code>的指针</li><li><code>m_lock_request_info</code>，这是一个很关键的成员变量，其中保存了对当前这个<code>locktree</code>申请锁，但是没有成功的请求，和<code>request</code>的排队有重要关系</li></ul></li></ul><p><strong><code>locktree_manager</code>:</strong></p><ul><li>这个类是管理多个<code>ColumnFamily</code>的，和<code>PointLockManager</code>其实是相同的设计，内部使用<code>Order Maintenance Tree (OMT)</code>管理多个<code>locktree</code></li><li>此外RocksDB在外面还包了一层<code>RangeTreeLockManager</code>，并且在这里实现了和<code>PointLockManager</code>相同的线程局部优化</li></ul><p><strong><code>lt_lock_request_info</code>:</strong></p><ul><li>前面已经提到了核心是保存请求锁暂时失败的<code>request</code>，除此之外当有锁发生释放的时候还需要基于这个结构体唤醒<code>request</code>来重试加锁，因此主要包括三个部分：<ul><li><code>omt&lt;lock_request *&gt; pending_lock_requests</code>，对所有暂时失败请求的缓存</li><li><code>toku_external_mutex_t mutex</code>，操作当前这个结构体的内容需要加锁保证正确性</li><li><code>toku_mutex_t retry_mutex</code>和<code>toku_cond_t retry_cv</code>，管理重试加锁操作的锁和条件变量，当多个锁发生释放时，每次锁的释放都会触发剩余等待request进行重试，但是同一时间只能有一个线程在遍历<code>pending_lock_requests</code>进行重试，所以这里需要进行精细的控制</li></ul></li></ul><p><strong><code>locked_keyrange</code>:</strong></p><ul><li>这个类是定义在<code>concurrent_tree</code>内部的，用来在并发状态下完成查找、插入、删除节点的工作</li><li>并发控制的方式其实比较简单，和<code>B+tree</code>在并发控制时使用的加锁解锁策略是相同的，就是交错释放二叉树链条上的两把锁</li><li>需要注意这里提到的加锁是指在并发访问二叉树的节点时的控制手段，和<code>rangelock</code>是没有关系的，范围锁的实现其实是每一个存储在二叉树中的节点，只要某个节点存在就表示对该范围加锁</li><li>内部总共有三个成员变量：<ul><li><code>concurrent_tree *m_tree</code></li><li><code>keyrange m_range</code>，期望锁住的键范围，需要注意这个值来源于进行加锁操作的<code>locked_keyrange::acquire</code>函数的传入参数，即这个是用户希望加锁的范围</li><li><code>treenode *m_subtree</code>，在查找流程结束时（即经过<code>prepare</code>和<code>acquire</code>两个函数），这个变量存储的是最深的存在范围覆盖的节点；如果没有范围覆盖的节点，会一直往下查找到一个<code>nullptr</code>的指针，这时存的是持有这个<code>nullptr</code>指针的节点（很重要的一点，<code>locked_keyrange</code>这时只持有<code>m_subtree</code>节点的锁）</li></ul></li><li>二叉树还是一个平衡的树，在各种操作中间穿插着各种调整树结构平衡的操作，这部分不是重点没有细看</li></ul><p><strong><code>lock_request</code>:</strong></p><ul><li>真正实现向<code>rangelock</code>加锁的类，较为核心的成员变量为：<ul><li><code>m_left_key</code>和<code>m_right_key</code>，范围的左右边界</li><li><code>locktree *m_lt</code>，实施加锁的二叉树，就是<code>ColumnFamily</code>对应的<code>locktree</code></li><li><code>lt_lock_request_info *m_info</code>，对应<code>locktree</code>内部的，本质来说不用重新存一份，可以通过前面的<code>m_lt</code>访问到</li><li><code>toku_external_cond_t m_wait_cond</code>，这个条件变量比较关键，当无法完成加锁而需要进行等待时，是在这个条件变量上进行等待。同时前面有提到过，当一个<code>rangelock</code>释放之后会遍历<code>requests</code>进行重试加锁，如果重试成功时需要唤醒这个条件变量</li></ul></li></ul><h3 id="3-2-2-代码逻辑"><a href="#3-2-2-代码逻辑" class="headerlink" title="3.2.2 代码逻辑"></a>3.2.2 代码逻辑</h3><p><strong>加锁 <code>RangeTreeLockManager::TryLock</code></strong></p><ul><li>首先创建<code>request</code>，并设置初始值</li><li>接着是调用<code>request.start()</code>，这一步是进行加锁的关键步骤，会尝试在<code>locktree</code>中添加新节点来完成加锁<ul><li>这里会有比较多的调用栈，最后是进入到<code>locktree::acquire_lock</code>，然后创建一个<code>locked_keyrange lkr</code>并调用<code>prepare</code>方法获得根节点的锁</li><li>然后将<code>lkr</code>传入<code>acquire_lock_consolidated</code>函数，通过<code>acquire</code>方法查找目标子树（这个方法的细节在上一小节有提到）</li><li>找到目标子树之后，通过<code>iterate_and_get_overlapping_row_locks()</code>去收集与申请加锁范围存在<code>overlap</code>的节点，注意这里在写锁和读锁的操作上发生了分歧。如果是要加写锁，不可能会存在可以共享的节点；如果是加读锁，有一种情况可以简单完成加锁操作，即当我们找到一个节点的范围和请求的range完全相匹配，并且已经持有的是读锁时，我们可以简单的将当前请求的<code>txnid</code>添加到那个节点中就算完成加锁了。（存在任何差别都不能以这样共享的方式完成加锁操作，所以真正能实现共享锁的情况很少）</li><li>上面收集到存在<code>overlap</code>的节点之后，通过<code>determine_conflicting_txnids()</code>检查存在冲突的节点，其实就是检查这些已经被上锁的节点是否本来就是被当前这个事务所持有的，如果全部<code>overlap</code>节点都是的话需要我们将这些范围进行合并，算是一个小优化减少<code>locktree</code>的规模</li><li>如果是存在加锁冲突的，这时会把当前<code>request</code>的状态设置为<code>DB_LOCK_NOTGRANTED</code>，表示存在互斥需要等待</li><li>然后退回到<code>request.start()</code>，如果当前<code>request</code>的状态为<code>DB_LOCK_NOTGRANTED</code>需要我们将其<strong>添加到<code>lt_lock_request_info</code>中</strong></li></ul></li><li>然后是调用<code>request.wait()</code>，这里是当上一步进行加锁发现存在冲突而失败时，通过<code>request.m_wait_cond</code>来完成等待操作；如果上一步成功加锁了，这个函数会快速经过<ul><li>进入函数之后先对<code>m_info-&gt;mutex</code>加锁，然后会有一次重新进行加锁的尝试，如果加锁成功了就可以不用去等待条件变量了，并且直接成功返回（这里的<code>retry</code>非常重要，单独开小节讲）</li><li>然后就是进入一个<code>while</code>循环中，等待<code>request</code>中的条件变量，等待超时唤醒，或者被别的线程唤醒</li></ul></li></ul><p><strong>为什么在<code>request.wait()</code>需要<code>retry</code></strong></p><ul><li>我们想象一个情况，现在A线程已经对<code>range[1,2]</code>加锁，B线程对相同的范围加锁时必然会冲突，然后将<code>request</code>添加到<code>lt_lock_request_info</code>中，并且开始等待条件变量。</li><li>但是如果在B线程加锁失败和将<code>request</code>添加到<code>lt_lock_request_info</code>的期间，A线程释放了<code>range[1,2]</code>。从后面的释放锁流程我们知道，每次调用<code>UnLock</code>的最后一步是<code>retry</code>所有等待的<code>request</code>。那么A并不会帮助B的<code>request</code>成功申请到锁了，此时这个<code>request</code>还不存在于<code>lt_lock_request_info</code>中，但是B会依然开始等待条件变量，并且不会再有线程能够唤醒这个条件变量，B只能等待超时唤醒</li><li>解决的方法就是重试，我们需要注意代码中关于<code>m_info</code>的操作都需要在<code>m_info-&gt;mutex</code>的锁定下执行。B将<code>request</code>添加到<code>lt_lock_request_info</code>需要加锁，在<code>request.wait</code>中，每次先获得<code>m_info-&gt;mutex</code>之后，进行一次<code>retry</code>，然后再等待条件变量，条件变量的<code>wait</code>语句会释放持有的<code>m_info-&gt;mutex</code>。同样A在<code>UnLock</code>的最后一步<code>retry</code>所有等待的<code>request</code>时，也需要先获得<code>m_info-&gt;mutex</code></li><li>那么A如果是在B将<code>request</code>添加到<code>lt_lock_request_info</code>之前先retry了所有的，B的<code>retry</code>会成功完成加锁；如果A的retry在B的之后，那么A需要等待B等待条件变量，并且释放<code>m_info-&gt;mutex</code>之后，再执行<code>retry_all_lock_requests_info</code>，这时会正常唤醒B</li></ul><p><strong>解锁 <code>RangeTreeLockManager::UnLock</code></strong></p><ul><li>有两种支持方式，一种是直接提告诉要解锁哪一个键范围，这种方式比较符合<code>locktree</code>的实现，可以直接调用对应的接口；还有一种在数据库中比较常用，即当一个事务完成时，我们直接释放和这个事务相关的所有锁，这种和<code>locktree</code>的设计是不匹配的，需要我们单独去保存事物加的所有锁，然后一次性释放，RocksDB实现了一个<code>LockTracker</code>去支持这种功能</li><li>首先是从<code>locktree</code>中释放锁的函数<code>locktree::release_locks</code>，其实就是将所有当初加锁插入的节点全部删除掉，所以只需要保证二叉树的并发控制就可以了。需要注意我们在加锁阶段有个优化是将存在<code>overlap</code>但是不冲突的节点进行合并，但是我们记录的加锁范围还是最初没有合并的样子。</li><li>所以最后在删除节点的时候我们可能发现某些节点的边界是不能和记录值完全对应的，这里代码的处理是只要存在<code>overlap</code>就直接删除这个节点。这会带来两个问题：1. 有的节点删除会发现当前范围的节点不存在；2. 我们将后加锁的某些范围释放之后，前面的一些加锁范围可能就自然释放了，因此我们在使用锁的时候必须遵守事务进行加锁的规范，不能中途释放锁</li><li>然后是重试当前等待的<code>request</code>的函数<code>lock_request::retry_all_lock_requests</code>，首先每一次执行全部重试都是非常繁琐的过程，需要对<code>lt_lock_request_info</code>中的每一个请求都进行重试看看能不能加锁成功，并且只有加锁成功之后才对<code>request</code>中的条件变量进行唤醒。重试意味着查询整个二叉树，是需要不断进行加锁和释放锁操作的，性能会较大程度被影响。</li><li>每一次释放某个事务的锁都会触发整体的重试操作，为了减少重试带来的性能影响，有一个简单的机制来保证，和<code>retry_cv</code>与<code>retry_mutex</code>相关。大概功能就是当目前有很多<code>retry</code>在排队时，我执行一次重试就可以了，因为释放的锁都已经反映到<code>locktree</code>上了，执行一次全部的重试就包含到了所有情况</li><li>然后就是依次重试所有<code>request</code>了，那些成功加锁的会被通过条件变量唤醒，注意一点在<code>PointLock</code>中当发生释放锁操作时是唤醒所有的等待线程自己去竞争重试加锁，而在<code>RangeLock</code>的实现中是通过释放锁的线程去重试的，这是否会较大影响事务的执行尾延迟呢？</li></ul><h3 id="3-2-3-STO优化"><a href="#3-2-3-STO优化" class="headerlink" title="3.2.3 STO优化"></a>3.2.3 STO优化</h3><ul><li>这是对范围锁的一个优化，大概思路是说当目前只有一个事务在申请锁，并不存在多个事务在竞争时，我们直接通过一个缓存保留所有的加锁操作，而不将加锁添加到<code>locktree</code>中。</li><li>当释放锁的时候直接释放缓存即可，大大减少锁处理的时间。但是这只对不存在多事务并行发生的条件下使用</li></ul><h2 id="3-3-Tracker"><a href="#3-3-Tracker" class="headerlink" title="3.3 Tracker"></a>3.3 Tracker</h2><div style="text-align:center;">    <img src="tracker.png" alt="tracker.png" width="678" height="229" class="jop-noMdConv"></div><ul><li>上图是LockTracker中用于管理跟踪的加锁信息的局部变量<code>TrackedKeys tracked_keys_</code>的结构示意图，其实就是两层HashMap，第一层是通过ColumnFamilyData索引，第二层通过key索引，最后找到<code>TrackedKeyInfo</code>，其包含加锁的key的各种信息（这里其实只说了PointLock下的Tracker，在RangeLock下是会不一样的）</li><li>在commit时，冲突检测的主要函数入口是 OptimisticTransaction::CheckTransactionForConflicts()，它会进一步调用 TransactionUtil::CheckKeysForConflicts() 执行冲突检测</li><li>要检测的其实就是每个 Key 在 db 中有没有比当前事务开始的 sequence 号之后更新的写入存在。最笨的办法就是把每个 Key 读一次 db，获得它最近的 sequence 号，与事务的 sequence 号做比较。如果 db 中的 sequence 号更大，事务冲突了。</li><li>简单优化一下就只需要判断近期的数据就可以了，而最近期的数据就是 MemTable，所以做近期的冲突检测，只需要读 MemTable 的数据就足够了，不需要执行 IO。不过事务的开始时间如果比 MemTable 中最老的 Key 还早，就无法判断了，这时 rocksdb 的处理也比较暴力，就直接说这个事务过期了，需要重试。</li><li>在检测的实现上RocksDB是通过<code>WriteWithCallback</code>在写入WriteBatch时通过调用OptimisticTransactionCallback实现，所有的检查逻辑都在回掉函数里面，提供了两种 OCC (optimistic concurrent control)策略: <code>kValidateParallel</code> 和 <code>kValidateSerial</code><ul><li><code>OptimisticTransaction::CommitWithSerialValidate</code>正常进行检查，但是比较慢</li><li><code>OptimisticTransaction::CommitWithParallelValidate</code>后来的优化</li></ul></li><li>Tracker机制也会影响到compaction，当我们需要将delete操作和原有KV数据进行合并时，要考虑将曾经出现过的KV直接删除是否会影响到现有Tracker的信息校验。</li></ul><h2 id="3-4-Deadlock"><a href="#3-4-Deadlock" class="headerlink" title="3.4 Deadlock"></a>3.4 Deadlock</h2><ul><li>采用PessimisticTransaction方式执行事务时，加锁顺序完全是由用户来决定的，因此存在很大的可能出现死锁问题。RocksDB通过记录事务间的等待关系来判定是否存在环，从而判定是否有死锁存在</li><li>死锁检测的核心是想要在一个 <strong>有向无环图</strong> 中检测有没有wait_circle，rocksdb的死锁检测就是拿着当前事务前面尝试获取锁时得到的一个<strong>wait_ids 数组</strong>和已有的wait-circle来构建一个 有向无环图，在这个有向无环图中按照前面用户配置的depth进行wait-circle的检测。</li><li>死锁检测入口是在<code>PointLockManager::IncrementWaiters</code>里面，通过前面对当前 txn 构造好的<code>wait_ids</code>数组构造 <code>wait_txn_map_</code> 和 <code>rev_wait_txn_map_</code> 两个 HashMap。<ul><li><code>HashMap&lt;TransactionID, int&gt; rev_wait_txn_map_</code> 用来保存活跃事务和该事务在被多少个事务所等待</li><li><code>HashMap&lt;TransactionID, TrackedTrxInfo&gt; wait_txn_map_</code> 用来保存整个活跃事务视图，用于广度优先遍历。保存的内容是 当前事务等待哪些事务</li></ul></li><li>接下来就是经典的广度优先遍历的实现了，通过提前resize 好的两个vector queue_values 和 queue_parents ，resize的大小是前面说的 deadlock_detect_depth。 queue_values 保存层序，即每一层的所有节点；queue_parents 用来记录当前层的父节点的下标，方便后面在发现死锁环之后进行死锁路径的回溯。</li><li>结束的条件是：<ul><li>在 deadlock_detect_depth 这个检测深度下如果没有发现 当前事务id 和 已有活跃事务依赖图 中不会有相等的情况，则认为不会死锁，返回未发现死锁。</li><li>如果发现有相等的，也就是在依赖图 下找到了环的存在，则通过 queue_parents 数组来回溯当前事务在依赖图中的依赖路径，保存到 dlock_buffer_ 中，同时将该事务信息从事务依赖图中踢出 DecrementWaitersImpl，也就是将当前txn的<code>wait_ids</code>逆着走一遍初始化的过程，返回发现死锁。</li></ul></li><li>注意一点，就是一个事务是有可能同时等待多个事务的，这个主要出现在使用RangeLock的情况，一个范围锁可能涵盖多个锁，那当然就要等待多个事务了。</li></ul><h1 id="四、两阶段提交（Two-Phase-Commit）"><a href="#四、两阶段提交（Two-Phase-Commit）" class="headerlink" title="四、两阶段提交（Two Phase Commit）"></a>四、两阶段提交（Two Phase Commit）</h1>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RocksDB</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RocksDB:线程私有化</title>
    <link href="/2024/05/12/RocksDB-%E7%BA%BF%E7%A8%8B%E7%A7%81%E6%9C%89%E5%8C%96/"/>
    <url>/2024/05/12/RocksDB-%E7%BA%BF%E7%A8%8B%E7%A7%81%E6%9C%89%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<ul><li>在RocksDB的<code>PointLockManager</code>中有使用到，是系统层面的优化点</li></ul><h1 id="一、线程资源"><a href="#一、线程资源" class="headerlink" title="一、线程资源"></a>一、线程资源</h1><ul><li>这一小节是实现各种系统设计中通过线程私有化实现性能优化的基础</li><li>是由编译器和标准库提供的线程资源的支持，有线程特定数据（Thread Specific Data）和线程局部存储 (Thread Local Storage)两种</li></ul><h2 id="1-1-TLS"><a href="#1-1-TLS" class="headerlink" title="1.1 TLS"></a>1.1 TLS</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-keyword">thread_local</span> var_1 = <span class="hljs-number">0</span>;<br></code></pre></td></tr></table></figure><ul><li>通过<code>thread_local</code>标识符修饰的全局或静态变量是线程独立的，线程对该变量的操作对其它线程来说是不可见的</li></ul><h3 id="线程栈"><a href="#线程栈" class="headerlink" title="线程栈"></a>线程栈</h3><ul><li>在Linux中，并没有真正的线程，而是通过多个进程共享资源的方式实现的。但每个线程自己的线程栈是私有的，通过分配的方式将进程的某一块内存分配给线程使用</li><li>拿到分配的栈空间之后，先将最前面的一段空间初始化为<code>pthread</code>对象，然后就是<code>__thread</code>变量区。代码中所有的 <code>__thread</code>变量是与<code>pthread</code>关联存储的，通过相对于<code>pthread</code>变量地址的偏移实现对变量的寻址</li></ul><h2 id="1-2-TSD"><a href="#1-2-TSD" class="headerlink" title="1.2 TSD"></a>1.2 TSD</h2><ul><li>通过<code>pthread_key_create</code>创建键值映射，每个线程通过键访问线程特定的数据</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 首先声明一个全局的Key</span><br><span class="hljs-type">static</span> <span class="hljs-type">pthread_key_t</span> heap_key_;<br><span class="hljs-comment">// 并且通过接口完成初始化，定义一个序号值（seq）及一个用于释放数据的“析构函数” （destr）</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">pthread_key_create</span> <span class="hljs-params">(<span class="hljs-type">pthread_key_t</span> *key, <span class="hljs-type">void</span> (*destructor)(<span class="hljs-type">void</span> *))</span></span>;<br><span class="hljs-comment">// 线程内通过接口设置某个key对应的值</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">pthread_setspecific</span> <span class="hljs-params">(<span class="hljs-type">pthread_key_t</span> key, <span class="hljs-type">const</span> <span class="hljs-type">void</span> *value)</span></span>;<br><span class="hljs-comment">// 线程内通过接口获取某个key对应的值</span><br><span class="hljs-function"><span class="hljs-type">void</span> *<span class="hljs-title">pthread_getspecific</span> <span class="hljs-params">(<span class="hljs-type">pthread_key_t</span> key)</span></span>;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">pthread_key_delete</span> <span class="hljs-params">(<span class="hljs-type">pthread_key_t</span> key)</span></span>;<br></code></pre></td></tr></table></figure><ul><li>通过TSD可以在每个线程内访问自己私有的变量，同时这些变量在不同的线程中是具有相同的变量名的，即我们在全局声明的<code>pthread_key_t</code>变量</li></ul><h1 id="二、TCMalloc"><a href="#二、TCMalloc" class="headerlink" title="二、TCMalloc"></a>二、TCMalloc</h1><ul><li><code>Golang</code>在设计时借鉴了<code>TCMalloc</code>（线程缓存分配）的设计，实现高速的内存分配</li><li>它的核心理念是使用多级缓存将对象根据大小分类，并按照类别实施不同的分配策略</li></ul><h2 id="2-1-隐式链表分配"><a href="#2-1-隐式链表分配" class="headerlink" title="2.1 隐式链表分配"></a>2.1 隐式链表分配</h2><ul><li>如果要对一整个<code>Page</code>的内存按照相同的单位进行分配，有非常的方法实现，比如可以使用<code>bitmap</code>的方式，如果对4KB的页按照16byte进行分配，只需要4KB &#x2F; 16 &#x2F; 8 &#x3D; 32byte的<code>bitmap</code></li><li>但是出于最大化内存利用率的目的，使用的是另一种经典的方式<code>freelist</code>。因为我们要分配的对象就是内存本身，在构成链表时可以将链表指针放到对象中进行存储，从而不需要额外的内存来存储管理信息了</li></ul><h2 id="2-2-内存对齐的规则"><a href="#2-2-内存对齐的规则" class="headerlink" title="2.2 内存对齐的规则"></a>2.2 内存对齐的规则</h2><ul><li>首先说明，TCMalloc的代码似乎存在多种宏定义可以改变内存的对齐规则，所有下面写的数据不一定是完全不变的</li><li>一共划分了四个档位：<code>(256KB, +∞)</code>按照8KB进行对齐；<code>[128B, 256KB]</code>按照$(1&lt;&lt;LgFloor(size))&#x2F;8$来对齐，$LgFloor$其实就是取size二进制最高位1的位置；<code>(16B, 128B)</code>按照16B进行对其；<code>(0, 16B)</code>按照8B进行对其。</li><li>通过这样设定的对齐方式，对于分配内存小于等于256KB的情况，我们可以将所有的内存size划分穷举出来，被设计成数组方便我们可以直接访问到对应的规则下</li></ul><h2 id="2-3-整体框架"><a href="#2-3-整体框架" class="headerlink" title="2.3 整体框架"></a>2.3 整体框架</h2><ul><li>TCMalloc的整体分配框架分成了<code>Thread Cache</code>, <code>Central List</code>, <code>Page Heap</code>三级</li><li>用户直接向每个线程私有的<code>Thread Cache</code>获取内存块，其基本结构是一个包含所有内存分配单位的数组，每个单元包含这个单位大小的空闲数据块链表，从这里分配内存可以避免多线程的竞争</li><li>如果线程私有的空闲块没有了，需要向全局的<code>Central List</code>申请，每个可能的单位分配大小都有一个<code>Central List</code>实例。每个实例内部是<code>SpanList</code>，存储着用于划分小内存块的<code>span</code>，每个<code>span</code>包含的<code>page</code>数量是不同的，但是同一个<code>Central List</code>下的<code>span</code> size肯定相同</li><li>如果还是没有足够的空间，需要向 <code>Page Heap</code>申请内存块了，内部是一个128长度的数组，用于表示size为1～128个<code>page</code>的<code>span</code>。用多种定长<code>page</code>来实现变长<code>page</code>的分配，初始时只有 128 <code>page</code> 的 <code>span</code>，如果要分配 1 个 <code>page</code> 的 <code>span</code>，就把这个 <code>span</code> 分裂成两个，1 + 127，把127再记录下来。对于 <code>span</code> 的回收，需要考虑<code>span</code>的合并问题，否则在分配回收多次之后，就只剩下很小的 <code>span</code> 了，也就是带来了<strong>外部碎片</strong>问题。</li></ul><h2 id="2-4-分配策略"><a href="#2-4-分配策略" class="headerlink" title="2.4 分配策略"></a>2.4 分配策略</h2><ul><li>每次分配时，从用户申请的对象的size开始，一路发生空间不够向上请求新空间，到最后真正向操作系统申请的内存size是由一些提前设定好的参数决定的</li><li>首先，用户申请的内存size会被进行对齐处理，这里是通过前面说的方法进行对齐的，但是我们还应该得出这是哪一个内存size下的，及得到<code>Index</code>，这是通过<code>ClassIndex(size)</code>实现的</li><li>然后，通过<code>Index</code>访问<code>class_to_size_</code>得到实际该给用户返回多大的内存</li><li>接着，通过<code>Index</code>访问<code>num_objects_to_move_</code>查每次给对应<code>thread_cache</code>分配多少个object，这里有预先多给一部分同样大小的内存块给线程的意思</li><li>最后，通过<code>Index</code>访问<code>class_to_pages_</code>查每次给不同<code>central_freelist</code>分包含多少个页的<code>span</code></li><li>超过256KB的大内存的分配会绕过其他结构直接访问<code>Page Heap</code>，并且单独管理</li></ul><h2 id="2-5-线程私有"><a href="#2-5-线程私有" class="headerlink" title="2.5 线程私有"></a>2.5 线程私有</h2><ul><li>在<code>TCMalloc</code>的三层结构中，<code>Thread Cache</code>这一层为了避免多线程的竞争从而带来的性能影响，选择了使用线程私有的方式实现</li><li>代码中使用了TSD的方式，为每个线程在需要通过<code>TCMalloc</code>申请内存时，构建一个线程私有的<code>Thread Cache</code>，实现内存分配上的线程私有话，避免了线程之间的竞争</li><li>但是因为TSD方式对局部变量的访问需要通过<code>pthread_getspecific()</code>，速度比较慢，因此<code>Thread Cache</code>中还有<code>__thread</code>变量存储每个线程对象的副本</li><li>但是因为需要注册清理函数，所以必须要TSD的方式创建线程局部变量</li></ul><h1 id="三、ThreadLocalPtr"><a href="#三、ThreadLocalPtr" class="headerlink" title="三、ThreadLocalPtr"></a>三、ThreadLocalPtr</h1><ul><li>RocksDB对线程私有存储的封装</li><li>实现线程私有的方法也非常简单，就是使用<code>pthread_key_t</code>，但是这样的实现方式较为原生，对于每一个需要私有化的变量都需要我们声明并创建。并且当我们不能事先知道需要多少私有变量个数时，会更加不方便</li><li>可以在全局就用一个<code>pthread_key_t</code>，这样所有线程都能知道它并通过它来访问自己的私有存储，然后在这个私有存储上做文章，让它支持维护多个变量就可以了</li></ul><h2 id="3-1-使用方法"><a href="#3-1-使用方法" class="headerlink" title="3.1 使用方法"></a>3.1 使用方法</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 1.首先定义线程退出时的回掉函数，用于释放存储的局部对象</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">UnrefHandle</span><span class="hljs-params">(<span class="hljs-type">void</span> *ptr)</span> </span>&#123;<br>  <span class="hljs-comment">//当线程退出的时候会回调UnrefHandle来释放该线程的私有存储，ptr指向该私有存储地址</span><br>  <span class="hljs-comment">//所以这里需要定义这块私有存储该如何释放，比如最简单的:</span><br>  <span class="hljs-keyword">delete</span> <span class="hljs-built_in">static_cast</span>&lt;Object&gt;(ptr);<br>&#125;<br><br><span class="hljs-comment">// 2.创建一个私有的存储变量，对应着pthread_key_create</span><br>ThreadLocalPtr *local_1 = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ThreadLocalPtr</span>(&amp;UnrefHandle);<br><br><span class="hljs-comment">// 3.设置本线程对应的该私有存储变量的值，对应pthread_setspecific</span><br>Object *ptr_1 = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Object</span>();<br><span class="hljs-type">void</span> *old_ptr_1 = local_1-&gt;<span class="hljs-built_in">Swap</span>(ptr_1);<br><span class="hljs-comment">// 或者使用reset，其实和swap是一样的，差别在是否返回原来位置上的值</span><br>local_1-&gt;<span class="hljs-built_in">Reset</span>(ptr_1);<br><br><span class="hljs-comment">// 4.读取本线程对应的私有存储变量的值，对应pthread_getspecific</span><br><span class="hljs-type">void</span> *cur_ptr_1 = local_l-&gt;<span class="hljs-built_in">Get</span>();<br></code></pre></td></tr></table></figure><h2 id="3-2-实现过程"><a href="#3-2-实现过程" class="headerlink" title="3.2 实现过程"></a>3.2 实现过程</h2><ul><li><p>首先所有真正被存放在<code>ThreadLocalPtr</code>中的都是指针，而不是数据本身，并且都是被转换成<code>void*</code>类型被包装在<code>Entry</code>对象中的，不用的线程只要能够获取到不同的指针就能访问到私有的内存了</p></li><li><p>然后是<code>ThreadData</code>包含<code>std::vector&lt;Entry&gt;</code>，这里其实存放了用户的多个私有内存的指针，因此只要我们能够实现每个线程都单独具有一个<code>ThreadData</code>对象，然后将每个线程需要私有化的内容放到<code>ThreadData</code>的数组中就可以了</p></li><li><p>接着是最重要的<code>StaticMeta</code>，其在整个程序中只存在一份，是单例模式。其内部包含了<code>static thread_local ThreadData* tls_;</code>和<code>pthread_key_t pthread_key_;</code>两个变量，都是存储的<code>ThreadData</code>指针，其中TLS方式是为了加速访问存储的副本</p></li><li><p>最后<code>ThreadLocalPtr</code>对象只存储了一个<code>ID</code>值，这是用于访问在<code>ThreadData</code>中保存的私有变量时，用于索引<code>std::vector&lt;Entry&gt;</code>的，其实就是通过下标的方式标明是哪一个变量。因为数组的长度不能无限的增长，因此<code>ID</code>其实是会进行回收使用的</p></li><li><p>关于对象的释放操作，目前存在两个维度的对象释放：</p><ol><li>当某个线程结束之后，其下管理的所有私有对象都应该被释放。这是由注册线程私有<code>ThreadData</code>时，通过<code>pthread_key_create</code>传入的回掉函数<code>OnThreadExit</code>完成。线程退出时自动调用回掉函数，会遍历<code>ThreadData</code>中的数组，并对每一个变量调用它的释放函数</li><li>当我们主动删除某一个线程私有变量时（也就是删除某个<code>ThreadLocalPtr</code>对象），我们需要将所有线程下的该私有对象都进行释放处理。这里是通过<code>ThreadData</code>自己构成的双向链表，找出所有线程下的变量进行释放</li></ol></li></ul><h1 id="四、线程私有优化案例"><a href="#四、线程私有优化案例" class="headerlink" title="四、线程私有优化案例"></a>四、线程私有优化案例</h1><h2 id="4-1-PointLockManager优化"><a href="#4-1-PointLockManager优化" class="headerlink" title="4.1 PointLockManager优化"></a>4.1 PointLockManager优化</h2><ul><li><p>在RocksDB的点锁实现<code>PointLockManager</code>中，不同<code>ColumnFamily</code>拥有不同的<code>LockMap</code>，而所有的<code>LockMap</code>是被集中存储在一个<code>LockMaps</code>下的</p></li><li><p>因此当我们需要对某个<code>ColumnFamily</code>下的Key加锁时，需要先将整个<code>PointLockManager</code>锁起来，然后从<code>LockMaps</code>中取出对应<code>ColumnFamily</code>的<code>LockMap</code>，然后再执行后续的操作</p></li><li><p>这里为了获得<code>ColumnFamily</code>对应的<code>LockMap</code>需要对整个<code>PointLockManager</code>对象进行加锁显然会造成较大的竞争。因此这里采用了线程优化的方式，在每个线程中都准备了一个<code>LockMaps</code>，并且把当前线程需要用到的<code>ColumnFamily</code>的<code>LockMap</code>放入其中</p></li><li><p>在线程私有化<code>LockMaps</code>之后，进行加锁时只需要访问线程本地的<code>LockMaps</code>，并查询<code>ColumnFamily</code>对应的<code>LockMap</code>，不需要加整个<code>PointLockManager</code>对象中的大锁</p></li><li><p>当然也有可能出现当前线程本地的<code>LockMaps</code>中不存在某个<code>ColumnFamily</code>的<code>LockMap</code>的问题，这个时候就需要加大锁从全局的<code>LockMaps</code>中查询结果，并添加到本地的<code>LockMaps</code>中</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RocksDB</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
