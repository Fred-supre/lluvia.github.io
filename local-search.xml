<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Makefile笔记</title>
    <link href="/2024/05/17/Makefile%E7%AC%94%E8%AE%B0/"/>
    <url>/2024/05/17/Makefile%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<blockquote><p>参考资料：<a href="/2024/05/17/%E9%99%88%E7%9A%93%E7%9A%84makefile%E7%AC%94%E8%AE%B0">陈皓makefile</a></p></blockquote><ul><li>Makefile作为一种自动化编译工具，理论上任何语言的编译，或者说任意工程的构建都是可以用make来完成的。但其实现如今主要还是作为<code>C/C++</code>的编译工具存在，其运行逻辑也和<code>C/C++</code>的编译流程十分契合。</li><li>因此本文首先会讲讲<code>C/C++</code>的编译过程，如何使用<code>gcc, g++, ar</code>工具等。然后再讲诉<code>make</code>的依赖关系定义以及命令的书写。</li></ul><h1 id="一、C-C-编译"><a href="#一、C-C-编译" class="headerlink" title="一、C/C++编译"></a>一、<code>C/C++</code>编译</h1><h2 id="1-1-编译可重定位目标文件"><a href="#1-1-编译可重定位目标文件" class="headerlink" title="1.1 编译可重定位目标文件"></a>1.1 编译可重定位目标文件</h2><ul><li>在<code>C/C++</code>的编译过程中，首先都是针对每个<code>.c/.cc/.cpp</code>文件编译成相同文件名的<code>.o</code>文件，这个过程即为生成可重定位目标文件，每个文件的编译过程都是独立的，我们是需要针对每一个<code>.c/.cc/.cpp</code>文件分别调用<code>gcc/g++</code>编译器的。</li><li>另外这部分的编译相互之间是独立的，只要保证能找到引用的各种<code>.h</code>文件就能成功编译。但是注意，如果我们修改了其引用的某个<code>.h</code>文件，那么这个<code>.o</code>文件是需要重新编译的（这也是<code>makefile</code>中<code>.o</code>依赖关系需要同时存在<code>.c/.cc/.cpp</code>和<code>.h</code>的原因）</li><li>编译方法<code>gcc -c main.c -o main.o</code>注意这条编译命令中并没有出现应用的<code>.h</code>文件，这是因为会到默认的搜索路径下去找需要用到的头文件，如果存在额外的头文件文件夹是需要我们使用<code>-I./include/</code>这样的参数添加头文件搜索路径的。</li></ul><h2 id="1-2-编译静态库文件"><a href="#1-2-编译静态库文件" class="headerlink" title="1.2 编译静态库文件"></a>1.2 编译静态库文件</h2><ul><li>静态库其实是对许多<code>.o</code>文件的归档<code>Archive</code>，因此打包静态库的命令其实就是<code>ar cr libxxx.a xx1.o xx2.o</code>。</li><li>打包出来的<code>.a</code>静态库文件其实就是一堆<code>.o</code>文件集合，是可以对单个目标文件进行替换操作的，即当某一个<code>.o</code>文件发生变化时我们可以在原来的<code>.a</code>文件上执行这一个<code>.o</code>文件的替换。（这个性质非常重要，会被应用到<code>makefile</code>的构建中。）</li><li>参数<code>r</code>即表示在库中插入模块（替换）。当插入的模块名已经在库中存在，则替换同名的模块。默认的情况下，新的成员增加在库的结尾处，可以使用其他任选项来改变增加的位置。</li><li>参数<code>c</code>表示创建一个库。不管库是否存在，都将创建。</li></ul><h2 id="1-3-编译动态库文件"><a href="#1-3-编译动态库文件" class="headerlink" title="1.3 编译动态库文件"></a>1.3 编译动态库文件</h2><ul><li><p>动态库的构建则涉及到链接过程，不仅仅是简单地将目标文件打包。通常需要使用链接器（如<code>g++</code>或<code>ld</code>）来创建一个包含所有必要符号的共享对象文件。构建动态库的命令为<code>gcc -shared -fPIC -o libtest.so test.o</code>。</p></li><li><p>在动态库（共享库）的构建过程中，一旦生成了<code>.so</code>这样的共享对象文件，它就包含了所有输入的<code>.o</code>目标文件的编译结果以及它们之间的链接信息。这意味着，即使你修改了其中一个目标文件，也不能简单地将其替换到已有的动态库中，因为动态库的完整性和链接信息是基于原始构建时的所有目标文件的。</p></li><li><p>另外，动态库的构建因为涉及链接过程，如果代码中引用了别的库是需要在构建的时候使用<code>-L./path/ -l[lib name]</code>进行引入的。另外动态库的链接尽量使用动态库的方式。</p></li></ul><h2 id="1-4-编译可执行文件"><a href="#1-4-编译可执行文件" class="headerlink" title="1.4 编译可执行文件"></a>1.4 编译可执行文件</h2><ul><li>编译过程和动态库是相似的，命令是<code>gcc -o test test.o -lpthread libcertain.a</code>注意动态库和静态库的链接方式的不同。</li></ul><h1 id="二、Makefile"><a href="#二、Makefile" class="headerlink" title="二、Makefile"></a>二、Makefile</h1><h2 id="2-1-基本运行方式"><a href="#2-1-基本运行方式" class="headerlink" title="2.1 基本运行方式"></a>2.1 基本运行方式</h2><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">target: prerequisites</span><br>[Tab]command<br></code></pre></td></tr></table></figure><ul><li><p>这是<code>Makefile</code>文件的基本规则：<code>target</code>也就是一个目标文件，可以是<code>Object File</code>，也可以是执行文件，还可以是一个标签<code>Label</code>；<code>prerequisites</code>就是要生成那个<code>target</code>所需要的文件或是依赖；  <code>command</code>也就是<code>make</code>需要执行的命令（任意的Shell命令）。</p></li><li><p>这里定义的其实是一种依赖关系，即<code>target</code>需要依赖于<code>prerequisites</code>这些对象，而使用这些依赖生成<code>target</code>的方式是下面给出的<code>command</code>指令。需要注意，不一定需要真的生成<code>target</code>文件；也不一定需要真的使用所有<code>prerequisites</code>对象；甚至<code>command</code>也不一定需要，某些依赖是不需要执行指令的，比如<code>all:test1 test2 test2</code>这样的一条依赖。</p></li><li><p>一个<code>Makefile</code>文件中可能会定义多个依赖关系，make会自动帮我们理清目标之间的相互依赖关系，然后帮我们按照正确的顺序得到最终的目标文件。</p></li></ul><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-comment"># 最终目标文件--可执行文件</span><br>edit : main.o kbd.o command.o<br>      cc -o edit main.o kbd.o command.o <br><span class="hljs-comment"># 中间目标文件</span><br>main.o : main.c defs.h<br>      cc -c main.c<br>kbd.o : kbd.c defs.h command.h<br>      cc -c kbd.c<br>command.o : command.c defs.h command.h<br>      cc -c command.c<br><span class="hljs-comment"># 伪目标文件</span><br>clean :<br>      rm edit main.o kbd.o command.o<br></code></pre></td></tr></table></figure><ul><li>这里给出了一个构建依赖关系的例子，如果使用<code>make</code>进行编译，根据依赖关系会优先编译所有的<code>.o</code>文件，最后编译可执行文件。这就是简单按照步骤编译整个项目，并不是<code>make</code>的核心功能。</li><li>我们知道一个比较大的<code>C/C++</code>项目在构建的时候是分成多个步骤的，存在很多中间文件。以上面这个例子，如果我们已经先编译过一次了，现在只修改了其中的<code>main.c</code>文件。如果我们再次编译项目<code>make</code>会发现<code>main.o</code>的日期早于<code>main.c</code>的日期，此时<code>make</code>会自动判定需要重新生成<code>main.o</code>文件。当然这会造成<code>edit</code>的日期又晚于<code>main.o</code>，也需要重新生成。</li><li>在一个大项目的修改中，往往只会涉及较少的一部分文件，因此很多文件是不需要重新编译的。<code>make</code>自动帮我们解决了这个问题。</li><li>对于伪目标而言，因为缺失依赖的对象，也就不会自动执行其后所定义的命令。要执行其后的命令，就要在<code>make</code>命令后明显得指出这个lable的名字。</li></ul><h2 id="2-2-o目标依赖"><a href="#2-2-o目标依赖" class="headerlink" title="2.2 .o目标依赖"></a>2.2 <code>.o</code>目标依赖</h2><h3 id="2-2-1-隐式规则"><a href="#2-2-1-隐式规则" class="headerlink" title="2.2.1 隐式规则"></a>2.2.1 隐式规则</h3><ul><li>一般来说我们项目中的每一个<code>.c/.cc/.cpp</code>文件都是需要生成对应的<code>.o</code>文件的。如果我们按照例子中的方式对每一个<code>.c/.cc/.cpp</code>文件都手动写出依赖和构建方式，这个工作量将会是巨大的。<code>make</code>提供了一种隐式规则方式来自动生成他们的构建方式。</li></ul><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">%.o: %.cc </span><br><span class="hljs-variable">$(GXX)</span> <span class="hljs-variable">$(GXXFLAGS)</span> -c <span class="hljs-variable">$&lt;</span> -o <span class="hljs-variable">$@</span><br></code></pre></td></tr></table></figure><ul><li>在这个模式规则的定义下，当我们需要某个<code>.o</code>文件时，会按照模式给出的模版自动生成构建指令。</li><li>这里的<code>$&lt;</code>表示<code>prerequisites</code>中的第一个对象；<code>$@</code>表示<code>target</code>中的挨个值。</li></ul><h3 id="2-2-2-依赖关系"><a href="#2-2-2-依赖关系" class="headerlink" title="2.2.2 依赖关系"></a>2.2.2 依赖关系</h3><ul><li>但是我们发现这样的模式规则是没有包含<code>.h</code>文件的，虽然<code>.h</code>文件并不直接写入我们编译<code>.o</code>文件的命令。但是这个依赖关系是会影响<code>makefile</code>的编译过程的，即如果依赖关系仅仅是<code>%.o: %.cc</code>，那么当我们仅修改<code>.h</code>文件并进行编译时，<code>make</code>并不会重新编译引用该头文件的<code>.cc</code>。</li><li>但是一个源文件可能引用非常多的头文件，如果这个引用关心手动管理会非常繁琐，因此使用<code>g++ -MM xxx.cc</code>工具自动生成源文件和头文件的依赖文件。</li><li>当然这个依赖文件的生成过程是可以通过<code>makefile</code>实现的，先生成依赖文件并将其引入当前<code>makefile</code>即可：</li></ul><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">%.d: %.c</span><br>    @set -e; rm -f <span class="hljs-variable">$@</span>; \<br>    <span class="hljs-variable">$(CC)</span> -MM <span class="hljs-variable">$(CPPFLAGS)</span> <span class="hljs-variable">$&lt;</span> &gt; <span class="hljs-variable">$@</span>.; \<br>    sed &#x27;s/\(<span class="hljs-variable">$*</span>\)\.o[ :]*/\1.o <span class="hljs-variable">$@</span> : /g&#x27; &lt; <span class="hljs-variable">$@</span>.&gt; <span class="hljs-variable">$@</span>; \<br>    rm -f <span class="hljs-variable">$@</span>.<br>    <br>SRC=<span class="hljs-variable">$(<span class="hljs-built_in">wildcard</span> *.cc)</span><br>DEP=$(SRC:.cc=.d)<br><span class="hljs-keyword">-include</span> <span class="hljs-variable">$(DEP)</span><br></code></pre></td></tr></table></figure><ul><li>这里通过<code>g++ -MM xxx.cc</code>生成的内容是形如<code>main.o : main.c defs.h</code>的内容，后面跟了一条<code>sed</code>指令是在原内容中新增<code>main.d</code>的依赖关系，即改成<code>main.o main.d : main.c defs.h</code>。如此依赖根据依赖关系的定义，只要修改过相关的<code>.h</code>文件，就必须要重新编译依赖于它的源文件了。</li><li>然后再将生成的所有<code>.d</code>依赖文件包含到当前<code>makefile</code>中，需要注意<code>include</code>命令之前增加符号<code>-</code>，避免第一次<code>make</code>时由于.<code>d</code>文件不存在报告错误信息。</li><li>但是存在一个疑问，<code>make</code>是根据依赖关系来生成文件的，这里的关于<code>.d</code>的文件依赖存在哪里，如何触发这些文件的生成的呢？</li></ul><h2 id="2-3-静态库的依赖"><a href="#2-3-静态库的依赖" class="headerlink" title="2.3 静态库的依赖"></a>2.3 静态库的依赖</h2><ul><li>在第一节的内容中我们提到静态库文件其实就是一堆<code>.o</code>文件的归档，根据<code>ar</code>命令的使用规则我们可以很容易写出依赖关系：</li></ul><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile">libxxx.a : xx1.o xx2.o<br>    ar cr <span class="hljs-variable">$@</span> <span class="hljs-variable">$^</span><br></code></pre></td></tr></table></figure><ul><li><p><code>$^</code>的意思是所有的依赖目标的集合。以空格分隔，如果在依赖目标中有多个重复的，那个这个变量会去除重复的依赖目标，只保留一份。</p></li><li><p>但是静态库的打包是可以仅仅新增或者更新一小部分的，即当这里的<code>.o</code>文件列表只有一部分发生更改的时候，并不需要完全重新打包一遍，所以应该使用<code>$?</code>，表示所有比目标新的依赖目标的集合，以空格分隔。个人认为这个自动变量是专门为<code>ar</code>的运行逻辑设计的。</p></li></ul><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile">libxxx.a : xx1.o xx2.o<br>    ar cr <span class="hljs-variable">$@</span> <span class="hljs-variable">$?</span><br></code></pre></td></tr></table></figure><h2 id="2-4-伪目标"><a href="#2-4-伪目标" class="headerlink" title="2.4 伪目标"></a>2.4 伪目标</h2><ul><li>我们定义依赖关系的时候，可以在依赖的下方定义用于生成目标文件的指令，也可以不定义而根据隐含规则生成指令。但是还存在一种可能是这就是一个伪目标，这常见于<code>clean, all</code>等命令或者标签。</li><li>由于伪目标不是文件，所以<code>make</code>无法生成它的依赖关系和决定它是否要执行。我们只有通过显示地指明这个目标才能让其生效。</li><li>当这些为目标存在和项目中的某个文件重名的风险，我们需要使用<code>.PHONY: clean all</code>指令来指明这是一个伪目标。</li></ul>]]></content>
    
    
    <categories>
      
      <category>C/C++</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Makefile</tag>
      
      <tag>C/C++</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RPC框架</title>
    <link href="/2024/05/13/RPC%E6%A1%86%E6%9E%B6/"/>
    <url>/2024/05/13/RPC%E6%A1%86%E6%9E%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="一、基础概念"><a href="#一、基础概念" class="headerlink" title="一、基础概念"></a>一、基础概念</h1><ul><li><code>RPC(Remote Procedure Call)</code>即远程过程调用，允许一台计算机调用另一台计算机上的程序得到结果，而代码中不需要做额外的编程，就像在本地调用一样。</li><li>所以可以把RPC看作是一种网络服务，网络传输函数调用信息，远端运行对应函数，然后再网络返回运行结果。这是一个很基本的运行模式，但是具体的实现方案却是多种多样的，但主要包含这些基本部分：</li></ul><ol><li>网络编程接口和协程。几乎所有的网络编程都会用多路复用，典型的就是使用<code>epoll</code>；而解决这种基于事件的最好编程模式是使用协程，用顺序逻辑写异步处理代码。</li><li>服务器架构。作为<code>RPC</code>服务器需要考虑如何设计出效率更高、吞吐量更高的服务器，这就是服务器机构设计的意义所在。经过多年的发展从最简单的多进程、多线程，到后来的多路复用异步编程，再到协程设计都是服务器架构设计的提升。</li><li>分发、动态代理。服务器的设计思路一般是每次被远程调用都运行一个相同的<code>dispatch</code>函数，然后在分发函数的内部去根据调用方法执行不同的函数。比如用<code>stub</code>拿到对应的方法名和参数类型，通过反射的方式找到方法，然后调用相应的方法并将结果返回给<code>stub</code>。</li><li>网络协议。即客户端和服务端之间通信选用的协议，传输层是使用<code>TCP/UDP</code>，然后在应用层可以选择<code>HTTP</code>等。</li><li>序列化。远程函数的调用的时候需要传输参数和运行结果，这里需要将代码中的结构体或者对象进行序列化和反序列化，有<code>protobuf</code>这样的工具帮助生成代码。</li><li>服务注册。</li></ol><h1 id="二、PhxRPC"><a href="#二、PhxRPC" class="headerlink" title="二、PhxRPC"></a>二、PhxRPC</h1><ul><li><code>PhxRPC</code>项目是一个完整的RPC框架，包括协程模块、服务器模块、网络协议模块、序列化模块等。</li><li>协程是使用<code>boost::ucontext</code>实现的，并且是无栈协程。如果想要创建新的协程需要在主协程中创建，不能在协程内创建新的协程。具体来说代码中通过一个<code>AddTask</code>函数创建协程，但这里只是将该协程加入到队列中，需要等到主协程的调度循环中取出这个协程并开始运行。这里和<code>libco</code>中的设计不太一样，<code>libco</code>是在创建协程之后立刻运行，但这就需要协程栈的支持了，必须要退回到上一级的协程。协程是一个非常大的话题，详细见<a href="https://lluvialuo.github.io/2024/05/12/%E5%8D%8F%E7%A8%8B%E5%BA%93/">协程库</a>。</li><li>网络协议上使用的<code>HTTP</code>，也属于比较常规的内容，但是注意<code>HTTP</code>的接口在实现时需要考虑是在协程上运行的，所以应该使用重新定义的网络读写接口。</li></ul><h2 id="2-1-基础框架"><a href="#2-1-基础框架" class="headerlink" title="2.1 基础框架"></a>2.1 基础框架</h2><div style="text-align:center;">    <img src="RPC架构.png" alt="RPC架构.png" width="405" height="323" class="jop-noMdConv"></div><ul><li><code>PhxRPC</code>的服务器架构有核心三个角色，分别是<code>HshaServer, HshaServerUnit, Worker</code>，图中是用虚线框表示的，他们都运行在各自的线程中（即每个虚线框都表示一个线程）；存在<code>UThreadEpollScheduler</code>单元的线程即表示在这个线程中存在协程调度单元，这个线程是以协程的模式运行的。</li><li><code>HshaServer</code>主要用于监听新的<code>TCP</code>链接，<code>HshaServerUnit</code>处理所有<code>RPC</code>请求响应相关的网络读写，而下方的<code>worker</code>用于实际执行用户自定义的业务逻辑。</li></ul><h2 id="2-2-核心流程"><a href="#2-2-核心流程" class="headerlink" title="2.2 核心流程"></a>2.2 核心流程</h2><div style="text-align:center;">    <img src="PhxRPC流程图.png" alt="PhxRPC流程图.png" width="872" height="425" class="jop-noMdConv"></div><h3 id="2-2-1-HshaServer"><a href="#2-2-1-HshaServer" class="headerlink" title="2.2.1 HshaServer"></a>2.2.1 <code>HshaServer</code></h3><ul><li><code>HshaServer</code>的职责是监听<code>Socket</code>端口，然后建立与客户端的连接，并将连接的<code>fd</code>传给<code>HshaServerUnit</code>进行后续处理。</li></ul><p><strong>处理流程</strong></p><ul><li>首先<code>HshaServer</code>会在构造函数里就创建多个<code>HshaServerUnit</code>，用于在后台处理各种事件，创建的时候就会启动线程。使用链表的方式来管理所有的<code>HshaServerUnit</code>。</li><li>监听的工作是<code>HshaServerAcceptor</code>完成的，处理流程是先建立并绑定<code>socket</code>端口，然后通过死循环的方式不断获得新到来的连接。</li><li>接着会从链表中选择一个<code>HshaServerUnit</code>来处理这次请求，这里是可以考虑使用一些负载均衡策略的，<code>PhxRPC</code>的实现方式用了简单的轮询方案。</li><li>最后是调用选定的<code>HshaServerUnit</code>的方法，将这个待处理的<code>fd</code>放入其内部的<code>HshaServerIO</code>的一个队列中，再通过调用该<code>HshaServerUnit</code>内部的<code>UThreadEpollScheduler::NotifyEpoll</code>方法唤醒线程进行处理。</li></ul><p><strong>线程唤醒问题</strong></p><ul><li><code>HshaSercer</code>和<code>HshaServerUnit</code>其实运行在不同的线程中的，当我们在<code>HshaServer</code>流程中添加一个任务之后想要立刻唤醒<code>HshaServerUnit</code>所在的线程立刻处理，但因为<code>HshaServerUnit</code>运行在协程模式下，目前该线程极有可能在<code>epoll_wait</code>等待状态。</li><li>所以需要一个机制将其从等待状态唤醒，<code>PhxRPC</code>选择的是创建一个管道，然后将管道也加入到<code>epoll</code>中进行轮询，所以当另外的线程想要唤醒自己的时候，只需要向管道中写入新的数据就可以了。这便是<code>NotifyEpoll</code>的实现方案。</li></ul><h3 id="2-2-2-HshaServerUnit"><a href="#2-2-2-HshaServerUnit" class="headerlink" title="2.2.2 HshaServerUnit"></a>2.2.2 <code>HshaServerUnit</code></h3><ul><li><code>HshaServerUnit</code>是用来处理<code>RPC</code>的网络数据读写的，在承接到<code>HshaServer</code>传来的<code>socket</code>连接之后需要先读出请求信息，然后将请求通过<code>DataFlow</code>发送给<code>Worker</code>进行处理；等待<code>Worker</code>处理完成之后需要再从<code>DataFlow</code>中取出返回信息，并将返回的数据写入<code>socket</code>。</li><li>可以发现<code>HshaServerUnit</code>是一个中间层的角色，只汇总处理<code>Socket IO</code>的问题，并执行用户定义的函数。并且一个<code>HshaServerUnit</code>可以管理多个<code>Worker</code>，这以为着多个<code>Worker</code>在<code>RPC</code>的网络传输上都是汇总给一个线程来处理的。</li></ul><p><strong>处理流程</strong></p><ul><li><code>HshaServerIO::HandlerAcceptedFd</code>函数是读取队列中缓存的<code>socket</code>连接，然后创建协程处理这个<code>socket</code>相关的网络数据读写，注册的函数是<code>HshaServerIO::IOFunc</code>。</li><li><code>IOFunc</code>的流程是先读数据，解析<code>HTTP</code>协议并生成<code>request</code>结构体；然后将其放入<code>DataFlow</code>中，并唤醒一个<code>Worker</code>来处理请求。</li><li>在通过<code>WokerPool</code>来唤醒<code>Woker</code>时，也是可以选择唤醒谁来处理的，可以有负载均衡的方案，但<code>PhxRPC</code>依然使用的轮询方案来处理。但不同的是，所有任务都被放在了<code>DataFlow</code>中，所有的<code>worker</code>对任务是一种竞争关系，不一定是唤醒的<code>Worker</code>拿到这个任务。这个和<code>HshaServerUnit</code>获取<code>socket</code>连接还不太一样，这个是直接写入了<code>HshaServerUnit</code>内部的队列，所以是不存在竞争关系的。</li><li>然后当前协程<code>IOFunc</code>被挂起，等待任务处理完成之后恢复运行（具体是等<code>ActiveSocketFunc</code>唤醒准备好的协程），恢复之后将结果写入<code>socket</code>，任务就完成了。</li><li><code>HshaServerIO::ActiveSocketFunc</code>是从<code>DataFlow</code>当中读取完成的<code>response</code>，这里面保存了<code>socket</code>信息以及协程ID，于是就可以通过协程ID恢复对应的协程了。</li></ul><h3 id="2-2-3-Worker"><a href="#2-2-3-Worker" class="headerlink" title="2.2.3 Worker"></a>2.2.3 <code>Worker</code></h3><ul><li><code>Worker::HandlerNewRequestFunc</code>函数用于从<code>DataFlow</code>中读取数据，并生成对应的处理协程，注册函数<code>Worker::UThreadFunc</code>；这个函数内部就是调用用户自定义的处理函数，并且将<code>response</code>写入到<code>DataFlow</code>中，最好还需要唤醒<code>HshaServerUnit</code>。</li><li>一开始看到<code>Worker</code>是多线程实现的，在想为啥处理函数的也需要用协程来组织，毕竟处理函数一般都是消耗<code>CPU</code>来处理，并不存在阻塞浪费资源的情况。但是这是一个<code>RPC</code>服务器，我们在处理某个请求的时候是有可能需要通过网络去访问别的服务的，比如<code>mysql, redis, rpc_server</code>等，所以这里的设计也是用协程。</li></ul><h2 id="2-3-序列化工具-ProtoBuf"><a href="#2-3-序列化工具-ProtoBuf" class="headerlink" title="2.3 序列化工具:ProtoBuf"></a>2.3 序列化工具:<code>ProtoBuf</code></h2><blockquote><p>参考资料：</p><p><a href="https://blog.csdn.net/liuxiao723846/article/details/99884741">C++ protobuf示例</a></p><p><a href="https://www.tizi365.com/archives/367.html">ProtoBuf 入门教程</a></p></blockquote><ul><li><code>Protocol Buffers</code>是一种语言无关、平台无关、可扩展的序列化结构数据的方法，它可用于（数据）通信协议、数据存储等。</li><li>灵活，高效，自动化机制的结构数据序列化方法，可类比 <code>XML</code>，但是比 <code>XML</code> 更小（3 ~ 10倍）、更快（20 ~ 100倍）、更简单，<code>json\xml</code>都是基于文本格式，<code>protobuf</code>是二进制格式。</li></ul><h3 id="2-3-1-安装"><a href="#2-3-1-安装" class="headerlink" title="2.3.1 安装"></a>2.3.1 安装</h3><ul><li><p>官网下载项目源码：<code>https://github.com/protocolbuffers/protobuf.git</code></p></li><li><p>下载依赖的第三方库项目：<code>git submodule update --init --recursive</code></p></li><li><p>使用CMake编译安装，创建一个<code>build</code>文件夹，然后执行命令<code>cmake -DCMAKE_BUILD_TYPE=Release -Dprotobuf_BUILD_TESTS=OFF -DABSL_PROPAGATE_CXX_STD=ON ..</code></p></li><li><p>接着通过make编译并安装项目即可<code>make &amp; sudo make install</code></p></li><li><p>安装操作将会把三种文件放置到三个地方，分别是：</p><ul><li>生成代码的可执行文件放在<code>/usr/local/bin</code></li><li>生成代码需要引用的头文件在<code>/usr/local/include</code></li><li>编译链接的<code>-lprotobuf</code>库文件放置在<code>/usr/local/lib</code></li></ul></li></ul><h3 id="2-3-2-消息定义"><a href="#2-3-2-消息定义" class="headerlink" title="2.3.2 消息定义"></a>2.3.2 消息定义</h3><ul><li>首先所有数据结构的定义都放在单独的<code>.proto</code>文件中，结构定义规则如下：</li></ul><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-keyword">message </span><span class="hljs-title class_">xxx</span> &#123;<br>  <span class="hljs-comment">// 字段规则：required -&gt; 字段只能也必须出现 1 次</span><br>  <span class="hljs-comment">// 字段规则：optional -&gt; 字段可出现 0 次或 1 次</span><br>  <span class="hljs-comment">// 字段规则：repeated -&gt; 字段可出现任意多次（包括 0）</span><br>  <span class="hljs-comment">// 类型：int32、int64、sint32、sint64、string、32-bit ....</span><br>  <span class="hljs-comment">// 字段编号：0 ~ 536870911（除去 19000 到 19999 之间的数字）</span><br>  [字段规则] [类型] [名称] = [字段编号];<br>&#125;<br><br><br><span class="hljs-keyword">message </span><span class="hljs-title class_">Person</span> &#123;<br>  <span class="hljs-keyword">required</span> <span class="hljs-type">string</span> name = <span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">required</span> <span class="hljs-type">int32</span> id = <span class="hljs-number">2</span>;<br>  <span class="hljs-keyword">optional</span> <span class="hljs-type">string</span> email = <span class="hljs-number">3</span>;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>此外可以在<code>.proto</code>文件中通过定义<code>package xxx</code>来设置生成的代码的<code>namespace</code></li><li>下面定义了<code>protobuf</code>的格式与C++类型的对应表</li></ul><table><thead><tr><th align="left">.protoType</th><th align="left">Notes</th><th align="left">C++Type</th></tr></thead><tbody><tr><td align="left">double</td><td align="left"></td><td align="left">double</td></tr><tr><td align="left">float</td><td align="left"></td><td align="left">float</td></tr><tr><td align="left">int32</td><td align="left">使用变长编码，对于负值的效率很低，如果你的域有可能有负值，请使用sint64替代</td><td align="left">int32</td></tr><tr><td align="left">uint32</td><td align="left">使用变长编码</td><td align="left">uint32</td></tr><tr><td align="left">uint64</td><td align="left">使用变长编码</td><td align="left">uint64</td></tr><tr><td align="left">sint32</td><td align="left">使用变长编码，这些编码在负值时比int32高效的多</td><td align="left">int32</td></tr><tr><td align="left">sint64</td><td align="left">使用变长编码，有符号的整型值。编码时比通常的int64高效。</td><td align="left">int64</td></tr><tr><td align="left">fixed32</td><td align="left">总是4个字节，如果数值总是比总是比228大的话，这个类型会比uint32高效。</td><td align="left">uint32</td></tr><tr><td align="left">fixed64</td><td align="left">总是8个字节，如果数值总是比总是比256大的话，这个类型会比uint64高效。</td><td align="left">uint64</td></tr><tr><td align="left">sfixed32</td><td align="left">总是4个字节</td><td align="left">int32</td></tr><tr><td align="left">sfixed64</td><td align="left">总是8个字节</td><td align="left">int64</td></tr><tr><td align="left">bool</td><td align="left"></td><td align="left">bool</td></tr><tr><td align="left">string</td><td align="left">一个字符串必须是UTF-8编码或者7-bit ASCII编码的文本。</td><td align="left">string</td></tr><tr><td align="left">bytes</td><td align="left">可能包含任意顺序的字节数据。</td><td align="left">string</td></tr></tbody></table><ul><li>其他复合类型的定义方式：</li></ul><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs protobuf">syntax = <span class="hljs-string">&quot;proto3&quot;</span>;<span class="hljs-comment">//指定版本信息，不指定会报错</span><br><br><span class="hljs-comment">// 枚举：</span><br><span class="hljs-keyword">enum </span><span class="hljs-title class_">PhoneType</span> <span class="hljs-comment">//枚举消息类型，使用enum关键词定义,一个电话类型的枚举类型</span><br>&#123;<br>    MOBILE = <span class="hljs-number">0</span>; <span class="hljs-comment">//proto3版本中，首成员必须为0，成员不应有相同的值</span><br>    HOME = <span class="hljs-number">1</span>;<br>    WORK = <span class="hljs-number">2</span>;<br>&#125;<br><br><span class="hljs-keyword">message </span><span class="hljs-title class_">PhoneNumber</span><br>&#123;<br>    <span class="hljs-type">string</span> number = <span class="hljs-number">1</span>; <span class="hljs-comment">// 电话号码字段</span><br>    PhoneType type = <span class="hljs-number">2</span>; <span class="hljs-comment">// 电话类型字段，电话类型使用PhoneType枚举类型</span><br>&#125;<br><br><br><span class="hljs-comment">// 数组：</span><br><span class="hljs-keyword">message </span><span class="hljs-title class_">Msg</span> &#123;<br>  <span class="hljs-comment">// 只要使用repeated标记类型定义，就表示数组类型。</span><br>  <span class="hljs-keyword">repeated</span> <span class="hljs-type">int32</span> arrays = <span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">repeated</span> <span class="hljs-type">string</span> names = <span class="hljs-number">2</span>;<br>&#125;<br><br><br><span class="hljs-comment">// map:</span><br>syntax = <span class="hljs-string">&quot;proto3&quot;</span>;<br><span class="hljs-keyword">message </span><span class="hljs-title class_">Product</span><br>&#123;<br>    <span class="hljs-type">string</span> name = <span class="hljs-number">1</span>; <span class="hljs-comment">// 商品名</span><br>    <span class="hljs-comment">// 定义一个k/v类型，key是string类型，value也是string类型</span><br>    map&lt;<span class="hljs-type">string</span>, <span class="hljs-type">string</span>&gt; attrs = <span class="hljs-number">2</span>; <span class="hljs-comment">// 商品属性，键值对</span><br>&#125;<br></code></pre></td></tr></table></figure><ul><li>还有一种是消息嵌套的定义方式，可以引用别的消息结构用于定义自己。也可以直接嵌套定义在自己内部</li></ul><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-comment">// 1.引用其他消息类型的用法</span><br><span class="hljs-comment">// 定义Result消息</span><br><span class="hljs-keyword">message </span><span class="hljs-title class_">Result</span> &#123;<br>  <span class="hljs-type">string</span> url = <span class="hljs-number">1</span>;<br>  <span class="hljs-type">string</span> title = <span class="hljs-number">2</span>;<br>  <span class="hljs-keyword">repeated</span> <span class="hljs-type">string</span> snippets = <span class="hljs-number">3</span>; <span class="hljs-comment">// 字符串数组类型</span><br>&#125;<br><br><span class="hljs-comment">// 定义SearchResponse消息</span><br><span class="hljs-keyword">message </span><span class="hljs-title class_">SearchResponse</span> &#123;<br>  <span class="hljs-comment">// 引用上面定义的Result消息类型，作为results字段的类型，这里就算是定义在别的文件中也是可以通过import导入的</span><br>  <span class="hljs-keyword">repeated</span> Result results = <span class="hljs-number">1</span>; <span class="hljs-comment">// repeated关键词标记，说明results字段是一个数组</span><br>&#125;<br><br><span class="hljs-comment">// 2.消息嵌套</span><br><span class="hljs-keyword">message </span><span class="hljs-title class_">SearchResponse</span> &#123;<br>  <span class="hljs-comment">// 嵌套消息定义</span><br>  <span class="hljs-keyword">message </span><span class="hljs-title class_">Result</span> &#123;<br>    <span class="hljs-type">string</span> url = <span class="hljs-number">1</span>;<br>    <span class="hljs-type">string</span> title = <span class="hljs-number">2</span>;<br>    <span class="hljs-keyword">repeated</span> <span class="hljs-type">string</span> snippets = <span class="hljs-number">3</span>;<br>  &#125;<br>  <span class="hljs-comment">// 引用嵌套的消息定义</span><br>  <span class="hljs-keyword">repeated</span> Result results = <span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-3-3-代码生成"><a href="#2-3-3-代码生成" class="headerlink" title="2.3.3 代码生成"></a>2.3.3 代码生成</h3><ul><li>这一步就是按照我们的定义规则生成对应的代码，以便项目使用，通过<code>protoc</code>程序完成代码生成</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">// $SRC_DIR: .proto 所在的源目录<br>// --cpp_out: 生成 c++ 代码<br>// $DST_DIR: 生成代码的目标目录<br>// xxx.proto: 要针对哪个 proto 文件生成接口代码<br> <br>protoc -I=$SRC_DIR --cpp_out=$DST_DIR $SRC_DIR/xxx.proto<br> <br>protoc ./person.proto --cpp_out=./<br></code></pre></td></tr></table></figure><ul><li>编译完成之后会生成<code>xxx.pb.h</code>，<code>xxx.pb.cpp</code>两个文件，项目中通过引入这些生成的源文件来对数据进行序列化和反序列化。</li></ul><h3 id="2-3-4-库函数使用"><a href="#2-3-4-库函数使用" class="headerlink" title="2.3.4 库函数使用"></a>2.3.4 库函数使用</h3><ul><li>关于用户自定义消息的各种操作是通过protobuf库函数对外提供支持的，比如封装数据流读取到对象，将对象输出到流、字符串等。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++">Person p;<br>p.<span class="hljs-built_in">set_name</span>(<span class="hljs-string">&quot;test&quot;</span>);<br>p.<span class="hljs-built_in">set_id</span>(<span class="hljs-number">100</span>);<br>p.<span class="hljs-built_in">set_email</span>(<span class="hljs-string">&quot;a.iabc.com&quot;</span>);<br><br><span class="hljs-comment">// 将p文本信息写入文件</span><br><span class="hljs-keyword">auto</span> *output = <span class="hljs-keyword">new</span> google::protobuf::io::<span class="hljs-built_in">OstreamOutputStream</span>(&amp;fw);<br>google::protobuf::TextFormat::<span class="hljs-built_in">Print</span>(p, output);<br><span class="hljs-comment">// 将p文本信息保存到字符串</span><br>std::string str1;<br>google::protobuf::TextFormat::<span class="hljs-built_in">PrintToString</span>(p, &amp;str1);<br><br><span class="hljs-comment">// 将p的二进制信息保存到字符串，序列化</span><br>std::string str;<br>p.<span class="hljs-built_in">SerializeToString</span>(&amp;str);<br><span class="hljs-comment">// 将二进制数据转换到对象p1中，反序列化</span><br>Person p1;<br>p1.<span class="hljs-built_in">ParseFromString</span>(str);<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>RPC</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PhxRPC</tag>
      
      <tag>Protobuf</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Raft</title>
    <link href="/2024/05/12/Raft/"/>
    <url>/2024/05/12/Raft/</url>
    
    <content type="html"><![CDATA[<blockquote><p>参考资料：</p><p>Raft论文 <a href="/Raft/raft.pdf"><em>In search of an understandable consensus algorithm.</em></a></p><p><a href="/Raft/CONSENSUS-BRIDGING.pdf"><em>Consensus: bridging theory and practice</em></a></p><p><a href="https://zhuanlan.zhihu.com/p/27207160">Raft协议详解</a></p><p><a href="https://www.thebyte.com.cn/consensus/raft-ConfChange.html">深入架构原理与实践:成员变更问题</a></p><p><a href="https://zhuanlan.zhihu.com/p/375059508">浅谈Raft配置变更(成员变更)策略</a></p></blockquote><h1 id="一、Raft基础"><a href="#一、Raft基础" class="headerlink" title="一、Raft基础"></a>一、Raft基础</h1><ul><li><code>Raft</code>集群包含若干个服务器节点都处于这三个状态之一：领导人(<code>Leader</code>)、跟随者(<code>Follower</code>)、候选人(<code>Candidate</code>)。<ol><li><code>Leader</code>：所有请求的处理者，其实就是整个Raft集群和外部进行沟通的接口。<code>Leader</code>接收<code>client</code>的更新请求，本地处理后再同步至多个其他副本；</li><li><code>Follower</code>：请求的被动更新者，从<code>Leader</code>接收更新请求，然后写入本地日志文件；</li><li><code>Candidate</code>：如果<code>Follower</code>副本在一段时间内没有收到<code>Leader</code>的心跳，则判断<code>Leader</code>可能已经发生故障，此时启动<code>Leader election</code>，<code>Follower</code>副本会变成<code>Candidate</code>状态，直至选主结束。</li></ol></li></ul><div style="text-align:center;">    <img src="raft状态变更图.png" alt="raft状态变更图.png" width="437" height="188" class="jop-noMdConv"></div><ul><li>时间被划分成一个个的<strong>任期</strong>，每个任期开始都是一次选举。在选举成功后， 领导人会管理整个集群直到任期结束。有时候选举会失败，那么这个任期就会以没有领导人而结束。任期之间的切换可以在不同的服务器上观察到。<code>Raft</code>保证了在一个给定的任期内，最多只有一个领导者。</li><li><code>Raft</code>算法中server节点之间通信使用远程过程调用(<code>RPCs</code>)，并且基本的一致性算法只需要两种类型的<code>RPCs</code>。请求投票<code>RequestVote RPCs</code>由候选人在选举期间发起，然后附件条目<code>AppendEntries RPCs</code>由领导人发起，用来复制日志和提供一种心跳机制。后面为了在<code>server</code>之间传输<code>snapshot</code>增加了第三种<code>RPC</code>。</li></ul><h1 id="二、领导人选举"><a href="#二、领导人选举" class="headerlink" title="二、领导人选举"></a>二、领导人选举</h1><h2 id="2-1-触发选举"><a href="#2-1-触发选举" class="headerlink" title="2.1 触发选举"></a>2.1 触发选举</h2><ul><li><code>Raft</code>使用一种心跳机制来触发领导人选举。</li><li>当服务器程序启动时，他们都是<code>Follower</code>角色。一个<code>server</code>节点继续保持着<code>Follower</code>状态只要它从<code>Leader</code>或者<code>Candidate</code>处接收到有效的<code>RPCs</code>。<code>Leader</code>周期性的向所有<code>Follower</code>发送心跳包(其实就是不包含日志项内容的<code>AppendEntries RPCs</code>)来维持自己的领导权威。</li><li>如果一个<code>Follower</code>在一段时间内没有接收到任何消息，也就是发生了<code>timeout</code>，那么他就会认为系统中没有<code>Leader</code>，因此自己就会进入<code>Candidate</code>状态，并发起选举以选出新的<code>Leader</code>。</li></ul><h2 id="2-2-选举过程"><a href="#2-2-选举过程" class="headerlink" title="2.2 选举过程"></a>2.2 选举过程</h2><ul><li>要开始一次选举过程，<code>Follower</code>先要增加自己的<code>current_term_id</code>并转换到<code>Candidate</code>状态。然后它会并行的向集群中的其他服务器节点发送<code>RequestVote RPC</code>来给自己投票。<code>Candidate</code>会继续保持当前状态直到以下三种情况出现：</li></ul><p><strong>1. 自己赢得选举</strong></p><ul><li>当收到了大多数节点(<code>majority</code>)的选票后，角色状态会转换为<code>Leader</code>，之后会定期给其它所有<code>server</code>发心跳信息（不带<code>log entry</code>的<code>AppendEntries RPC</code>），用来告诉对方自己是当前<code>term</code>（<code>RequestVote RPC</code>附带的<code>current_term_id</code>）的<code>Leader</code>。</li><li>每个<code>term</code>最多只有一个<code>Leader</code>，<code>term id</code>作为<code>logical clock</code>，在每个RPC消息中都会带上，用于检测过期的消息。当一个<code>server</code>收到的<code>RPC</code>消息中的<code>rpc_term_id</code>比本地的<code>current_term_id</code>更大时，就更新<code>current_term_id</code>为<code>rpc_term_id</code>，并且如果当前节点的角色状态为<code>Leader</code>或者<code>Candidate</code>时，也会将自己的状态切换为<code>Follower</code>。如果<code>rpc_term_id</code>比接收节点本地的<code>current_term_id</code>更小，那么<code>RPC</code>消息就被会拒绝。</li></ul><p><strong>2. 别人赢得选举</strong></p><ul><li>当<code>Candidate</code>在等待投票的过程中，收到了<code>rpc_term_id</code>大于或者等于本地的<code>current_term_id</code>的<code>AppendEntries RPC</code>消息时，并且这个<code>RPC</code>消息声明自己是这个任期内的<code>Leader</code>。那么收到消息的节点将自己的角色状态转换为<code>Follower</code>，并且更新本地的<code>current_term_id</code>。</li></ul><p><strong>3. 无人赢得选举</strong></p><ul><li>第三种可能的结果是<code>Candidate</code>既没有赢得选举也没有输，本轮选举没有选出<code>Leader</code>，这说明投票被瓜分了。没有任何一个<code>Candidate</code>收到了<code>majority</code>的投票时，<code>Leader</code>就无法被选出。这种情况下，每个<code>Candidate</code>等待的投票的过程就出现<code>timeout</code>，随后<code>Candidates</code>都会将本地的<code>current_term_id</code>自增“1”，再次发起<code>RequestVote RPC</code>进行新一轮的<code>leader election</code>。</li></ul><h2 id="2-3-投票策略"><a href="#2-3-投票策略" class="headerlink" title="2.3 投票策略"></a>2.3 投票策略</h2><ul><li>每个节点只会对每个<code>term_id</code>中的一个<code>RequestVote RPC</code>进行相应，对每个投票请求是否进行投票需要根据日志长度比较来决定，和后续的Safety有关，除此之外就是对先来的请求投票。</li><li>当投票被瓜分后，所有的<code>Candidate</code>同时超时，然后有可能进入新一轮的票数被瓜分，为了避免这个问题，<code>Raft</code>采用一种很简单的方法：每个<code>Candidate</code>的<code>election timeout</code>从150ms-300ms之间随机取，那么第一个超时的<code>Candidate</code>就可以发起新一轮的<code>leader election</code>，带着最大的<code>term_id</code>给其它所有<code>server</code>发送<code>RequestVote RPC</code>消息，从而自己成为<code>Leader</code>。</li></ul><h1 id="三、日志复制"><a href="#三、日志复制" class="headerlink" title="三、日志复制"></a>三、日志复制</h1><h2 id="3-1-正常日志复制"><a href="#3-1-正常日志复制" class="headerlink" title="3.1 正常日志复制"></a>3.1 正常日志复制</h2><ul><li>当<code>Leader</code>被选出来后，就可以接受客户端发来的请求了，每个请求包含一条需要被<code>replicated state machines</code>执行的命令。<code>Leader</code>会把它作为一个<code>log entry</code>追加到日志中，然后给其它的<code>server</code>发<code>AppendEntries RPC</code>请求。</li><li>当<code>Leader</code>确定一个<code>log entry</code>被<code>safely replicated</code>了（即大多数节点已经将该命令写入日志），就<code>apply</code>这条<code>log entry</code>到状态机中然后返回结果给客户端。如果某个<code>Follower</code>宕机了或者运行的很慢，或者网络丢包了，则会一直给这个<code>Follower</code>发<code>AppendEntries RPC</code>直到日志一致。</li><li>当一条日志是<code>commited</code>时，<code>Leader</code>才可以将它应用到状态机中。<code>Raft</code>保证一条<code>commited</code>的<code>log entry</code>已经持久化了并且会被所有的节点执行。</li></ul><h2 id="3-2-日志恢复"><a href="#3-2-日志恢复" class="headerlink" title="3.2 日志恢复"></a>3.2 日志恢复</h2><ul><li>当一个新的<code>Leader</code>被选出来时，它的日志和其它的<code>Follower</code>的日志可能不一样，这个时候，就需要一个机制来保证日志的一致性。</li><li>新<code>Leader</code>产生后，就以<code>Leader</code>上的<code>log</code>为准（当然这里保证了新<code>Leader</code>包含了所有已经提交的日志，这是通过<code>Safety</code>保证的）。对于其他的<code>Follower</code>，缺失数据、多无效日志、即缺失有多无效日志都是可能的。我们需要一定的机制让所有的<code>Follower</code>的日志和<code>Leader</code>保持一致。</li><li><code>Leader</code>会为每个<code>Follower</code>维护一个<code>nextIndex</code>，表示<code>Leader</code>给各个<code>Follower</code>发送的下一条<code>log entry</code>在<code>log</code>中的<code>index</code>，初始化为<code>Leader</code>的最后一条<code>log entry</code>的下一个位置。<code>Leader</code>给<code>Follower</code>发送<code>AppendEntries RPC</code>消息，附带<code>(term_id, nextIndex-1)</code>，表明这个<code>AppendEntries RPC</code>中的<code>log</code>是哪个位置的日志。</li><li><code>Follower</code>接收到<code>AppendEntries RPC</code>后，会和自己的日志中对应位置的日志进行对比。如果不存在这样的<code>log entry</code>或者不相等，就给<code>Leader</code>回复拒绝消息，然后<code>Leader</code>则将<code>nextIndex</code>减“1”，再重复直到<code>AppendEntries RPC</code>消息被接收。</li></ul><h1 id="四、安全性"><a href="#四、安全性" class="headerlink" title="四、安全性"></a>四、安全性</h1><h2 id="4-1-选举限制"><a href="#4-1-选举限制" class="headerlink" title="4.1 选举限制"></a>4.1 选举限制</h2><ul><li><p>为了达到选择出的<code>Leader</code>节点必须拥有所有已经提交的日志项的目的，<code>Raft</code>给出的方案是比较日志。如果<code>Candidate</code>的日志至少跟过半的服务器节点一样新，那么它就一定包含了所有已经提交的日志条目，一旦有<code>Follower</code>发现自己的日志比<code>Candidate</code>的还新，那么就会拒绝该投票请求，该<code>Candidate</code>也就不会赢得选举。这里对日志的“新”做一个定义:</p><ul><li>如果两份日志最后条目的任期号不同，那么任期号大的日志更新。</li><li>如果两份日志最后条目的任期号相同，那么谁的日志更长，谁就更新。</li></ul></li><li><p>通过比较日志的“新”选出的<code>Leader</code>一定拥有着一个大多数集群中最新的日志。一个日志只有被 成功添加到了大多数节点中才有可能被提交，而选举的限制保证了所选出的<code>Leader</code>拥有一个大多数集群中最新的日志，因此<code>Leader</code>一定包含了已提交的日志。尽管非大多数的节点也有可能拥有比<code>Leader</code>还“新”的日志，但是这部分日志是没有被提交过的，被删除掉并不会影响正确性。</p></li></ul><h2 id="4-2-日志提交限制"><a href="#4-2-日志提交限制" class="headerlink" title="4.2 日志提交限制"></a>4.2 日志提交限制</h2><h3 id="4-2-1-提交日志"><a href="#4-2-1-提交日志" class="headerlink" title="4.2.1 提交日志"></a>4.2.1 提交日志</h3><ul><li>关于日志提交的问题，我们通常认为只要某一条日志已经被集群的大多数节点所复制了，那就可以提交了。这里的提交包含两层意思：第一层是可以将提交的结果返回给上层应用；第二层是将提交的信息发送给<code>Follower</code>。</li><li>作者在设计<code>Raft</code>时为了尽可能使协议足够简单易懂，将很多消息发送都进行了合并和简化。所以<code>Commit</code>的消息只需要附带到下一次的<code>AppendEntries RPCs</code>（心跳包）就可以了，这避免了消息的冗余。</li><li>但是<strong>“大多数节点复制的日志就可以提交。”</strong> 的结论是存在漏洞的，冲突来源于<code>Leader</code>节点切换时对前面任期的日志进行提交的处理上。</li></ul><h3 id="4-2-2-经典问题分析"><a href="#4-2-2-经典问题分析" class="headerlink" title="4.2.2 经典问题分析"></a>4.2.2 经典问题分析</h3><ul><li><code>Raft</code>原文中给出了一个经典例子，将会以此为例分析Raft关于提交之前任期内的日志条目的解决方案：</li></ul><div style="text-align:center;">    <img src="日志提交问题.png" alt="日志提交问题.png" width="428" height="189" class="jop-noMdConv"></div><ul><li>在图(a)中，<code>Leader</code>节点为<code>S1</code>，任期为2。在 <code>log index = 2</code> 的日志还没有被添加到大多数节点日志中时开始了新一轮的任期。</li><li>在图(b)中，<code>S5</code>获得了<code>S3</code>和<code>S4</code>的投票当选<code>Leader</code>，任期为3。这时对于<code>S5</code>来说，其 <code>log index = 2</code> 的位置并没有日志项，所以其新添加的日志会被放着这个位置。但是因为一些意外<code>S5</code>只完成了对自己日志的更新便又开始了新一轮的任期。</li><li>在图(c)中，S1获得了<code>S2</code>和<code>S3</code>的投票当选<code>Leader</code>，任期为4。然后S1将复制它之前在任期2中放在<code>log index = 2</code>的日志项到其余的<code>Follower</code>中。这时那条日志已经被复制到过半的节点中了。</li><li>情况一：在图(d)中，由于<code>S5</code>最后的日志项的任期号大于<code>S2</code>、<code>S3</code>、<code>S4</code>，因此<code>S5</code>可以被成功选举为<code>Leader</code>，任期为5。<code>S5</code>在当选之后会将自己在<code>log index = 2</code>的日志项同步到<code>Follower</code>节点，如果在上一个任期中，<code>S1</code>将<code>log index = 2</code>的日志项提交了，就会造成已提交日志丢失的问题</li><li>情况二：在图(e)中，在任期4时，如果<code>S1</code>节点在自己的任期内复制了日志项到大多数机器上。那么到下一个任期<code>S5</code>就不可能成为<code>Leader</code>了，这种情况下通过提交任期4的日志，根据日志匹配特性也可以保证同时提交之前任期的日志。</li></ul><h3 id="4-2-3-日志提交方案"><a href="#4-2-3-日志提交方案" class="headerlink" title="4.2.3 日志提交方案"></a>4.2.3 日志提交方案</h3><ul><li>所以<code>Raft</code>关于前任期内的日志条目的提交方法已经呼之欲出了，<code>Raft</code>永远不会通过计算副本数目的方式来提交之前任期内的日志条目。</li><li>只有<code>Leader</code>当期内的日志条目才通过计算副本数目的方式来提交。一旦当前任期内的某个日志条目以这种方式被提交，那么由于日志匹配特性，之前的所有日志条目也会被间接地提交。</li></ul><h1 id="五、拓扑变更"><a href="#五、拓扑变更" class="headerlink" title="五、拓扑变更"></a>五、拓扑变更</h1><h2 id="5-1-问题分析"><a href="#5-1-问题分析" class="headerlink" title="5.1 问题分析"></a>5.1 问题分析</h2><ul><li>在实际场景中，我们会遇到很多改变集群节点数的情况，例如服务器故障需要移除副本、集群扩容增加副本等等。为了让所有成员在同一时刻都能获取到更新后的集群配置，选择集群停机后再更新配置是最简单的方案，但在一个致力于解决分布式可用性的容错系统中，用影响可用性的方式解决成员变更问题显然不可接受。</li><li>集群配置的变更本质上也是将一个消息同步到所有节点上，自然可以把配置当成 <code>raft</code> 中的日志，成员动态变更的需求就演化成了<strong>配置日志一致性问题</strong>。</li><li>但成员变更存在一个特殊性，集群成员的动态变更导致多数派的数量也随之变化。如果处理方式不当，可能会导致两个多数派（变更前的多数派 $C_{old}$（旧配置）和变更的多数派$C_{new}$（新配置））之间不存在相交的成员，这样就产生两个<code>Leader</code>在各自认为的“多数派”中工作的问题。</li></ul><div style="text-align:center;">    <img src="拓扑变更.png" alt="拓扑变更.png" width="283" height="200" class="jop-noMdConv"></div><ul><li><p>配置的变更显然是无法原子完成的，而变更配置需要一个过程。如上图所示，3 个节点的集群扩展到 5 个节点，在某个时刻只有3个节点变更配置完成，另外2个节点还处于原配置状态。这会造成 <code>Server1</code> 和 <code>Server2</code> 构成老成员配置的多数派，<code>Server3</code>、<code>Server4</code> 和 <code>Server5</code> 构成新成员配置的多数派。因为这两个多数派不存在相交的成员，所以有可能在一个日志索引上会提交两个不同的日志项，从而导致协议冲突，影响 <code>Raft</code> 的安全性。</p></li><li><p>原论文中提出了一种两阶段的成员变更方法 <strong>Joint Consensus</strong>（联合共识）。大致是维护一个变更中的状态，在这个状态中开展新的选举，已经获得新配置的节点需要同时获得 $C_{old}$和$C_{new}$中的大多数投票才能当选，中间状态完成后再转变成$C_{new}$的最终配置。这种方式实现起来很复杂。</p></li><li><p>后来提出一种更简单的方案 <strong>Single Server Changes</strong>（单成员变更），单成员变更的思路是既然同时提交多个会存在问题，那每次就提交一个成员变更，这样旧配置的“多数派”和新配置的多数派就始终会有一个节点重叠，这样就不存在不相交的问题了，如果有要添加多个成员，那就执行多次单成员变更。</p></li></ul><h2 id="5-2-联合共识"><a href="#5-2-联合共识" class="headerlink" title="5.2 联合共识"></a>5.2 联合共识</h2><h3 id="5-2-1-基本流程"><a href="#5-2-1-基本流程" class="headerlink" title="5.2.1 基本流程"></a>5.2.1 基本流程</h3><div style="text-align:center;">    <img src="联合共识.png" alt="联合共识.png" width="318" height="155" class="jop-noMdConv"></div><ul><li>配置变更为两阶段实现，第一阶段集群先从旧成员配置$C_{old}$切换到一个过渡成员配置$C_{old} \cup C_{new}$，这个中间状态被称为联合共识；第二阶段集群再从过渡成员配置切换到新成员配置$C_{new}$。<code>Raft</code>协议的两阶段成员变更过程如下：<ol><li><code>Leader</code>收到成员变更请求从$C_{old}$切换成$C_{new}$；</li><li><code>Leader</code>在本地节点生成一个新的<code>log entry</code>，内容为$C_{old} \cup C_{new}$，代表当前时刻新旧拓扑配置共存，写入本地日志，同时将该<code>log entry</code>推送至其他<code>Follower</code>节点。在此之后新的日志同步需要保证得到$C_{old}$和$C_{new}$两个多数派的确认；</li><li><code>Follower</code>节点收到<code>log entry</code>后更新本地日志，并且此时就以该配置作为自己认知的全局拓扑结构；</li><li>如果$C_{old}$和$C_{new}$中的两个<code>majority</code>的<code>Follower</code>节点确认了$C_{old} \cup C_{new}$这条日志的时候，<code>Leader</code>就提交这条<code>log entry</code>；（注意这里要求的是两个大多数集合都确认收到日志，这里应该是保证不会出现两个<code>Leader</code>的关键）</li><li>随后<code>Leader</code>会生成一条新的<code>log entry</code>，内容是全新的成员配置$C_{new}$，同样将这条<code>log entry</code>写入本地节点日志，并同时推送到其他<code>Follower</code>节点上；</li><li><code>Follower</code>收到新的配置日志$C_{new}$后，将其写入日志，并且从当前时刻起，将$C_{new}$作为系统成员拓扑结构，并且如果发现自己不在$C_{new}$这个配置中会自动退出；</li><li><code>Leader</code>收到<code>majority</code>的<code>Follower</code>节点的确认消息后，给客户端发起命令执行成功的消息。后续的日志只要得到$C_{new}$多数派的确认即可。</li></ol></li></ul><h3 id="5-2-2-安全性分析"><a href="#5-2-2-安全性分析" class="headerlink" title="5.2.2 安全性分析"></a>5.2.2 安全性分析</h3><ul><li>首先需要明确，集群的配置更新过程会出现问题的核心是会在某一时刻存在两个<code>majority</code>，因此如果这时候发生选举，可能造成出现两个<code>Leader</code>的情况，会严重影响分布式集群的安全性。</li></ul><p><strong>为什么会出现两个合法的<code>majority</code>？</strong></p><ul><li>集群在变更过程中节点存在两种配置状态，即一部分节点为$C_{old}$状态，另一部分的节点为$C_{new}$。只要$C_{old}$中的少部分节点完成变更，并与新添加的节点可以构成$C_{new}$的<code>majority</code>，那么就可以同时存在两个合法的大多数集合了。</li><li>这里有两个破局点，一个是不让部分配置变更完成的节点能够成为合法的<code>majority</code>，方案就是添加联合共识的中间的态，对中间态节点达成共识添加更多的限制；还有一个是让新增节点不能与$C_{old}$中的少部分节点构成$C_{new}$​的<code>majority</code>，其实只要控制每次变更的节点数量就可以了，即下一节的单成员变更方案。</li></ul><p><strong>联合共识的中间的态是什么？</strong></p><ul><li>中间态或者过渡态即为$C_{old} \cup C_{new}$，处于这种配置的节点在选举或者提交数据时需要同时获得$C_{old}$和$C_{new}$两个<code>majority</code>的认可。先说选举上的问题，无论是$C_{old}$还是$C_{old} \cup C_{new}$配置的节点，想要成功当选<code>Leader</code>都是需要得到$C_{old}$的<code>majority</code>的投票，所以便避免出现两个<code>leader</code>了。</li><li>第二步是将$C_{old} \cup C_{new}$配置同步到<code>Follower</code>的日志中，并且得到大多数节点的回复后提交这条消息，然后开启下一阶段对$C_{new}$配置的同步。这里有一个细节，因为<code>Leader</code>节点必然是$C_{old} \cup C_{new}$配置，所以想要提交这个配置需要等待$C_{old}$和$C_{new}$两个<code>majority</code>的认可。这意味着提交$C_{old} \cup C_{new}$时，原$C_{old}$中的大多数节点必然已经进入中间态了，那么这时$C_{old}$配置的节点必然不可能当选新<code>Leader</code>了。</li><li>我们来考虑一下如果没有这条提交消息的限制会怎样。有<code>[server1, server2, server3]</code>三个原节点，然后添加两个新节点<code>[server4, server5]</code>。然后<code>[server3, server4, server5]</code>进入$C_{old} \cup C_{new}$配置，并且完成提交。这时候开始同步$C_{new}$配置，并且<code>[server3, server4, server5]</code>进入$C_{new}$，但是<code>[server1, server2]</code>依然保持在$C_{old}$，这是就可能出现$C_{old}$和$C_{new}$​两个<code>majority</code>形成的两个<code>Leader</code>节点了。</li></ul><h3 id="5-2-3-异常处理"><a href="#5-2-3-异常处理" class="headerlink" title="5.2.3 异常处理"></a>5.2.3 异常处理</h3><p><strong>追赶日志</strong></p><ul><li>新的服务器节点在初始化时没有存储任何的日志条目。当这些服务器节点以这种状态加入集群中，那么这些新加入的节点需要一定的时间来追赶日志，这段时间内还无法接收新的日志条目。</li><li>为了避免这种可用性的间隔时间，<code>Raft</code>在成员变更的时候使用了一种额外的阶段，在这个阶段，新的服务器节点以没有投票权的身份加入到集群中(<code>Leader</code>会复制日志给他们，但是不考虑他们是大多数)。一旦新的服务器节点追赶上了集群中的其他机器，就可以按照上面描述的做成员配置变更。</li></ul><p><strong>删除<code>Leader</code>节点</strong></p><ul><li>集群的<code>Leader</code>不是$C_{new}$中的一员。在这种情况下，<code>Leader</code>会在提交了$C_{new}$日志之后退出，回到<code>Follower</code>状态。因此会有一段时间<code>Leader</code>管理着集群，但是并不在集群成员范围内。<code>Leader</code>复制日志但是不把他自己算作大多数之一。当$C_{new}$被提交之后，会发生<code>Leader</code>过渡，因为$C_{new}$提交之后，最新的集群成员配置就可以正常独立工作了，此时会在$C_{new}$范围内选出新的<code>Leader</code>。在此之前，<code>Leader</code>都是从$C_{new}$范围内选举<code>Leader</code>。</li></ul><h2 id="5-3-单成员变更"><a href="#5-3-单成员变更" class="headerlink" title="5.3 单成员变更"></a>5.3 单成员变更</h2><div style="text-align:center;">    <img src="单节点变更.png" alt="单节点变更.png" width="388" height="157" class="jop-noMdConv"></div><h3 id="5-3-1-安全分析"><a href="#5-3-1-安全分析" class="headerlink" title="5.3.1 安全分析"></a>5.3.1 安全分析</h3><ul><li>配置变更的思路是相同的，通过日志提交的方式利用自身的共识机制实现配置的变更。但单成员的变更就不需要添加额外的限制了，上图给出了奇偶节点数新增和减少一个节点时候的四种情况，可以发现必然是存在交集的。</li><li>这里一定要注意新增或者被删除的那个节点是知道变更之后的配置情况的（不存在形成两个$C_{old}$的<code>majority</code>的情况），因此要同时形成$C_{old}$和$C_{new}$​两个<code>majority</code>的节点数量一定会超过集群节点总数，所以单节点的变更是绝对安全的。</li></ul><h3 id="5-3-2-连续变更"><a href="#5-3-2-连续变更" class="headerlink" title="5.3.2 连续变更"></a>5.3.2 连续变更</h3><p><strong>连续增加</strong></p><ul><li>如果对于一个节点数量为3的集群，我们想要新增两个节点，第一步按照要求进行配置变更日志的共识和提交，此时集群可能会变为<code>[server1, server2, server4]</code>进入$C_{new}$，<code>[server3]</code>保持$C_{old}$；第二步是继续新增节点，而时机上只要上一条变更配置的日志被提交就可以立刻开始下一条配置变更的共识。</li><li>此时新进入的<code>[server5]</code>是具有最新配置的，那么可以组成大多数集<code>[server1, server2, server5]</code>。此时剩余的<code>[server3, server4]</code>前者停留在3节点，后者停留在4节点，因为<code>[server4]</code>是已经提交第一轮配置变更的节点，因而他一定能在两者的选举中胜出。此时的<code>[server3, server4]</code>则不可能可以形成<code>majority</code>。</li></ul><p><strong>连续删除</strong></p><ul><li>连续删除是类似的道理，对于原来节点数量为5的集群<code>[server1, server2, server3, server4, server5]</code>，我们希望删除两个节点<code>[server1, server2]</code>，第一步是<code>[server3, server4, server5]</code>三个节点达成共识，要删除<code>[server1]</code>，此时的<code>[server1]</code>因为暂时丢失没有被真正删除。</li><li>然后开始继续删除<code>[server2]</code>，如果<code>[server4, server5]</code>完成了删除操作，那么接下来发生选举时这两个节点自己就能形成<code>majority</code>。剩下的<code>[server1, server2, server3]</code>分别认为集群中还存在5，5，4个节点，那么剩下的这三个节点就能形成大多数集吗？</li><li>要注意<code>[server3]</code>是有第一次的删除记录的，所以首先他会有选举的优先权，而他是知道<code>[server1]</code>在第一轮被删除过的，所以即使这里有三个节点，依然是不能形成<code>majority</code>的。</li></ul><p><strong>增删混合</strong></p><ul><li>当想要替换某个节点的时候可能会发生这种场景，考虑3节点的集群替换其中的一个节点。如果是先删除后新增，场景分析和连续删除非常相似；如果是先新增后删除，场景分析和连续新增非常相似。</li><li>个人理解，单节点变更的方法其实就是利用将配置变更拆成多次进行提交，而这些中间的提交状态其实就是多节点变更的联合共识状态，只不过实现起来简单了很多。</li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Raft</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux:文件IO</title>
    <link href="/2024/05/12/Linux-%E6%96%87%E4%BB%B6IO/"/>
    <url>/2024/05/12/Linux-%E6%96%87%E4%BB%B6IO/</url>
    
    <content type="html"><![CDATA[<h1 id="一、I-O"><a href="#一、I-O" class="headerlink" title="一、I&#x2F;O"></a>一、I&#x2F;O</h1><p><strong>同步&#x2F;异步</strong></p><ul><li><p>同步、异步强调的是消息的通信机制（同步通信&#x2F;异步通信）</p><ul><li><p>同步，就是在发出一个”调用”时，在没有得到结果之前，该“调用”就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由“调用者”主动等待这个“调用”的结果。</p></li><li><p>异步则是相反，”调用”在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在”调用”发出后，”被调用者”通过状态、通知来通知调用者，或通过回调函数处理这个调用。</p></li></ul></li></ul><p><strong>阻塞&#x2F;非阻塞</strong></p><ul><li><p>阻塞、非阻塞强调的是程序在等待调用结果（消息，返回值）时的状态</p><ul><li><p>阻塞调用是指调用结果返回之前，当前线程会被挂起，一直处于等待消息通知，不能够执行其他业务</p></li><li><p>非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程</p></li></ul></li></ul><p><strong>五种IO模型</strong></p><div style="text-align:center;">    <img src="io.webp" alt="输入图片描述" width="522" height="334" class="jop-noMdConv"></div><p><strong>同步阻塞IO blocking IO</strong></p><ul><li><p>首先采用主动等待调用返回的这种方式；然后在等待期间，需要将进程阻塞</p></li><li><p>在等待数据到处理数据的两个阶段，整个进程都是被阻塞的</p></li></ul><p><strong>同步非阻塞IO nonblocking IO</strong></p><ul><li><p>依然是主动等待调用返回的方式，但是这里不再是通过阻塞的方式来等待调用函数的返回，而是调用函数直接返回，但是这里返回的是一个<code>error</code>，进程需要不断调用这个函数来查看运行情况</p></li><li><p>这样的过程通常被称为<strong>轮询</strong>，轮询检查内核数据，直到数据准备好，再拷贝数据到进程，进行数据处理。</p></li><li><p>但是这里只是轮询等待数据准备好，将数据拷贝到用户进程依然是通过阻塞的方式来进行的（这里需要重点注意，数据传送过程依然是阻塞的）</p></li></ul><p><strong>IO多路复用 IO multiplexing</strong></p><ul><li>其实是同步非阻塞IO的升级版，通过把多个I&#x2F;O的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求，可以等待多个socket，能实现同时对多个IO端口进行监听</li></ul><p><strong>信号驱动式IO signal-driven IO</strong></p><ul><li><p>安装一个信号处理函数，在信号处理函数中调用IO操作函数处理数据</p></li><li><p>但是在数据拷贝的阶段依然是采用的阻塞的方式</p></li></ul><p><strong>异步非阻塞IO asynchronous IO</strong></p><ul><li><p>无论是等待数据阶段，还是数据拷贝阶段都是采用非阻塞式的方法</p></li><li><p>内核准备好数据之后，会发送一个signal或执行一个基于线程的回调函数来完成这次 IO 处理过程，告诉进程read操作完成了</p></li></ul><h2 id="1-1-阻塞-非阻塞I-O"><a href="#1-1-阻塞-非阻塞I-O" class="headerlink" title="1.1 阻塞&#x2F;非阻塞I&#x2F;O"></a>1.1 阻塞&#x2F;非阻塞I&#x2F;O</h2><h3 id="1-1-1-read-write"><a href="#1-1-1-read-write" class="headerlink" title="1.1.1 read&#x2F;write"></a>1.1.1 read&#x2F;write</h3><ul><li><p>由Linux操作系统直接提供的基础IO方式是<code>read/write</code>两个系统调用接口，默认状态下这两个接口都是阻塞方式的。如果在打开文件的时候配置了<code>O_NONBLOCK</code>参数，这个文件描述符的<code>read/write</code>将变成非阻塞方式，调用之后会立刻返回。</p></li><li><p>读数据时，需要提供一段用户空间的空闲内存，然后进入内核态进行文件读取，先检查内核的缓冲区有没有需要的数据，如果已经缓存了，那么就直接从缓存中返回；否则从磁盘中读取，然后缓存在内核的缓存中。</p></li><li><p>写操作时，将数据从用户空间复制到内核空间的缓存中，这时对用户程序来说写操作就已经完成，至于什么时候再写到磁盘中由操作系统决定，除非显示地调用了sync同步命令。</p></li><li><p>在内核中用来缓存从磁盘读出的数据或者写入数据的是PageCache：</p><ul><li><p>PageCache提供预读功能来加快磁盘访问的性能；</p></li><li><p>同时内核的 I&#x2F;O 调度算法会缓存尽可能多的 I&#x2F;O 请求在 PageCache 中，最后「<strong>合并</strong>」成一个更大的 I&#x2F;O 请求再发给磁盘，这样做是为了减少磁盘的寻址操作；</p></li></ul></li></ul><h3 id="1-1-2-fread-fwrite"><a href="#1-1-2-fread-fwrite" class="headerlink" title="1.1.2 fread&#x2F;fwrite"></a>1.1.2 fread&#x2F;fwrite</h3><ul><li><p>这个是C标准库中提供的文件接口，对<code>read/write</code>的进一步封装，在用户空间中又分配了一块内存用于缓冲用户的读写调用。</p></li><li><p>相较于每次都是系统调用的<code>read/write</code>，<code>fread/fwrite</code>可以先将用户的请求缓存到用户态下。然后收集到一部分的请求之后统一调用一次<code>read/write</code>系统调用，从而降低系统调用切换用户态和内核态带来的开销。</p></li><li><p>如果使用了<code>fread/fwrite</code>写入操作可能被缓存在用户态，如果进程崩溃也有可能造成数据的丢失；但使用<code>read/write</code>的程序因为写入数据被直接写入到内核态，及时进程崩溃内核中依然可以保留以写入的数据。</p></li></ul><h3 id="1-1-3-direct-I-O"><a href="#1-1-3-direct-I-O" class="headerlink" title="1.1.3 direct I&#x2F;O"></a>1.1.3 direct I&#x2F;O</h3><ul><li><p>如果在打开文件的时候配置了<code>O_DIRECT</code>参数，这个文件将被打开用于直接I&#x2F;O</p></li><li><p>应用程序直接读写文件，而不经过内核缓冲区，也就是绕过内核缓冲区，自己管理IO缓存区，这样做的目的是减少一次内核缓冲区到用户程序缓存的数据复制。</p></li></ul><h3 id="1-1-4-mmap"><a href="#1-1-4-mmap" class="headerlink" title="1.1.4 mmap"></a>1.1.4 mmap</h3><ul><li><p>mmap 是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。</p></li><li><p>实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用 read、write 等系统调用函数。</p></li><li><p>在mmap之后，并没有在将文件内容加载到物理页上，只上在虚拟内存中分配了地址空间。当进程在访问这段地址时（通过mmap在写入或读取时），若虚拟内存对应的page没有在物理内存中缓存，则产生”缺页”，由内核的缺页异常处理程序处理，将文件对应内容，以页为单位(4K)加载到物理内存，注意是只加载缺页，但也会存在预读。</p></li><li><p>因此是通过“缺页”异常来读取硬盘数据的，所以本质来说这是个阻塞同步I&#x2F;O</p></li></ul><h2 id="1-2-多路复用I-O"><a href="#1-2-多路复用I-O" class="headerlink" title="1.2 多路复用I&#x2F;O"></a>1.2 多路复用I&#x2F;O</h2><ul><li>主要是用来处理网络socket读写的，让单线程可以同时处理多个socket连接的系统调用</li></ul><p><strong>问题</strong></p><ul><li><p>服务器可承载的最大连接数，主要会受两个方面的限制：</p><ul><li><p><strong>文件描述符</strong>，Socket 实际上是一个文件，也就会对应一个文件描述符。在 Linux 下，单个进程打开的文件描述符数是有限制的，没有经过修改的值一般都是 1024，不过我们可以通过 ulimit 增大文件描述符的数目；</p></li><li><p><strong>系统内存</strong>，每个 TCP 连接在内核中都有对应的数据结构，意味着每个连接都是会占用一定内存的，如果每个连接都需要绑定一个线程来处理，那应该很快就会触及资源上线。</p></li></ul></li><li><p>无论是单进程绑定一个socket还是单线程去绑定一个socket都是没法达到C10K的（并发1万请求），因此需要多路复用系统调用，单个进程&#x2F;线程可以通过一个系统调用函数从内核中获取多个事件。</p></li></ul><h3 id="1-2-1-select"><a href="#1-2-1-select" class="headerlink" title="1.2.1 select"></a>1.2.1 select</h3><ul><li><p>将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生。</p></li><li><p>文件描述符集合由fd_set表示（其实这是一个数组的宏定义，实际上是一long类型的数组，每一个数组元素都能与一打开的文件句柄socket、文件、管道、设备等建立联系），而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 <code>1024</code>，只能监听 0~1023 的文件描述符。</p></li><li><p>检查的方式很粗暴，就是遍历文件描述符集合，即轮询（内核来做这个轮询操作），效率较低。当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里。因此一次select的调用到返回需要两次copy文件描述符集合。</p></li><li><p>select返回之后，调用者仅知道有I&#x2F;O事件发生，却不知哪几个流，只会无差异轮询所有流，找出能读&#x2F;写数据的流进行操作。寻找可以读写的socket的时间复杂度是<code>O(n)</code>。</p></li></ul><h3 id="1-2-2-poll"><a href="#1-2-2-poll" class="headerlink" title="1.2.2 poll"></a>1.2.2 poll</h3><ul><li><p>和select类似，只是描述fd集合的方式不同，poll使用<code>pollfd</code>结构而非select的<code>fd_set</code>结构。突破了 select 的文件描述符个数限制。</p></li><li><p>管理多个描述符也是进行轮询，根据描述符的状态进行处理。poll和select一样有大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，其开销也随着文件描述符数量增加而线性增大。</p></li><li><p>返回到用户态之后也需要通过遍历的方式查找哪些socket是准备好了的。时间复杂度为<code>O(n)</code>。</p></li></ul><h3 id="1-2-3-epoll"><a href="#1-2-3-epoll" class="headerlink" title="1.2.3 epoll"></a>1.2.3 epoll</h3><ul><li>epoll模型修改主动轮询为被动通知，当有事件发生时，被动接收通知。所以epoll模型注册套接字后，主程序可做其他事情，当事件发生时，接收到通知后再去处理。</li></ul><div style="text-align:center;">    <img src="epoll.webp" alt="" width="452" height="209" class="jop-noMdConv"></div><ul><li><p>epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过 <code>epoll_ctl()</code> 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 <code>O(logn)</code>。</p></li><li><p>而 select&#x2F;poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select&#x2F;poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。</p></li><li><p>epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 <code>epoll_wait()</code> 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select&#x2F;poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。所以用户程序在获得准备好的socket时的复杂度是<code>O(1)</code></p></li></ul><p><strong>边缘触发和水平触发</strong></p><ul><li><p>使用<strong>边缘触发</strong>模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；</p></li><li><p>使用<strong>水平触发</strong>模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；</p></li><li><p>简单总结一下就是，边缘触发是针对事件到达触发的，socket从没有数据到数据准备好这个状态变化会发生一次边缘触发，因此在后续读取socket中已经准备好的数据时要尽量多读写数据，以免错失读写的机会。因此，我们会循环从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，边缘触发模式一般和非阻塞 I&#x2F;O 搭配使用，程序会一直执行 I&#x2F;O 操作，直到系统调用（如 <code>read</code> 和 <code>write</code>）返回错误，错误类型为 <code>EAGAIN</code> 或 <code>EWOULDBLOCK</code>。</p></li><li><p>select&#x2F;poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。</p></li></ul><h2 id="1-3-信号驱动I-O"><a href="#1-3-信号驱动I-O" class="headerlink" title="1.3 信号驱动I&#x2F;O"></a>1.3 信号驱动I&#x2F;O</h2><ul><li><p>预先在内核中设置一个回调函数，当某个事件发生时，内核使用信号（SIGIO）通知进程来处理（运行回调函数）。 它也可以看成是一种异步IO，因为检测fd是否有数据和是否可读写是在两个流程中做的。</p></li><li><p>优势是进程没有收到SIGIO信号之前，不被阻塞，可以做其他事情。劣势是当数据量变大时，信号产生太频繁，性能会非常低。</p></li><li><p>信号驱动 I&#x2F;O 提供的是边缘触发通知，即只有当 I&#x2F;O 事件发生时我们才会收到通知，且当文件描述符收到 I&#x2F;O 事件通知时，并不知道要处理多少 I&#x2F;O 数据。因此和边缘触发模式的epoll一样需要配合非阻塞I&#x2F;O使用。</p></li></ul><h2 id="1-4-异步I-O"><a href="#1-4-异步I-O" class="headerlink" title="1.4 异步I&#x2F;O"></a>1.4 异步I&#x2F;O</h2><ul><li><p>如果使用非直接I&#x2F;O的方式，每次需要用户线程从内核态内存中拷贝数据到用户态内存，因为内存访问速度相对较快，并不会带来较大的性能瓶颈。</p></li><li><p>但如果我们使用DIRECT模式，每次都需要直接与磁盘交互，同步IO在数据拷贝阶段的等待会非常长。因此我们需要一种异步IO的机制，让进程去做别的工作，在IO的数据拷贝完成后再通知进程。</p></li></ul><h3 id="1-4-1-kernel-aio"><a href="#1-4-1-kernel-aio" class="headerlink" title="1.4.1 kernel aio"></a>1.4.1 kernel aio</h3><ul><li><p>大概流程是用户通过 <code>io_submit()</code> 提交 I&#x2F;O 请求，过一会再调用 <code>io_getevents()</code> 阻塞等待event事件完成，另外linux aio也支持了epoll。（普通文件的IO无法使用epoll来监视，因为ext4格式文件未实现 poll 方法，但是使用aio之后就可以用epoll来监视了）</p></li><li><p>只支持 <code>O_DIRECT</code> 文件，因此对常规的非数据库应用几乎是无用的。虽然从技术上说接口是非阻塞的，但实际上有很多可能的原因都会导致它阻塞，而且引发的方式难以预料。</p></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> _GNU_SOURCE</span><br><span class="hljs-comment">//  sudo apt-get install libaio-dev</span><br><span class="hljs-comment">//  gcc -static aio.c -o aio -laio</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdlib.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;string.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;libaio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;errno.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;unistd.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;fcntl.h&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> FILEPATH <span class="hljs-string">&quot;./aio.txt&quot;</span></span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">io_context_t</span> context;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">iocb</span> io[<span class="hljs-number">1</span>], *p[<span class="hljs-number">1</span>] = &#123;&amp;io[<span class="hljs-number">0</span>]&#125;;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">io_event</span> e[<span class="hljs-number">1</span>];<br>    <span class="hljs-type">unsigned</span> nr_events = <span class="hljs-number">10</span>;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">timespec</span> timeout;<br>    <span class="hljs-type">char</span> *wbuf;<br>    <span class="hljs-type">int</span> wbuflen = <span class="hljs-number">1024</span>;<br>    <span class="hljs-type">int</span> ret, num = <span class="hljs-number">0</span>, i;<br><br>    <span class="hljs-built_in">posix_memalign</span>((<span class="hljs-type">void</span> **)&amp;wbuf, <span class="hljs-number">512</span>, wbuflen);<br><br>    <span class="hljs-built_in">memset</span>(wbuf, <span class="hljs-string">&#x27;@&#x27;</span>, wbuflen);<br>    <span class="hljs-built_in">memset</span>(&amp;context, <span class="hljs-number">0</span>, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">io_context_t</span>));<br><br>    timeout.tv_sec = <span class="hljs-number">0</span>;<br>    timeout.tv_nsec = <span class="hljs-number">10000000</span>;<br><br>    <span class="hljs-type">int</span> fd = <span class="hljs-built_in">open</span>(FILEPATH, O_CREAT|O_RDWR|O_DIRECT, <span class="hljs-number">0644</span>); <span class="hljs-comment">// 1. 打开要进行异步IO的文件</span><br>    <span class="hljs-keyword">if</span> (fd &lt; <span class="hljs-number">0</span>) &#123;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;open error: %d\n&quot;</span>, errno);<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> (<span class="hljs-number">0</span> != <span class="hljs-built_in">io_setup</span>(nr_events, &amp;context)) &#123;               <span class="hljs-comment">// 2. 创建一个异步IO上下文</span><br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;io_setup error: %d\n&quot;</span>, errno);<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br><br>    <span class="hljs-built_in">io_prep_pwrite</span>(&amp;io[<span class="hljs-number">0</span>], fd, wbuf, wbuflen, <span class="hljs-number">0</span>);           <span class="hljs-comment">// 3. 创建一个异步IO任务</span><br><br>    <span class="hljs-keyword">if</span> ((ret = <span class="hljs-built_in">io_submit</span>(context, <span class="hljs-number">1</span>, p)) != <span class="hljs-number">1</span>) &#123;            <span class="hljs-comment">// 4. 提交异步IO任务</span><br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;io_submit error: %d\n&quot;</span>, ret);<br>        <span class="hljs-built_in">io_destroy</span>(context);<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">while</span> (<span class="hljs-number">1</span>) &#123;<br>        ret = <span class="hljs-built_in">io_getevents</span>(context, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, e, &amp;timeout);     <span class="hljs-comment">// 5. 获取异步IO的结果</span><br>        <span class="hljs-keyword">if</span> (ret &lt; <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;io_getevents error: %d\n&quot;</span>, ret);<br>            <span class="hljs-keyword">break</span>;<br>        &#125;<br><br>        <span class="hljs-keyword">if</span> (ret &gt; <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;result, res2: %d, res: %d\n&quot;</span>, e[<span class="hljs-number">0</span>].res2, e[<span class="hljs-number">0</span>].res);<br>            <span class="hljs-keyword">break</span>;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>其实Linux IO的“异步”其实比“同步”更好实现，因为它底层调用的那些提交IO的接口本身就是异步的，比如vfs层通过submit_bio提交一个io请求，这个过程本身就是异步的，只不是传统的同步写入中，会等待IO完成才返回， 而aio中调用之后就直接返回了，通过回调来通知请求完成。这就是AIO的总体逻辑。</li></ul><h3 id="1-4-2-posix-aio"><a href="#1-4-2-posix-aio" class="headerlink" title="1.4.2 posix aio"></a>1.4.2 posix aio</h3><ul><li><p>kernel aio是Linux提供的一些内核函数来支持异步IO，性能很好，但是没有可移植性。</p></li><li><p>posix aio是c标准库 glibc 中，基于posix接口规范，在用户态用多线程实现的一个aio。它的优点是可移植性好，在满足posix规范的平台上基本上都能跑，缺点是基于多线程实现的性能较差，而且受限于线程池的大小，可能出现任务积压影响IO速度。</p></li><li><p>很多方式可以判断 posix aio 任务的结束，和 kernel aio 一样，也是有办法通过 epoll 来监视异步IO任务的。</p></li></ul><h3 id="1-4-3-io-uring"><a href="#1-4-3-io-uring" class="headerlink" title="1.4.3 io_uring"></a>1.4.3 io_uring</h3><blockquote><p>参考资料：</p><p><a href="https://arthurchiao.art/blog/intro-to-io-uring-zh/#15-%E5%BC%82%E6%AD%A5-ioaio">Linux 异步 I&#x2F;O 框架 io_uring</a></p><p><a href="https://www.bilibili.com/video/BV1JB4y1R7QY">阿里云的 Linux 内核 io_uring 介绍与实践</a></p></blockquote><p><strong>此前aio实现的问题</strong></p><ol><li><p>虽然是异步实现，但系统调用非常多在更高负载的场景性能并不好</p></li><li><p>并不总是异步的，在很多地方都可能造成阻塞等待</p></li><li><p>仅支持<code>O_DIRECT</code>，目前只有数据库领域大量使用这样的接口调用，而在绝大部分的场景都是buffered I&#x2F;O使用更多</p></li><li><p>请求元数据开销很大，尤其是对较小的I&#x2F;O请求元数据比读写数据更大</p></li><li><p>对iopoll的支持方式不好。处理I&#x2F;O请求的方式主要有两种，一个是通过中断告诉应用程序，而另一种就是应用程序主动轮询去查找I&#x2F;O请求是否完成，随着设备越来越快， 中断驱动（interrupt-driven）模式效率已经低于轮询模式 （polling for completions）</p></li></ol><p><strong>io_uring的优势</strong></p><ol><li><p>仅使用简单强大的三个系统调用：</p><ul><li><p>io_uring_setup，用于设置 io_uring 上下文</p></li><li><p>io_uring_enter，提交并获取完成任务</p></li><li><p>io_uring_register，注册内核用户共享的缓冲区</p></li></ul></li><li><p>通用型非常强，提供内核统一的异步编程框架，支持任何类型的I&#x2F;O (cached files、direct-access files、blocking sockets)，同时也支持类epoll型编程。</p></li><li><p>有更加丰富的特性，支持很多高级特性。同时IO请求带来的overhead比较小，高性能。</p></li></ol><p><strong>基本结构</strong></p><ul><li><p>在设计上是真正异步的（truly asynchronous）。只要设置了合适的flag，它在系统调用上下文中就只是将请求放入队列， 不会做其他任何额外的事情，保证了应用永远不会阻塞。支持任何类型的 I&#x2F;O：cached files、direct-access files 甚至 blocking sockets。</p></li><li><p>由于设计上就是异步的（async-by-design nature），因此无需 poll+read&#x2F;write 来处理 sockets。 只需提交一个阻塞式读（blocking read），请求完成之后，就会出现在 completion ring。</p></li></ul><div style="text-align:center;">    <img src="uring.png" alt="uring.png" width="426" height="246" class="jop-noMdConv"></div><ul><li><p>每个 io_uring 实例都有<strong>两个环形队列</strong>（ring），在内核和应用程序之间共享。因为这两个队列是共享的，完全可以做到用户态线程添加任务和获取完成的任务两个操作都不需要系统调用：</p><ul><li><p><strong>提交队列</strong>：submission queue (SQ)</p></li><li><p><strong>完成队列</strong>：completion queue (CQ)</p></li></ul></li><li><p>都是单生产者、单消费者，所以每个环形队列都是两个线程在竞争使用，提供无锁接口（lock-less access interface），内部使用内存屏障做同步（coordinated with memory barriers）。</p></li></ul><p><strong>重要特性</strong></p><ul><li><p>IORING_SETUP_SQPOLL：创建一个内核线程来进行sqe的提交，几乎完全消除用户态内核态的上下文切换。并真正得将IO逻辑offload，业务逻辑和IO逻辑完全分离。</p></li><li><p>IORING_SETUP_IOPOLL：配合blk_mq多类型硬件队列映射机制，利用这个特性内核io协议栈开始真正支持iopoll</p></li><li><p>IORING_FEAT_FAST_POLL：网络编程环境下使用的，类似于epoll这样的接口，但是不再需要用户程序做数据的拷贝工作，性能会更优。</p></li></ul><p><strong>中断驱动模式</strong>（interrupt driven）</p><ul><li>默认模式，可通过 io_uring_enter() 提交 I&#x2F;O 请求SQE，然后通过<code>io_uring_wait_cqe</code>等待完成IO请求的CQE。</li></ul><p><strong>轮询模式</strong>（polled）</p><ul><li><p>Busy-waiting for an I&#x2F;O completion，而不是通过异步 IRQ（Interrupt Request）接收通知。</p></li><li><p>这种模式需要文件系统和块设备（block device）支持轮询功能。 相比中断驱动方式延迟更低（连系统调用都省了）， 但可能会消耗更多 CPU 资源。</p></li><li><p>目前，只有指定了 O_DIRECT flag 打开的文件描述符，才能使用这种模式。当一个读 或写请求提交给轮询上下文（polled context）之后，应用（application）必须调用 <code>io_uring_enter()</code> 来轮询 CQ 队列，判断请求是否已经完成。</p></li></ul><p><strong>内核轮询模式</strong>（kernel polled）</p><ul><li><p>创建一个内核线程（kernel thread）来执行 SQ 的轮询工作。</p></li><li><p>使用这种模式的 io_uring 实例，应用无需切到到内核态就能触发I&#x2F;O 操作。 通过 SQ 来提交 SQE，以及监控 CQ 的完成状态，应用无需任何系统调用，就能提交和收割 I&#x2F;O（submit and reap I&#x2F;Os）。</p></li><li><p>如果内核线程的空闲时间超过了用户的配置值，它会通知应用，然后进入 idle 状态。 这种情况下，应用必须调用 <code>io_uring_enter()</code> 来唤醒内核线程。如果 I&#x2F;O 一直很繁忙，内核线性是不会 sleep 的。</p></li></ul><h1 id="二、零拷贝"><a href="#二、零拷贝" class="headerlink" title="二、零拷贝"></a>二、零拷贝</h1><h2 id="2-1-传统文件传输"><a href="#2-1-传统文件传输" class="headerlink" title="2.1 传统文件传输"></a>2.1 传统文件传输</h2><div style="text-align:center;">    <img src="传统文件传输.webp" alt="传统文件传输.webp" width="380" height="234" class="jop-noMdConv"></div><ul><li><p>将磁盘上的文件读取出来，然后通过网络协议发送给客户端。</p></li><li><p>发生了 4 次用户态与内核态的上下文切换，还发生了 4 次数据拷贝，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的。</p></li><li><p>要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数</p></li></ul><h2 id="2-1-mmap优化"><a href="#2-1-mmap优化" class="headerlink" title="2.1 mmap优化"></a>2.1 mmap优化</h2><div style="text-align:center;">    <img src="mmap + write 零拷贝.webp" alt="mmap + write 零拷贝.webp" width="373" height="230"></div><ul><li><p><code>mmap()</code> 系统调用函数会直接把内核缓冲区里的数据「<strong>映射</strong>」到用户空间，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。</p></li><li><p>减少一次数据拷贝的过程，仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换。</p></li></ul><h2 id="2-2-sendfile"><a href="#2-2-sendfile" class="headerlink" title="2.2 sendfile"></a>2.2 sendfile</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;sys/socket.h&gt;</span></span><br><span class="hljs-function"><span class="hljs-type">ssize_t</span> <span class="hljs-title">sendfile</span><span class="hljs-params">(<span class="hljs-type">int</span> out_fd, <span class="hljs-type">int</span> in_fd, <span class="hljs-type">off_t</span> *offset, <span class="hljs-type">size_t</span> count)</span></span>;<br></code></pre></td></tr></table></figure><ul><li><p>前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。</p></li><li><p>替代前面的 <code>read()</code> 和 <code>write()</code> 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。但依然是三次数据拷贝，不是真正的零拷贝技术。</p></li></ul><div style="text-align:center;">    <img src="sendfile-零拷贝.webp" alt="sendfile-零拷贝.webp" width="404" height="239" class="jop-noMdConv"></div><ul><li><p>如果网卡支持 SG-DMA（<em>The Scatter-Gather Direct Memory Access</em>）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。</p></li><li><p>所谓的零拷贝（<em>Zero-copy</em>）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。</p></li><li><p>零拷贝技术的文件传输方式相比传统文件传输的方式，只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。</p></li></ul><p><strong>应用案例</strong></p><ul><li><p><code>Kafka</code>文件传输最终它调用了 Java NIO 库里的 <code>transferTo</code> 方法，如果 Linux 系统支持 <code>sendfile()</code> 系统调用，那么 <code>transferTo()</code> 实际上最后就会使用到 <code>sendfile()</code> 系统调用函数。</p></li><li><p><code>Nginx</code>也支持零拷贝技术，一般默认是开启零拷贝技术，这样有利于提高文件传输的效率。</p></li></ul><h1 id="三、网络模式"><a href="#三、网络模式" class="headerlink" title="三、网络模式"></a>三、网络模式</h1><ul><li><p>市面上常见的开源软件很多都采用了这个方案，比如 Redis、Nginx、Netty 等等</p></li><li><p>基于面向对象的思想，对 I&#x2F;O 多路复用作了一层封装，让使用者不用考虑底层网络 API 的细节，只需要关注应用代码的编写。</p></li><li><p>Reactor 模式也叫 <code>Dispatcher</code> 模式，我觉得这个名字更贴合该模式的含义，即 I&#x2F;O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 &#x2F; 线程。</p></li></ul><h2 id="3-1-Reactor"><a href="#3-1-Reactor" class="headerlink" title="3.1 Reactor"></a>3.1 Reactor</h2><p><strong>组成</strong></p><ul><li><p>Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下：</p><ul><li><p>Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；</p></li><li><p>处理资源池负责处理事件，如 read -&gt; 业务逻辑 -&gt; send；</p></li></ul></li><li><p>Reactor 模式是灵活多变的，Reactor 的数量可以只有一个，也可以有多个；处理资源池可以是单个进程 &#x2F; 线程，也可以是多个进程 &#x2F;线程；</p></li></ul><p><strong>单Reactor 单进程&#x2F;线程</strong></p><div style="text-align:center;">    <img src="单Reactor单进程.webp" alt="单Reactor单进程.webp" width="469" height="274" class="jop-noMdConv"></div><ul><li><p>进程里有 <strong>Reactor、Acceptor、Handler</strong> 这三个对象：Reactor 对象的作用是监听和分发事件；Acceptor 对象的作用是获取连接；Handler 对象的作用是处理业务。select、accept、read、send 是系统调用函数，dispatch 和 「业务处理」是需要完成的操作，其中 dispatch 是分发事件操作。</p></li><li><p>代码流程大概是：</p><ul><li><p>Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；</p></li><li><p>如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；</p></li><li><p>如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；</p></li><li><p>Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</p></li></ul></li><li><p>全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争。但因为只有一个进程，无法充分利用多核CPU的性能，Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，如果业务处理耗时比较长，那么就造成响应的延迟。</p></li><li><p>单Reactor 单进程的方案不适用计算机密集型的场景，只适用于业务处理非常快速的场景。因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案。</p></li></ul><p><strong>单Reactor 多线程&#x2F;多进程</strong></p><div style="text-align:center;">    <img src="单Reactor多线程.webp" alt="单Reactor多线程.webp" width="468" height="395" class="jop-noMdConv"></div><ul><li><p>Handler对象不再负责业务处理，只负责数据的接收和发送，Handler对象通过read读取到数据后，会将数据发给子线程里的 Processor 对象进行业务处理；</p></li><li><p>子线程里的 Processor 对象就进行业务处理，处理完后将结果发给主线程中的 Handler 对象，接着由 Handler 通过 send 方法将响应结果发送给 client。</p></li><li><p>优势在于能够充分利用多核 CPU 的能，但是带来了多线程竞争资源的问题。例如子线程完成业务处理后，要把结果传递给主线程的 Handler 进行发送，这里涉及共享数据的竞争。另外因为一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方。</p></li></ul><p><strong>多Reactor 多进程&#x2F;线程</strong></p><div style="text-align:center;">    <img src="主从Reactor多线程.webp" alt="主从Reactor多线程.webp" width="484" height="345" class="jop-noMdConv"></div><ul><li><p>主线程中的 MainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 对象中的 accept 获取连接，将新的连接分配给某个子线程；</p></li><li><p>子线程中的 SubReactor 对象将 MainReactor 对象分配的连接加入 select 继续进行监听，并创建一个 Handler 用于处理连接的响应事件。</p></li><li><p>如果有新的事件发生时，SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应。Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</p></li><li><p>大名鼎鼎的两个开源软件 Netty 和 Memcache 都采用了「多 Reactor 多线程」的方案。采用了「多 Reactor 多进程」方案的开源软件是 Nginx，不过方案与标准的多 Reactor 多进程有些差异。</p></li></ul><h2 id="3-2-Proactor"><a href="#3-2-Proactor" class="headerlink" title="3.2 Proactor"></a>3.2 Proactor</h2><ul><li><p>Proactor采用了异步I&#x2F;O技术，所以被称为异步网络模型。无论是 Reactor，还是 Proactor，都是一种基于「事件分发」的网络编程模式，区别在于Reactor 模式是基于「待完成」的 I&#x2F;O 事件，而 Proactor 模式则是基于「已完成」的 I&#x2F;O 事件。</p></li><li><p><strong>Reactor 是非阻塞同步网络模式，感知的是就绪可读写事件</strong>。在每次感知到有事件发生（比如可读就绪事件）后，就需要应用进程主动调用 read 方法来完成数据的读取，也就是要应用进程主动将 socket 接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据。</p></li><li><p><strong>Proactor 是异步网络模式， 感知的是已完成的读写事件</strong>。在发起异步读写请求时，需要传入数据缓冲区的地址（用来存放结果数据）等信息，这样系统内核才可以自动帮我们把数据的读写工作完成，这里的读写工作全程由操作系统来做，并不需要像 Reactor 那样还需要应用进程主动发起 read&#x2F;write 来读写数据，操作系统完成读写工作后，就会通知应用进程直接处理数据。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux:同步与锁</title>
    <link href="/2024/05/12/Linux-%E5%90%8C%E6%AD%A5%E4%B8%8E%E9%94%81/"/>
    <url>/2024/05/12/Linux-%E5%90%8C%E6%AD%A5%E4%B8%8E%E9%94%81/</url>
    
    <content type="html"><![CDATA[<h1 id="一、互斥量"><a href="#一、互斥量" class="headerlink" title="一、互斥量"></a>一、互斥量</h1><ul><li>在Linux中要实现互斥锁mutex最简单的办法是通过操作系统提供的信号量来实现，但是目前在C++中调用pthread_mutex_lock并不是直接通过操作系统的信号量原语来实现的，而是使用了优化过的futex来实现。</li></ul><h2 id="1-1-futex基本概念"><a href="#1-1-futex基本概念" class="headerlink" title="1.1 futex基本概念"></a>1.1 futex基本概念</h2><ul><li>Futex 是Fast Userspace muTexes的缩写，在传统的Unix系统中当进程间要同步的时候必须要通过系统调用(如semop())在内核中完成。而大部分时候其实并没有另外的程序在竞争这个信号量，但是在这种情况下，这个进程也要陷入内核去看看有没有进程和它竞争，退出的时侯还要陷入内核去看看有没有进程等待在同一同步变量上。这些不必要的系统调用(或者说内核陷入)造成了大量的性能开销。</li><li>Futex是一种用户态和内核态混合的同步机制。首先，同步的进程间通过mmap共享一段内存，futex变量就位于这段共享的内存中且操作是原子的，当进程尝试进入互斥区或者退出互斥区的时候，先去查看共享内存中的futex变量，如果没有竞争发生，则只修改futex,而不用再执行系统调用了。</li><li>当通过访问futex变量告诉进程有竞争发生，则还是得执行系统调用去完成相应的处理(wait 或者 wake up)。简单的说，futex就是通过在用户态的检查，（motivation）如果了解到没有竞争就不用陷入内核了，大大提高了low-contention时候的效率。</li></ul><h2 id="1-2-futex实现原理"><a href="#1-2-futex实现原理" class="headerlink" title="1.2 futex实现原理"></a>1.2 futex实现原理</h2><ul><li>futex包含了用户态和内核态的两部分行为，用户态由glibc-nptl库的pthread_mutex实现，内核态由futex系统调用支持。</li></ul><h3 id="1-2-1-用户态"><a href="#1-2-1-用户态" class="headerlink" title="1.2.1 用户态"></a>1.2.1 用户态</h3><ul><li>C++中的std::mutex只是对glibc-nptl库的pthread_mutex_t的一层封装，pthread_mutex_t其实是个union结构，它的主干部分是其中的__pthread_mutex_s，大概成员为：</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">union</span> &#123;<br>  <span class="hljs-keyword">struct</span> <span class="hljs-title class_">__pthread_mutex_s</span> &#123;<br>    <span class="hljs-type">int</span> __lock;                <span class="hljs-comment">// !&lt; 表示是否被加锁，是否存在竞争</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> __count;       <span class="hljs-comment">//!&lt; __kind代表可重入锁时，重复上锁会对__count进行递增。</span><br>    <span class="hljs-type">int</span> __owner;                <span class="hljs-comment">//!&lt; 持有线程的线程ID。</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> __nusers;<br>    <span class="hljs-type">int</span> __kind;                 <span class="hljs-comment">//!&lt; 上锁类型。</span><br>    <span class="hljs-type">int</span> __spins;<br>    <span class="hljs-type">__pthread_list_t</span> __list;<br>  &#125; __data;<br>&#125; <span class="hljs-type">pthread_mutex_t</span>;<br></code></pre></td></tr></table></figure><ul><li><p>__lock是CAS操作对象，其值有三种状态：</p><ul><li><p>0， 表示还没有进程&#x2F;线程获得这把锁</p></li><li><p>1， 表示有进程&#x2F;线程已经获得了这个锁</p></li><li><p>2， 当lock值已经为1，且又有进程&#x2F;线程要获取这个锁时，将lock置为2，表示发生了竞争</p></li></ul></li><li><p>__kind的是一个32位的整数，库的设计者将这个32字节分成几个部分来提通不同的分类方式</p><ul><li>其中的第1到第7位，代表一个锁的类别。<ul><li><code>PTHREAD_MUTEX_TIMED_NP</code>是mutex的默认类型，它是非递归的，这最常用的锁类别。</li><li><code>PTHREAD_MUTEX_RECURSIVE_NP</code>则表示可重入锁。</li></ul></li><li>它的第8位表示<strong>该锁是用在进程间同步还是线程间同步</strong>，通常情况下我们在线程同步中使用mutex，此时只需要将mutex声明在全局数据段即可；但如果是进程间的同步，则需要先开辟一个共享内存，将mutex放入共享内存中，然后不同进程才能操作同一个mutex。</li></ul></li><li><p>__count是给可重入锁使用的，如果同一个线程重复对同一个mutex加锁，则对该属性进行递增即可。</p></li></ul><p><strong>pthread_mutex_lock</strong></p><ul><li>加锁lock()的逻辑很简单，首先在用户态利用CAS判断是否发生冲突，如果CAS返回0，那么直接返 回;如果CAS返回1或者2，进入futex系统调用，交由操作系统仲裁</li></ul><p><strong>pthread_mutex_unlock</strong></p><ul><li>解锁unlock()的逻辑类似，同样需要通过CAS，如果lock的旧值是1，那么只有当前线程占用该锁，直接返回;如果lock的旧值是2，说明超过一个线程发生了竞争，调用futex系统调用唤醒其它线程。</li></ul><h3 id="1-2-2-内核态"><a href="#1-2-2-内核态" class="headerlink" title="1.2.2 内核态"></a>1.2.2 内核态</h3><ul><li>当一个线程需要等待一个锁而陷入睡眠时，内核会为其分配一个futex_q结构，一切的唤醒、睡眠操作都需要先找到这个futex_q结构。</li><li>但如果争抢情况比较激烈，那么内核存在的futex_q结构会有很多，如何快速查找对应的futex_q？内核的解决办法是使用<strong>哈希表</strong>，因为哈希表的查询、插入操作都是O(1)的时间复杂度。如上图所示，内核使用开链法处理哈希碰撞。</li></ul><div style="text-align:center;">    <img src="futex.png" alt="futex.png" width="409" height="237" class="jop-noMdConv"></div><p><strong>hash表的key问题</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">union</span> <span class="hljs-title class_">futex_key</span> &#123;<br>    <span class="hljs-keyword">struct</span> &#123;<br>        u64 i_seq;<br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> pgoff;<br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> offset;<br>    &#125; shared;  <span class="hljs-comment">//不同进程间通过文件共享futex变量，表明该变量在文件中的位置</span><br><br>    <span class="hljs-keyword">struct</span> &#123;<br>        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">mm_struct</span> *mm;<br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> address;<br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> offset;<br>    &#125; <span class="hljs-keyword">private</span>;  <span class="hljs-comment">//同一进程的不同线程共享futex变量，表明该变量在进程地址空间中的位置</span><br><br>    <span class="hljs-keyword">struct</span> &#123;<br>        u64 ptr;<br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> word;<br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> offset;<br>    &#125; both;<br>&#125;;<br></code></pre></td></tr></table></figure><ul><li><p>futex_key.private对于非共享的使用虚拟地址作为key</p><ul><li><p>如果被用来进行线程间同步，那么futex的虚拟地址在不同的线程间是相同的，因此只需要使用虚拟地址就可以唯一地标识同一线程组（进程）中的某个futex。</p></li><li><p>但是内核中的hash表是系统中的所有线程共用的，不只对一个线程组服务，因此需要额外的值来标识不同线程组，linux内核选择使用 mm_struct的虚拟地址（若两个线程属于同一进程，则它们的mm_struct的地址相同，若两个线程分属不同进程，则它们的mm_struct的地址不同）。</p></li><li><p>最终linux使用(mm_struct的虚拟地址, 锁的虚拟地址)来表示一个private futex的key。</p></li></ul></li><li><p>futex_key.shared对于进程间的使用物理地址作为key</p><ul><li><p>如果futex被用来进行进程间同行，那么futex的虚拟地址在不同的进程间不一定相同，因此linux内核需要计算它的物理地址，才可能唯一地表示futex。</p></li><li><p>linux使用( inode-&gt;i_sequence, page-&gt;index, offset_within_page)标识一个shared futex地key。其中inode是用来作为共享内存载体的文件inode， page则是futex虚拟地址所对应的struct page结构（page结构在内核中唯一地对应了一个物理页），offest就是futex结构在实际物理页中偏移量。</p></li></ul></li></ul><p><strong>futex_wait</strong></p><ol><li><p>调用set_current_state将进程状态设置为TASK_INTERRUPTIBLE</p></li><li><p>调用queue_me将futex_q挂载到hash链表上</p></li><li><p>调用freezable_schedule进行冲调度，此后除非有其他线程唤醒本线程，本线程不会被调度器选择 执行。这就是陷入了阻塞状态的含义。（当然这里还有一些timeout机制和提前返回不陷入阻塞的额外处理）</p></li></ol><p><strong>futex_wake</strong></p><ul><li>找到对应的futex_q，将其记录的task_struct的进程状态设置为TASK_RUNNING。</li></ul><h1 id="二、条件变量"><a href="#二、条件变量" class="headerlink" title="二、条件变量"></a>二、条件变量</h1><blockquote><p>参考文献：<br><a href="https://weakyon.com/2019/03/14/deep-understanding-of-condition-variable.html">浅析条件变量</a></p></blockquote><ul><li>条件变量是与互斥量相关联的一种用于多线程之间关于共享数据状态改变的通信机制，当一个动作需要另外一个动作完成时才能进行，即：当一个线程的行为依赖于另外一个线程对共享数据状态的改变时，这时候就可以使用条件变量。其实就是同步的概念。</li><li>较为经典的例子是生产者消费者问题，每个线程都必须关注“物品”的数量信息，如果现在还有物品消费者才能继续运行，负责应该等待；如果承载物品的结构还有空余空间，生产者才能继续添加新的物品，否则等待。</li><li>这里的等待其实就是通过阻塞的方式来实现，只是我们需要在特定的时候唤醒等待的线程。当然这个生产者消费者例子的核心条件是物品数量，我们可以通过C++20引入的信号量<code>std::counting_semaphore</code>来实现，但是如果我们是要针对一些条件判断来进行同步操作，则使用<code>std::condition_variable</code></li></ul><h3 id="2-1-condition-variable"><a href="#2-1-condition-variable" class="headerlink" title="2.1 condition_variable"></a>2.1 condition_variable</h3><ul><li><code>std::condition_variable</code>是需要结合一个<code>std::mutex</code>使用的，并且传入的参数应该是<code>std::unique_lock&lt;std::mutex&gt;</code>，这是类似<code>std::lock_guard</code>是管理锁的辅助类工具，都是RAII风格；它们是在定义时获得锁，在析构时释放锁。它们的主要区别在于unique_lock锁机制更加灵活，可以再需要的时候进行lock或者unlock调用，不非得是析构或者构造时。</li></ul><p><strong>等待</strong></p><ul><li><code>wait</code>：阻塞当前线程，直到条件变量被唤醒</li><li><code>wait_for</code>：阻塞当前线程，直到条件变量被唤醒，或到指定时限之后</li><li><code>wait_until</code>：阻塞当前线程，直到条件变量被唤醒，或直到抵达指定时间点</li></ul><p><strong>唤醒</strong></p><ul><li><code>notify_one</code>：通知一个等待线程</li><li><code>notify_all</code>：通知所有的等待线程</li></ul><p><strong>使用说明</strong></p><ul><li>wait操作必须传入一个锁，条件变量在阻塞时会主动放弃锁的持有权，因此我们是需要传入<code>std::unique_lock&lt;std::mutex&gt;</code>这种更加灵活的包装。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">wait</span><span class="hljs-params">(std::unique_lock&lt;std::mutex&gt;&amp; lock)</span></span>;<br><br><span class="hljs-comment">//Predicate 谓词函数，可以普通函数或者lambda表达式</span><br><span class="hljs-function"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> Predicate&gt;</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">wait</span><span class="hljs-params">(std::unique_lock&lt;std::mutex&gt;&amp; lock, Predicate pred)</span></span>;<br></code></pre></td></tr></table></figure><ul><li>普通调用方式传入这个锁就可以了，但是C++还提供了一种可以再传入一个lambda表达式的接口，这个和条件变量存在的<strong>虚假唤醒</strong>有关系，需要我们通过while循环检测条件是否满足。</li><li>而第二个接口其实就是封装了这个循环检测过程，通过lambda表达式的方式传入这个条件判断语句。</li><li>notify操作则不需要任何如何传入参数，只是唤醒别的在这个条件变量上阻塞的线程。</li></ul><p><strong>例子</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-type">bool</span> work_;<br>std::mutex cvMutex;<br>std::condition_variable cv;<br><br><span class="hljs-comment">//缓存区</span><br>std::deque&lt;<span class="hljs-type">int</span>&gt; data_deque;<br><span class="hljs-comment">//缓存区最大数目</span><br><span class="hljs-type">size_t</span> max_num;<br><span class="hljs-comment">//数据</span><br><span class="hljs-type">int</span> next_index;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">producer_thread</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-keyword">while</span> (work_) &#123;<br>    std::this_thread::<span class="hljs-built_in">sleep_for</span>(std::chrono::<span class="hljs-built_in">milliseconds</span>(<span class="hljs-number">500</span>));<br><br>    <span class="hljs-comment">//加锁</span><br>    <span class="hljs-function">std::unique_lock&lt;std::mutex&gt; <span class="hljs-title">lk</span><span class="hljs-params">(cvMutex)</span></span>;<br>    <span class="hljs-comment">//当队列未满时，继续添加数据</span><br>    cv.<span class="hljs-built_in">wait</span>(lk, [<span class="hljs-keyword">this</span>]() &#123; <span class="hljs-keyword">return</span> <span class="hljs-keyword">this</span>-&gt;data_deque.<span class="hljs-built_in">size</span>() &lt;= <span class="hljs-keyword">this</span>-&gt;max_num; &#125;);<br><br>    next_index++;<br>    data_deque.<span class="hljs-built_in">push_back</span>(next_index);<br>    <span class="hljs-comment">//唤醒其他线程</span><br>    cv.<span class="hljs-built_in">notify_all</span>();<br>    <span class="hljs-comment">//自动释放锁</span><br>  &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">consumer_thread</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-keyword">while</span> (work_) &#123;<br>    <span class="hljs-comment">//加锁</span><br>    <span class="hljs-function">std::unique_lock&lt;std::mutex&gt; <span class="hljs-title">lk</span><span class="hljs-params">(cvMutex)</span></span>;<br>    <span class="hljs-comment">//检测条件是否达成</span><br>    cv.<span class="hljs-built_in">wait</span>(lk, [<span class="hljs-keyword">this</span>] &#123; <span class="hljs-keyword">return</span> !<span class="hljs-keyword">this</span>-&gt;data_deque.<span class="hljs-built_in">empty</span>(); &#125;);<br><br>    <span class="hljs-comment">//互斥操作，消息数据</span><br>    <span class="hljs-type">int</span> data = data_deque.<span class="hljs-built_in">front</span>();<br>    data_deque.<span class="hljs-built_in">pop_front</span>();<br>    <span class="hljs-comment">//唤醒其他线程</span><br>    cv.<span class="hljs-built_in">notify_all</span>();<br>    <span class="hljs-comment">//自动释放锁</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>这里是一个生产者消费者的例子，公共区域是一个双向队列，那么我们访问公共区域必然是需要加锁来保证互斥访问的，也就用这里声明的<code>cvMutex</code>来保证互斥访问了，无论是生产者还是消费者在每次循环中都是先通过<code>std::unique_lock&lt;std::mutex&gt;</code>加锁来保证互斥访问。<strong>这里引出了CondVar需要绑定Mutex的第一个原因，我们在操作公共资源或者是在判断条件的时候都是需要互斥访问的，而Mutex完成了这个工作。</strong></li><li>但如果是对atomic这样的共享变量，是否可以不需要Mutex呢？依然不能，这是CondVar设计的核心要点，后面介绍</li><li>注意wait操作在阻塞时会释放掉锁，并且重新被唤醒并退出wait函数时是会重新持有锁的</li></ul><h2 id="2-2-CondVar为什么需要绑定Mutex"><a href="#2-2-CondVar为什么需要绑定Mutex" class="headerlink" title="2.2 CondVar为什么需要绑定Mutex"></a>2.2 CondVar为什么需要绑定Mutex</h2><ul><li>假设我们现在只有阻塞自己和唤醒别人的两个接口，不绑定Mutex，那能否实现相同的功能？我们依然是先加锁访问共享区域，如果需要阻塞等待就释放锁并阻塞自己。也就是先释放资源锁，再阻塞自己，且不是一个原子操作。</li><li>这里存在一个问题，以消费者生产者为例，消费者条件不满足，于是释放锁并准备阻塞自己，但刚完成解锁的操作，就被生产者获取到了并开始执行，这时，因为消费者还未挂起自己，来不及将自己的标识符保存在某个位置，所以生产者在执行唤醒操作的时候并没有唤醒这个即将阻塞的消费者。这时，切换到消费者后，消费者将永远的等待下去，虽然队列中有产品。而生产者因为队列中有产品可能也一直的等待下去，形成了死锁。</li><li>解决方法是必须让解锁、保存线程标识符、挂起这一系列操作成为原子操作。（当然我们不可能先挂起自己再释放锁）</li><li>glibc怎么做的呢？每一个condvar内部有一个额外的mutex，在pthread_cond_wait的逻辑中，首先是condvar的内部mutex lock，再是外部mutex unlock，再是内部futex wait。这样，就保证了，线程B signal一定在线程A wait之后（毕竟线程B signal也需要获取内部mutex）。</li></ul><h2 id="2-3-虚假唤醒"><a href="#2-3-虚假唤醒" class="headerlink" title="2.3 虚假唤醒"></a>2.3 虚假唤醒</h2><ul><li>在正常情况下，wait类型函数返回时要么是因为被唤醒，要么是因为超时才返回，但是在实际中发现，因此操作系统的原因，wait类型在不满足条件时，它也会返回，这就导致了虚假唤醒。</li><li>既然没有满足条件为何会被唤醒呢？原因有很多，较为经典的一个是我们有一个消费者在运行状态不断消耗生产者生产的“物品”。但是在生产者的循环中每次都会去做notify操作，此外还有可能会做notify_all操作。虽然在唤醒的时候确实还有资源可以使用，但是当被唤醒的消费者真正开始执行的时候却发现资源已经被消耗完了。</li><li>于是我们需要在wait结束的时候再判断一下是否符合条件，那么设计成一个while结构就可以了。</li></ul><h1 id="三、死锁"><a href="#三、死锁" class="headerlink" title="三、死锁"></a>三、死锁</h1><ul><li>死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。</li><li>此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。</li></ul><h2 id="3-1-产生条件"><a href="#3-1-产生条件" class="headerlink" title="3.1 产生条件"></a>3.1 产生条件</h2><ul><li><p>产生死锁的四个必要条件：</p><ul><li><p>互斥条件：一个资源每次只能被一个进程使用。</p></li><li><p>请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。</p></li><li><p>不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。</p></li><li><p>循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。</p></li></ul></li></ul><h2 id="3-2-解决方案"><a href="#3-2-解决方案" class="headerlink" title="3.2 解决方案"></a>3.2 解决方案</h2><h3 id="3-2-1-预防死锁"><a href="#3-2-1-预防死锁" class="headerlink" title="3.2.1 预防死锁"></a>3.2.1 预防死锁</h3><ul><li>预防是通过破坏产生死锁的必要条件之一，使系统不会产生死锁。</li></ul><div style="text-align:center;">    <img src="dead_lock.png" alt="dead_lock.png" width="637" height="280" class="jop-noMdConv"></div><ul><li>在数据库中对B+树访问进行加锁操作时，利用了破坏循环等待条件的方法，通过指定顺序来进行加锁操作，从而保证不产生死锁。</li></ul><h3 id="3-2-2-避免死锁"><a href="#3-2-2-避免死锁" class="headerlink" title="3.2.2 避免死锁"></a>3.2.2 避免死锁</h3><ul><li>有一个安全状态的概念，我们将资源分配给不同的用户，如果我们提前知道每个程序最多需要申请多少资源，那当某个程序申请资源的时候，我们就可以判定如果响应这个请求之后，我们剩余的资源是否还能在未来满足某个进程的最大需要，然后等他返回资源之后，还能满足别的程序，最终保证满足所有的请求。</li><li>如果我们按照某个顺序响应资源请求，可以保证在任意时刻都可以有足够的剩余资源保障请求程序的需要，那么用于不会有产生死锁的可能，这是安全状态。</li><li>如果没有按照这种安全顺序响应请求，会有出现死锁的风险，这时是不安全状态。不安全状态不一定会出现死锁。</li></ul><p><strong>银行家算法</strong></p><ul><li>银行家算法的实质就是要设法保证系统动态分配资源后不进入不安全状态，以避免可能产生的死锁。即没当进程提出资源请求且系统的资源能够满足该请求时，系统将判断满足此次资源请求后系统状态是否安全，如果判断结果为安全，则给该进程分配资源，否则不分配资源，申请资源的进程将阻塞。</li></ul><h3 id="3-2-3-检测死锁和解除"><a href="#3-2-3-检测死锁和解除" class="headerlink" title="3.2.3 检测死锁和解除"></a>3.2.3 检测死锁和解除</h3><ul><li>保存有关资源的请求和分配信息，提供一种算法通过这些信息来检测系统是否已经进入死锁状态</li><li>检测到死锁之后应该通过某种机制让部分进程被终止，从而打破死锁</li></ul><blockquote><p>具体的例子看RocksDB中在事务管理上进行加锁操作时，采用PessimisticTransaction方式时如何对锁进行跟踪和死锁检测。本质上来说是检测有向图中是否存在环，采用BFS算法来实现。</p></blockquote><h1 id="四、可重入锁"><a href="#四、可重入锁" class="headerlink" title="四、可重入锁"></a>四、可重入锁</h1><ul><li><code>std::recursive_mutex</code>：允许在同一个线程中同一个互斥量多次被 lock() ，（但是递归加锁的次数是有限制的，太多可能会报异常），效率要比mutex低。</li><li>实现方式其实就是记录持有锁的线程ID，也是调用pthread_mutex_t，只不过相对于std::mutex调用pthread_mutex_t的传入参数不一样。</li></ul><blockquote><p>分析的c++标准库的std::shared_mutex的实现</p></blockquote><ul><li><p>c++在c++14以上的版本引入了shared_mutex，实现了读写锁的语义。实际上，它的读写锁有两种实现：第一种就是封装操作系统的，其实就是封装了glibc的读写锁实现(只不过这种实现是依托于操作系统本身是posix还是windows的，所以多加了一层shared_mutex来实现统一)；第二种是c++自己的实现。</p></li><li><p>它们的区别就是是否定义了_GLIBCXX_USE_PTHREAD_RWLOCK_T这个宏。如果定义了，就直接用glibc中的pthread_rwlock_t；如果没定义，就用libstdc++中实现的__shared_mutex_cv</p></li></ul><h1 id="五、读写锁"><a href="#五、读写锁" class="headerlink" title="五、读写锁"></a>五、读写锁</h1><h2 id="5-1-优先倾向"><a href="#5-1-优先倾向" class="headerlink" title="5.1 优先倾向"></a>5.1 优先倾向</h2><p><strong>读者优先</strong></p><ul><li>如果当前读者持有锁，那么读者想进就优先进，不用管写者是不是有想进的；如果当前是写者持有锁，那么写者释放锁之后优先唤醒读者。</li></ul><p><strong>写者优先</strong>：</p><ul><li>如果当前是写持有锁，那么写者直接排在队列最前面；如果当前是读者持有锁，那么写者设置一个意向。读者上锁时，如果有这个意向存在，那么也不能进入。</li></ul><p><strong>公平</strong>：</p><ul><li><p>如果当前读者持有锁，那么读者和作者在同一个队列上排布。当出现可以进入时，操作系统来决定让读者或者作者进入。</p></li><li><p>如果单纯判断当前的read_count个数，比如read_count &gt; 1，那么一定进入，此时就是读者优先；如果此时还要判断作者的意向，比如write_entered &#x3D; true时不进入，此时就不是读者优先，但也不一定是写者优先</p></li><li><p>如果作者解锁的时候优先唤醒读者，那显然是读者优先；如果写者解锁的时候优先唤醒写者，那显然是写者优先；如果写者解锁的时候随机唤醒，那么就是公平策略。</p></li></ul><h2 id="5-2-libstdc-的实现"><a href="#5-2-libstdc-的实现" class="headerlink" title="5.2 libstdc++的实现"></a>5.2 libstdc++的实现</h2><h3 id="5-2-1-类定义"><a href="#5-2-1-类定义" class="headerlink" title="5.2.1 类定义"></a>5.2.1 类定义</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">shared_mutex</span><br>&#123;<br>    mutex    _M_mut; <span class="hljs-comment">// 保护对_M_state、gate1_、gate2_的访问</span><br>    cond_var gate1_; <span class="hljs-comment">// 用于在writer存在时(或reader达到最大值时,只不过这种情况几乎不会发生) 阻塞reader/writer</span><br>    cond_var gate2_; <span class="hljs-comment">// 用于在reader非0时 阻塞writer</span><br>    <span class="hljs-type">unsigned</span> _M_state; <span class="hljs-comment">// 最高bit表示writer已经获取锁或正在排队等待获取锁(即write-entered被设置) 其余bit表示reader锁定的个数</span><br>    <br>    <span class="hljs-type">static</span> <span class="hljs-keyword">constexpr</span> <span class="hljs-type">unsigned</span> _S_write_entered<br>      = <span class="hljs-number">1U</span> &lt;&lt; (<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">unsigned</span>)*__CHAR_BIT__ - <span class="hljs-number">1</span>); <span class="hljs-comment">// 二进制表现为1后面31个0 相当于一个筛选器，用于按位与</span><br>    <span class="hljs-type">static</span> <span class="hljs-keyword">constexpr</span> <span class="hljs-type">unsigned</span> _S_max_readers = ~_S_write_entered; <span class="hljs-comment">// 二进制表现为0后面31个1 用于按位与</span><br><br><span class="hljs-keyword">public</span>:<br><br>    <span class="hljs-built_in">shared_mutex</span>() : <span class="hljs-built_in">state_</span>(<span class="hljs-number">0</span>) &#123;&#125;<br><br><span class="hljs-comment">// Exclusive ownership</span><br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">lock</span><span class="hljs-params">()</span></span>;<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">try_lock</span><span class="hljs-params">()</span></span>;<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">timed_lock</span><span class="hljs-params">(nanoseconds rel_time)</span></span>;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">unlock</span><span class="hljs-params">()</span></span>;<br><br><span class="hljs-comment">// Shared ownership</span><br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">lock_shared</span><span class="hljs-params">()</span></span>;<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">try_lock_shared</span><span class="hljs-params">()</span></span>;<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">timed_lock_shared</span><span class="hljs-params">(nanoseconds rel_time)</span></span>;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">unlock_shared</span><span class="hljs-params">()</span></span>;<br>&#125;;<br></code></pre></td></tr></table></figure><ul><li><p>成员变量的核心在两个条件变量和状态标识符上</p><ul><li><p><code>gate1_</code>用于有写线程时阻塞其他的读&#x2F;写线程，<code>gate2_</code>用于有读线程时阻塞写线程。</p></li><li><p>状态标识符号表示目前是否有写线程在等待或者占用，此外还表示当前读线程的数量。</p></li></ul></li></ul><h3 id="5-2-2-读锁"><a href="#5-2-2-读锁" class="headerlink" title="5.2.2 读锁"></a>5.2.2 读锁</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">shared_mutex::lock_shared</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-comment">// 1.首先锁住_M_mut，保护对_M_state的独占访问(这里上锁的原因可以参考为什么condvar需要mutex的参与)</span><br>unique_lock&lt;mutex&gt; __lk(_M_mut);<br><span class="hljs-comment">// 2. 判断reader是否可以进入 </span><br><span class="hljs-comment">// 这里的_M_state &lt; _S_max_readers其实有两层含义</span><br><span class="hljs-comment">// 2.1 如果_M_state最高位为1，此时等式不成立，会在这里锁住；这里代表的语义就是writer正在写，reader不要进入</span><br><span class="hljs-comment">// 2.2 如果_M_state最高位不为1，但最低31位均为1，此时等式不成立，会在这里锁住；这里代表的语义就是reader满了，新的reader不要进入</span><br>    _M_gate1.<span class="hljs-built_in">wait</span>(__lk, [=]&#123; <span class="hljs-keyword">return</span> _M_state &lt; _S_max_readers; &#125;);<br>    <span class="hljs-comment">// 3. reader成功进入，增加readers数量</span><br>    ++_M_state;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">shared_mutex::unlock_shared</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-comment">// 1. 首先锁住_M_mut，保护对_M_state的独占修改</span><br>lock_guard&lt;mutex&gt; __lk(_M_mut);<br>__glibcxx_assert( _M_readers() &gt; <span class="hljs-number">0</span> );<br><span class="hljs-comment">// 2. 修改reader数量，减一</span><br><span class="hljs-keyword">auto</span> __prev = _M_state--;<br><span class="hljs-comment">// 3. 判断当前是否有writer想要进入</span><br><span class="hljs-keyword">if</span> (_M_write_entered())<br>&#123;<br><span class="hljs-comment">// Wake the queued writer if there are no more readers.</span><br><span class="hljs-keyword">if</span> (_M_readers() == <span class="hljs-number">0</span>)<br>_M_gate2.<span class="hljs-built_in">notify_one</span>();<br><span class="hljs-comment">// No need to notify gate1 because we give priority to the queued</span><br><span class="hljs-comment">// writer, and that writer will eventually notify gate1 after it</span><br><span class="hljs-comment">// clears the write-entered flag.</span><br>&#125;<br><span class="hljs-keyword">else</span><br>&#123;<br><span class="hljs-comment">// Wake any thread that was blocked on reader overflow.</span><br><span class="hljs-keyword">if</span> (__prev == _S_max_readers)<br>_M_gate1.<span class="hljs-built_in">notify_one</span>();<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li><p>加读锁的逻辑是，如果目前没有写锁占用或者写锁等待，就直接加锁。所以我们只需要在<code>gate1_</code>上面进行条件等待</p></li><li><p>解锁的时候，需要唤醒在等待的写锁请求，因此需要去唤醒<code>gate2_</code>；这里还有一个else的情况是针对加读锁超过最大数量的情况下唤醒<code>gate2_</code>，一般不可能存在这种情况</p></li></ul><h3 id="5-2-3-写锁"><a href="#5-2-3-写锁" class="headerlink" title="5.2.3 写锁"></a>5.2.3 写锁</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">shared_mutex::lock</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-comment">// 1. 首先锁住_M_mut，保护对_M_state的独占访问(这里上锁的原因可以参考为什么condvar需要mutex的参与)</span><br>    unique_lock&lt;mutex&gt; __lk(_M_mut);<br>    <span class="hljs-comment">// 2. 如果有其他writer正在占用，则阻塞在_M_gate1上</span><br>    _M_gate1.<span class="hljs-built_in">wait</span>(__lk, [=]&#123; <span class="hljs-keyword">return</span> !_M_write_entered(); &#125;);<br>    <span class="hljs-comment">// 3. 设置_M_state最高位为1，让writer保持&quot;想要访问&quot;的状态</span><br>    _M_state |= _S_write_entered;<br>    <span class="hljs-comment">// 4. 如果由readers正在占用，则阻塞在_M_gate2上</span><br>    _M_gate2.<span class="hljs-built_in">wait</span>(__lk, [=]&#123; <span class="hljs-keyword">return</span> _M_readers() == <span class="hljs-number">0</span>; &#125;);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">shared_mutex::unlock</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-comment">// 1. 首先锁住_M_mut，保护对_M_state的独占访问(这里上锁的原因可以参考为什么condvar需要mutex的参与)</span><br>    lock_guard&lt;mutex&gt; __lk(_M_mut);<br>    __glibcxx_assert( _M_write_entered() );<br>    <span class="hljs-comment">// 2. 设置_M_state最高位为0</span><br>    _M_state = <span class="hljs-number">0</span>;<br><span class="hljs-comment">// 3. 唤醒沉睡在_M_gate1上的线程</span><br>    _M_gate1.<span class="hljs-built_in">notify_all</span>();<br>&#125;<br></code></pre></td></tr></table></figure><ul><li><p>写锁请求存在两个阻塞点，首先会被写锁阻塞，这里是被阻塞在<code>gate1_</code>上的；第二种情况是被读锁阻塞的，被阻塞在<code>gate2_</code>上。需要注意，我们在<code>gate1_</code>这一步上因为需要判断<code>_S_write_entered</code>是否为0，所以永远只可能存在1个写请求等待在<code>gate2_</code>上。</p></li><li><p>并且当持有写锁时，<code>gate2_</code>上不会有写锁请求存在，后面到达的写锁请求只会阻塞到<code>gate1_</code>上。因此解锁阶段，只需要唤醒<code>gate1_</code>即可。</p></li></ul><h3 id="5-2-4-公平保证"><a href="#5-2-4-公平保证" class="headerlink" title="5.2.4 公平保证"></a>5.2.4 公平保证</h3><ul><li><p>只要有写线程进入<code>gate2_</code>开始等待，<code>_S_write_entered</code>就会被设置，此后有读请求到来时因为存在<code>_M_state &lt; _S_max_readers;</code>条件，就会被一直阻塞在<code>gate1_</code>上。达成这种状态的情况是当前读锁占用，然后到达的第一个写锁请求。</p></li><li><p>但是如果当前被写锁占用，所有后到达的读&#x2F;写锁请求都被阻塞在<code>gate1_</code>，那么就是公平竞争的。</p></li></ul><h2 id="5-3-glibc的实现"><a href="#5-3-glibc的实现" class="headerlink" title="5.3 glibc的实现"></a>5.3 glibc的实现</h2><p>&nbsp;</p><h1 id="六、乐观锁与悲观锁"><a href="#六、乐观锁与悲观锁" class="headerlink" title="六、乐观锁与悲观锁"></a>六、乐观锁与悲观锁</h1><ul><li>这两种概念并不是指一种具体的锁实现，而是指一种控制并发访问的理念，是程序设计上的概念。</li></ul><p><strong>悲观锁</strong></p><ul><li>其实互斥锁、自旋锁、读写锁，都是属于悲观锁。</li><li>悲观锁做事比较悲观，它认为<strong>多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁</strong>。</li></ul><p><strong>乐观锁</strong></p><ul><li>那相反的，如果多线程同时修改共享资源的概率比较低，就可以采用乐观锁。</li><li>乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：<strong>先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作</strong>。</li><li>放弃后如何重试，这跟业务场景息息相关，虽然重试的成本很高，但是冲突的概率足够低的话，还是可以接受的。<strong>乐观锁全程并没有加锁，所以它也叫无锁编程</strong>。</li></ul>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux:进程管理</title>
    <link href="/2024/05/12/Linux-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"/>
    <url>/2024/05/12/Linux-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="一、进程管理"><a href="#一、进程管理" class="headerlink" title="一、进程管理"></a>一、进程管理</h1><h2 id="1-1-进程"><a href="#1-1-进程" class="headerlink" title="1.1 进程"></a>1.1 进程</h2><ul><li>进程是处于执行期的程序，除了除了可执行代码之外，还包含：<ul><li>打开的文件</li><li>挂起的信号</li><li>内核内部数据</li><li>处理器状态</li><li>具有内存映射的内存地址空间</li><li>执行的线程</li><li>存放全局变量的数据段</li></ul></li><li>线程则包含一个独立的程序计数器、进程栈和一组进程寄存器</li><li>内核调度的对象是线程，而非进程，在Linux中线程只不过是特殊的进程</li></ul><h2 id="1-2-进程描述符和任务结构"><a href="#1-2-进程描述符和任务结构" class="headerlink" title="1.2 进程描述符和任务结构"></a>1.2 进程描述符和任务结构</h2><ul><li>进程描述符task_struct，通过双向链表连接，进程和线程都通过这个结构体表示</li><li>五种进程状态：<ul><li>运行：进程准备就绪或者正在执行，进程在用户空间中执行的唯一可能状态</li><li>可中断：被阻塞，等待某些条件达成，达成条件可以立即进入运行状态，如果收到别的信号也会被唤醒而立刻进入运行状态</li><li>不可中断：同上一种，但不会因为收到信号而被唤醒，通常在等待时不能受干扰或者等待事件很快发生时出现</li><li>被其他进程跟踪：例如通过ptrace对调试程序进行跟踪</li><li>停止执行：进程没有被投入运行也不能投入运行，在接受到某些信号或者调试期间接收到任何信号时进入这种状态</li></ul></li><li>程序执行系统调用或者出发异常时会陷入内核空间，此时内核“代表进程执行“，并处于进程的上下文中。而在中断上下文中，系统不代表进程执行，而是执行中断处理程序，此时不存在进程上下文。</li></ul><h2 id="1-3-创建进程"><a href="#1-3-创建进程" class="headerlink" title="1.3 创建进程"></a>1.3 创建进程</h2><ul><li>创建新的进程步骤是：1. 在新的地址空间中创建进程；2. 读入可执行文件；3. 最后开始执行。Unix使用fork()和exec()两个函数完成</li><li>写时拷贝（copy-on-write）通过fork()创建进程时理论上是需要新的资源的，比如地址空间等。但是全部拷贝一份的开销很大，甚至这些拷贝的资源不会被新的进程用到</li><li>创建新的进程时，不复制整个进程的地址空间，而是让父子进程共享同一个拷贝，只有需要写入的时候才复制数据，使进程拥有自己的拷贝，将拷贝推迟到实际发生拷贝的时候进行。</li><li>因此fork()的实际开销是：复制父进程的页表以及给子进程创建一个进程描述符</li></ul><h3 id="fork"><a href="#fork" class="headerlink" title="fork()"></a>fork()</h3><ul><li>fork()通过拷贝当前进程创建一个子进程，其从内核返回两次，一次回到父进程返回值是子进程的PID，一次回到子进程返回值是0</li><li>fork()、vfork()、__clone()都是通过调用clone()完成的，只是传入的参数不同</li><li>拷贝完成之后内核一般有意让子进程优先执行避免写时拷贝的额外开销，如果父进程先执行可能开始向地址空间中写入</li><li>fork()和vfork()的差异是：vfork()不用拷贝页表，子进程会作为父进程的一个单独线程在他的地址空间中运行，父进程被阻塞，直到子进程退出或者执行exec()，子进程不能向地址空间中写入</li></ul><h2 id="1-4-Linux线程"><a href="#1-4-Linux线程" class="headerlink" title="1.4 Linux线程"></a>1.4 Linux线程</h2><ul><li><p>线程是现代操作系统的常见一个抽象概念，线程之间共享内存地址空间、打开的文件等资源，并且可以并发。</p></li><li><p>Linux的线程实现机制非常特殊，对Linux内核来说，不存在线程的概念，Linux使用标准进程来实现线程，每个线程都一个自己独占的task_struct，线程只是和其他进程共享地址空间等资源的进程而已。</p></li></ul><h3 id="创建线程"><a href="#创建线程" class="headerlink" title="创建线程"></a>创建线程</h3><ul><li>线程创建的方式和进程是一样的，区别在于给clone()系统调用传递的参数不一样，创建线程时，clone的参数规定了哪些资源是共享的：<code>clone(CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND, 0);</code></li><li>上述代码产生的作用和普通的fork是类似的，只是父子进程共享地址空间、文件系统资源、文件描述符、信号处理程序。此时的子进程和父进程就是我们说的线程了。</li><li>fork()的实现则是<code>clone(SIGCHLD,0)</code>，仅共享信号处理程序。</li><li>vfork()的实现则是<code>clone(CLONE_VFORK | CLONE_VM | SIGCHLD,0)</code></li></ul><h3 id="内核线程"><a href="#内核线程" class="headerlink" title="内核线程"></a>内核线程</h3><p>内核通过内核线程在后台执行各种操作，内核线程指的是只存在于内核空间的标准进程（线程），内核线程（进程）和普通进程之间的最大区别是内核线程没有独立的地址空间（task_struct的mm域，即地址空间域为NULL），他们只在内核空间运行，不会切换到用户空间。实际上内核线程会使用上一个运行的进程的地址空间，因为用户空间和内核空间是分开的，所以不会产生冲突。内核线程和普通进程一样可以被调度和抢占。只有内核线程可以创建新的内核线程，内核线程通常是在系统启动时被创建的。</p><h2 id="1-5-进程终结"><a href="#1-5-进程终结" class="headerlink" title="1.5 进程终结"></a>1.5 进程终结</h2><ul><li><p>通常进程的终结发生在exit()系统调用时，进程可能显示地调用这个系统调用，也可能隐式地调用（C编译器会在main函数return点后面插入exit语句）。当进程接收到一个终结信号或者发生进程无法处理也不能忽略的异常时，进程会被动地终结。终结进程的大部分工作是在do_exit()中完成的，do_exit()会释放进程占用的资源。包括</p><ol><li>释放地址空间结构mm_struct（如果没有共享，这就会彻底释放该地址空间对象）。</li><li>将使用的文件描述符、文件系统的引用计数减1。</li><li>向父进程发送信号，并给当前进程的子进程寻找新的父亲。-</li><li>将进程描述符task_struct的exit_state设为EXIT_ZOMBIE（僵尸进程），成为僵尸进程。</li></ol></li><li><p>至此进程在内存只有内核栈、thread_info结构、task_struct结构。作为僵尸进程存在的唯一目的就是为父进程提供信息。</p></li><li><p>父进程调用wait函数族(最终使用wait4()实现）并被阻塞，当有一个子进程退出时，函数会返回，并提供子进程的相关信息。release_task()会被调用，彻底释放和该进程所有的数据结构（包括进程描述符、tread_info结构、内核栈）和剩下的资源。</p></li></ul><h3 id="僵尸进程与孤儿进程"><a href="#僵尸进程与孤儿进程" class="headerlink" title="僵尸进程与孤儿进程"></a>僵尸进程与孤儿进程</h3><ul><li>如果父进程先于子进程退出，子进程会成为孤儿进程。此时必须给子进程找到新的进程作为父进程，否则当没有父进程的子进程退出时，因为没有父进程收尸，子进程会永远作为僵尸进程存在于系统中，浪费资源。Linux内核对此的处理方法是在当前线程组中为子进程寻找一个线程作为父亲，如果不行（比如当前线程组没有其他线程），就让init做父进程。init进程会例行地调用wait()来清除僵尸子进程。</li></ul><h2 id="1-6-多进程和多线程的应用场景"><a href="#1-6-多进程和多线程的应用场景" class="headerlink" title="1.6 多进程和多线程的应用场景"></a>1.6 多进程和多线程的应用场景</h2><h3 id="1-6-1-优势场景"><a href="#1-6-1-优势场景" class="headerlink" title="1.6.1 优势场景"></a>1.6.1 优势场景</h3><ul><li><p>多进程模型的优势是CPU，多线程模型的优势是线程间切换代价较小</p></li><li><p>多线程模型适用于I&#x2F;O密集型的工作场景，因此I&#x2F;O密集型的工作场景经常会由于I&#x2F;O阻塞导致频繁的切换线程。同时，多线程模型也适用于单机多核分布式场景。</p></li><li><p>多进程模型，适用于CPU密集型。同时，多进程模型也适用于多机分布式场景中，易于多机扩展。</p></li></ul><h3 id="1-6-2-多进程的优点"><a href="#1-6-2-多进程的优点" class="headerlink" title="1.6.2 多进程的优点"></a>1.6.2 多进程的优点</h3><ol><li>编程相对容易；通常不需要考虑锁和同步资源的问题。</li><li>更强的容错性：比起多线程的一个好处是一个进程崩溃了不会影响其他进程。</li><li>有内核保证的隔离：数据和错误隔离。 对于使用如C&#x2F;C++这些语言编写的本地代码，错误隔离是非常有用的：采用多进程架构的程序一般可以做到一定程度的自恢复；（master守护进程监控所有worker进程，发现进程挂掉后将其重启）。</li></ol><h3 id="1-6-3-多线程的优点"><a href="#1-6-3-多线程的优点" class="headerlink" title="1.6.3 多线程的优点"></a>1.6.3 多线程的优点</h3><ol><li>创建速度快，方便高效的数据共享。多线程间可以共享同一虚拟地址空间；多进程间的数据共享就需要用到共享内存、信号量等IPC技术。</li><li>较轻的上下文切换开销，不用切换地址空间，不用更改寄存器，不用刷新TLB。</li><li>提供非均质的服务。如果全都是计算任务，但每个任务的耗时不都为1s，而是1ms-1s之间波动；这样，多线程相比多进程的优势就体现出来，它能有效降低“简单任务被复杂任务压住”的概率。</li></ol><h3 id="1-6-4-应用场景"><a href="#1-6-4-应用场景" class="headerlink" title="1.6.4 应用场景"></a>1.6.4 应用场景</h3><p><strong>多进程应用场景</strong></p><ul><li><p>nginx主流的工作模式是多进程模式（也支持多线程模型）。几乎所有的web server服务器服务都有多进程的，至少有一个守护进程配合一个worker进程，例如apached,httpd等等以d结尾的进程包括init.d本身就是0级总进程，所有你认知的进程都是它的子进程；</p></li><li><p>chrome浏览器也是多进程方式。（原因：①可能存在一些网页不符合编程规范，容易崩溃，采用多进程一个网页崩溃不会影响其他网页；而采用多线程会。②网页之间互相隔离，保证安全，不必担心某个网页中的恶意代码会取得存放在其他网页中的敏感信息。）</p></li><li><p>redis也可以归类到“多进程单线程”模型（平时工作是单个进程，涉及到耗时操作如持久化或aof重写时会用到多个进程）</p></li></ul><p><strong>多线程应用场景</strong></p><ul><li>线程间有数据共享，并且数据是需要修改的（不同任务间需要大量共享数据或频繁通信时）。<br>提供非均质的服务（有优先级任务处理）事件响应有优先级。</li><li>单任务并行计算，在非CPU Bound的场景下提高响应速度，降低时延。与人有IO交互的应用，良好的用户体验（键盘鼠标的输入，立刻响应）</li><li>案例：桌面软件，响应用户输入的是一个线程，后台程序处理是另外的线程；memcached。</li></ul><h1 id="二、进程调度"><a href="#二、进程调度" class="headerlink" title="二、进程调度"></a>二、进程调度</h1><h2 id="2-1-基本概念"><a href="#2-1-基本概念" class="headerlink" title="2.1 基本概念"></a>2.1 基本概念</h2><ul><li>多任务系统分为抢占式多任务和非抢占式多任务</li><li>在抢占式的模式下，由调度程序决定何时停止一个进程的执行，这个强制挂起的动作就是<strong>抢占</strong></li><li>进程被抢占之前能运行的时间是预先设置好的，叫做进程<strong>时间片</strong></li><li>进程主动挂起自己的操作叫做<strong>让步</strong></li></ul><h2 id="2-2-Linux的进程调度"><a href="#2-2-Linux的进程调度" class="headerlink" title="2.2 Linux的进程调度"></a>2.2 Linux的进程调度</h2><ul><li><p>Linux 进程调度算法经历了以下几个版本的发展：</p><ul><li>基于时间片轮询调度算法。(2.6之前的版本)</li><li>O(1) 调度算法。(2.6.23之前的版本)</li><li>完全公平调度算法。(2.6.23以及之后的版本)</li></ul></li><li><p>O(1)调度程序可以在恒定时间内完成调度工作，采用静态时间片算法和针对每一个处理器的运行队列。但是其对相应时间敏感的程序（交互程序）存在先天不足</p></li></ul><h3 id="调度策略"><a href="#调度策略" class="headerlink" title="调度策略"></a>调度策略</h3><ul><li>I&#x2F;O消耗型和CPU消耗型进程，一般来说I&#x2F;O消耗型是需要及时响应但只运行较短的时间，而CPU消耗型需要更多的CPU时间但不关心相应速度</li><li>Linux有两种优先级范围：<ul><li>nice值，范围在[-20, 19]，在Unix系统中是标准化概念，一般越低代表获得的时间片越多。但是在不同的系统实现中因为调度算法的差异，具体含义不同，如在MacOS表示分配给进程的时间片绝对值；在Linux中代表分配时间片的比例。</li><li>实时优先级，范围在[0, 99]，数字越大代表优先级越高，任何实时进程的优先级高于普通进程，与nice值不是一个层面的。普通任务的实时优先级在[100, 139]</li></ul></li><li>三种调度类：Deadline、Realtime、Fair</li></ul><div style="text-align:center;">    <img src="调度类.webp" alt="调度类.webp" width="397" height="177" class="jop-noMdConv"></div><ul><li><p>Deadline 和 Realtime 这两个调度类，都是应用于实时任务的，这两个调度类的调度策略合起来共有这三种，它们的作用如下：</p><ul><li>SCHED_DEADLINE：是按照 deadline 进行调度的，距离当前时间点最近的 deadline 的任务会被优先调度；</li><li>SCHED_FIFO：对于相同优先级的任务，按先来先服务的原则，但是优先级更高的任务，可以抢占低优先级的任务，也就是优先级高的可以「插队」；</li><li>SCHED_RR：对于相同优先级的任务，轮流着运行，每个任务都有一定的时间片，当用完时间片的任务会被放到队列尾部，以保证相同优先级任务的公平性，但是高优先级的任务依然可以抢占低优先级的任务；</li></ul></li><li><p>而 Fair 调度类是应用于普通任务，都是由 CFS 调度器管理的，分为两种调度策略：</p><ul><li>SCHED_NORMAL：普通任务使用的调度策略；</li><li>SCHED_BATCH：后台任务的调度策略，不和终端进行交互，因此在不影响其他需要交互的任务，可以适当降低它的优先级。</li></ul></li><li><p>Linux在进行调度的时候首先根据调度类的优先级进行调度，策略是拥有一个可执行进程的最高优先级的调度类胜出</p></li></ul><h2 id="2-3-完全公平调度算法-CFS"><a href="#2-3-完全公平调度算法-CFS" class="headerlink" title="2.3 完全公平调度算法 CFS"></a>2.3 完全公平调度算法 CFS</h2><h3 id="2-3-1-CFS调度理论"><a href="#2-3-1-CFS调度理论" class="headerlink" title="2.3.1 CFS调度理论"></a>2.3.1 CFS调度理论</h3><ul><li><p>CFS并不会划分固定的时间片给进程，而只将处理器的使用比划分给进程，那么进程可以获得的处理器时间就是和系统负载密切相关的，同时这个比例会进一步受到nice值的影响</p></li><li><p>在这种按照比例进行划分的模式下，因为I&#x2F;O消耗型的程序更多时间是被阻塞的，并不会占用很多的时间片，而CPU消耗型会占用很多的时间片。当两种程序都在就绪状态时，调度器为了保证公平性自然而然会优先调度I&#x2F;O消耗型的程序</p></li><li><p>在Unix系统中采用的是nice值对应固定的时间片的方案进行调度的，这种方案存在如下的一些问题：</p><ol><li>nice值代表着优先级，高优先级必然对应着跟大的时间片，但是我们知道往往是CPU消耗型程序分配到低优先级，当系统中有多个相同低优先级的程序在运行时，尽管他们分配的时间片都是相同的，但是因为时间片都很小，这个时候会面临频繁切换程序的问题，影响CPU的利用率，这与CPU消耗型程序需要更长时间片初衷背道而驰（减少上下文切换可以增加缓存利用率）。</li><li>如果有两个进程的nice值分别为0和1对应100ms和95ms的时间片，而对于nice值分别为18和19的程序对应的时间片为10ms和5ms（前者是后者时间片的两倍）。尽管两个例子的nice值差距都是1，但是造成的时间片分配比例的变化相差却非常大。</li><li>绝对时间片的分配必须是定时器节拍的整数倍，因此两个时间片的差距至少为一个节拍（多则10ms，少则1ms）；时间片还会随着定时器节拍改变</li><li>用户可以通过设置很高优先级达到让进程更快投入运行的目的，这为玩弄调度器留下了后门，打破了公平性的原则</li></ol></li><li><p>这些问题的核心原因是分配绝对时间片引发的固定的切换频率给公平性造成的很大变数。而CFS摒弃时间片而是给进程处理器的使用比例，将切换频率置于不断变动中。</p></li><li><p>公平调度的理想状态是在任意小的时间片段内，每个任务所分配到的时间都是遵守优先级所设定的时间比例的，要实现这个目标需要调度周期无限小。CFS为了贴近这种理想状态设定了一个无限小调度周期的近似值——目标延迟。而CFS对运行时间进行划分的就是这个“目标延迟”</p></li><li><p>如果目标延迟是20ms，两个相同优先级（nice&#x3D;0）的进程将各自分配到10ms的运行时间；而如果这两个进程的nice&#x3D;19，依然是各运行10ms。这是CFS的重要特性，绝对的nice值不会影响调度决策，只有相对值才会影响处理器时间的分配比例。</p></li><li><p>当进程非常多时会导致每个进程被分到的运行时间非常短，有一个时间片底线称为最小粒度，默认值是1ms</p></li></ul><h3 id="2-3-2-CFS调度实现"><a href="#2-3-2-CFS调度实现" class="headerlink" title="2.3.2 CFS调度实现"></a>2.3.2 CFS调度实现</h3><ul><li>CFS由四个组件组成：<ul><li>时间记账（Time Counting）</li><li>进程选择（Process Selection）</li><li>调度程序入口（The Scheduler Entry Point）</li><li>睡眠和唤醒（Sleeping and Waking Up）</li></ul></li></ul><h4 id="时间记账"><a href="#时间记账" class="headerlink" title="时间记账"></a>时间记账</h4><ul><li><p>nice值并不是表示优先级，而是表示优先级的修正数值，其被映射到 100~139，这个范围是提供给普通任务用的，因此 nice 值调整的是普通任务的优先级。</p></li><li><p>CFS通过sched_entity中的vruntime保存进程的虚拟运行时间，内核使用update_curr()函数来更新运行进程的vruntime，系统时钟（system timer）会定期调用update_curr()，此外每当有进程进入runnable状态或者blocked状态时，也会调用update_curr()来更新vruntime。</p></li></ul><blockquote><p>实际运行时间 &#x3D; 调度周期 * 进程权重 &#x2F; 所有进程权重之和</p><p>虚拟运行时间 &#x3D; 实际运行时间 * 1024 &#x2F; 进程权重<br>= (调度周期 * 进程权重 &#x2F; 所有进程权重之和) * 1024 &#x2F; 进程权重<br>= 调度周期 * 1024 &#x2F; 所有进程总权重</p></blockquote><ul><li>从上面的公式可以看出，在一个调度周期里，所有进程的虚拟运行时间是相同的。所以在进程调度时，只需要找到虚拟运行时间最小的进程调度运行即可。</li></ul><h4 id="进程选择"><a href="#进程选择" class="headerlink" title="进程选择"></a>进程选择</h4><ul><li><p>因此要达到公平调度，简单来说就是让每个进程的vruntime相同，但是我们可以使vruntime尽可能的接近，所以CFS每次会选择vruntime最小的进程来运行。</p></li><li><p>CFS使用红黑树来管理所有处于runnable状态的进程，使用进程的vruntime作为红黑树的key（实际上，CFS并不会每次对红黑树进程查找，它使用rb_leftmost来缓存最左边的节点）</p></li><li><p>每当有进程进入runnable状态或者通过fork()创建了一个新的进程时，CFS就会将该进程加入红黑树。每当有进程进入blocked状态或者停止执行（terminate）时，CFS会将该进程从红黑树中移除。</p></li></ul><h4 id="调度程序入口"><a href="#调度程序入口" class="headerlink" title="调度程序入口"></a>调度程序入口</h4><ul><li>最主要的调度程序入口是schedule()函数。schedule()函数会找到优先级最高的调度类（scheduler class），并从该调度类获得下一个要运行的进程，如果该调度类没有runnable进程，就会检查优先级次高的调度类，以此类推。</li></ul><h4 id="睡眠和唤醒"><a href="#睡眠和唤醒" class="headerlink" title="睡眠和唤醒"></a>睡眠和唤醒</h4><ul><li>睡眠状态（sleeping），即阻塞状态（blocked）是一种特殊的不可运行（nonrunnable）状态。进程进入睡眠状态的原因多种多样，比如等待I&#x2F;O完成或者是请求的资源暂时无法获得等。不管是什么情况，在内核中的表现是一样的：进程将自己标识为sleeping，将自己加入等待队列（wait queue），并将自己从runnable进程的红黑树中移除，然后调用schedule()，让调度器选择一个新的进程去执行。</li><li>唤醒（waking up）是相反的：进程被标识为runnable，被从wait queue中移除，并插入runnable进程红黑树中（不一定马上运行，需要调度器选中它才可以运行）。</li><li>等待队列(wait queue)有很多个，每个等待队列存储等待某个特定事件的所有进程。当某个事件发生时，内核会唤醒该事件对应的等待队列上的所有进程。通常是导致该事件发生的代码调用wake_up()来唤醒该数据的等待队列上的所有进程。比如当磁盘中的数据读取完成时，VFS会调用wake_up（）。</li></ul><h3 id="2-3-3-关于vruntime的补充"><a href="#2-3-3-关于vruntime的补充" class="headerlink" title="2.3.3 关于vruntime的补充"></a>2.3.3 关于vruntime的补充</h3><h4 id="新建进程的vruntime的初值是不是0？"><a href="#新建进程的vruntime的初值是不是0？" class="headerlink" title="新建进程的vruntime的初值是不是0？"></a>新建进程的vruntime的初值是不是0？</h4><blockquote><p>我们先考虑另一个问题，通过fork()创建的新进程的vruntime如果是0会怎么样？就绪队列上所有的进程的vruntime都已经是很大的一个值。如果新建进程的vruntime的值是0的话，根据CFS调度器pick_next_task_fair()逻辑，我们会倾向选择新建进程，一直让其更多的运行，追赶上就绪队列中其他进程的vruntime。既然不能是0，初值应该是什么比较合理呢？当然是和就绪队列上所有进程的vruntime的值差不多。具体怎么操作，下个问题揭晓。</p></blockquote><h4 id="就绪队列记录的min-vruntime的作用是什么？"><a href="#就绪队列记录的min-vruntime的作用是什么？" class="headerlink" title="就绪队列记录的min_vruntime的作用是什么？"></a>就绪队列记录的min_vruntime的作用是什么？</h4><blockquote><p>首先我们需要明白的是min_vruntime记录的究竟是什么。min_vruntime记录的是就绪队列管理的所有进程的最小虚拟时间。理论上来说，所有的进程的虚拟时间都大于min_vruntime。记录这个时间有什么用呢？我认为主要有3点作用。</p><ul><li>当我们fork()一个新的进程的时候，虚拟时间肯定不能赋值0。否则的话，新建的进程会追赶其他进程，直到和就绪队列上其他进程的虚拟时间相当。这当然是不公平的，也是不可合理的设计。所以针对新fork()的进程，我们根据min_vruntime的值适当调整后赋值给新进程的虚拟时间。这样就不会出现新建的进程疯狂的运行。</li><li>当进程sleep一段时间被wakeup的时候，此时也仅是物是人非。同样面临着类似新建进程的境况。同样我们需要根据min_vruntime的值适当调整后赋值给该进程。</li><li>针对migration进程，我们面临一个新的问题。每个CPU上就绪队列的min_vruntime的值各不相同。有可能相差很多。如果进程从CPU0迁移到CPU1的话，进程的vruntime是否应该改变呢？当时是需要的，否则就会面临迁移后受到惩罚或者奖励。我们的方法是进程进程的vruntime减去CPU0的min_vruntime，然后加上CPU1的min_vruntime。</li></ul></blockquote><h4 id="唤醒的进程的vruntime该如何处理？"><a href="#唤醒的进程的vruntime该如何处理？" class="headerlink" title="唤醒的进程的vruntime该如何处理？"></a>唤醒的进程的vruntime该如何处理？</h4><blockquote><p>经过上一个问题，我们应该有点答案了。如果睡眠时间很长，自然是根据min_vruntime的值处理。问题是我们该如何处理？我们会根据min_vruntime的值减去一个数值作为唤醒进程的vruntime。为何减去一个值呢？我认为该进程已经sleep很长时间，本身就没有太占用CPU时间。给点补偿也是正常的。大多数的交互式应用，基本都是属于这种情况。这样处理，又<strong>提高了交互式应用的相应速度</strong>。如果sleep时间很短呢？当然是不需要干涉该进程的vruntime。</p></blockquote><h4 id="就绪队列上所有的进程的vruntime都一定大于min-vruntime吗？"><a href="#就绪队列上所有的进程的vruntime都一定大于min-vruntime吗？" class="headerlink" title="就绪队列上所有的进程的vruntime都一定大于min_vruntime吗？"></a>就绪队列上所有的进程的vruntime都一定大于min_vruntime吗？</h4><blockquote><p>答案当然不是的。我们虽然引入min_vruntime的意义是最终就绪队列上所有进程的最小虚拟时间，但是并不能代表所有的进程vruntime都大于min_vruntime。这个问题在部分的情况下是成立的。例如，上面提到给唤醒进程vruntime一定的补偿，就会出现唤醒的进程的vruntime的值小于min_vruntime。</p></blockquote><h4 id="唤醒的进程会抢占当前正在运行的进程吗？"><a href="#唤醒的进程会抢占当前正在运行的进程吗？" class="headerlink" title="唤醒的进程会抢占当前正在运行的进程吗？"></a>唤醒的进程会抢占当前正在运行的进程吗？</h4><blockquote><p>分成两种情况，这个取决于唤醒抢占特性是否打开。即sched_feat的WAKEUP_PREEMPTION。如果没有打开唤醒抢占特性，那么就没有后话了。现在考虑该特性打开的情况。由于唤醒的进程会根据min_vruntime的值进行一定的奖励，因此存在很大的可能vruntime小于当前正在运行进程的vruntime。当时是否意味着只要唤醒进程的vruntime比当前运行进程的vruntime小就抢占呢？并不是。我们既要满足小的条件，又要在此基础上附加条件。两者差值必须大于唤醒粒度时间。该时间存在变量<code>sysctl_sched_wakeup_granularity</code>中，默认值1ms。</p></blockquote><h2 id="2-4-上下文切换"><a href="#2-4-上下文切换" class="headerlink" title="2.4 上下文切换"></a>2.4 上下文切换</h2><ul><li><p>CPU从一个进程切换到另一个进程需要进行上下文切换，schedule()会调用context_switch()函数来完成上下文切换。</p><ul><li>该函数首先会调用switch_mm()将虚拟内存映射从上一个进程的切换到下一个进程的（这意味着TLB的内容全部失效了，需要从0开始缓冲。对TLB切换的一个优化是保留上一个进程除高端内存的内核空间地址映射，因为这部分对所有进程来说是一样的，都是直接线性映射）</li><li>然后调用switch_to()来保存上一个进程的处理器状态并恢复下一个进程的处理器状态，包括栈信息、处理器寄存器和其他架构相关的每个进程自有（per-process）的处理器状态。</li></ul></li><li><p>进程和线程发生上下文切换的区别：</p><ul><li>对于Linux来说，线程相比于进程的差距就在资源共享上，尤其是内存地址空间上的共享。而程序运行对虚拟内存地址进行映射的方式是页表，此外还有缓存地址转换结果的TLB。进程在进行切换时需要切换内存地址空间，包括内存地址、页表和内核资源、处理器中的缓存，部分TLB和内存的CacheLine缓存也会失效。</li><li>而线程因为是共享地址空间的，切换只涉及切换身份和资源，例如程序计数器、寄存器和堆栈指针。线程到线程切换的成本和进出内核的成本差不多。</li><li><strong>进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。</strong></li><li><strong>两个线程是属于同一个进程时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据</strong>；</li></ul></li><li><p>中断上下文切换，中断处理程序并不具有自己的栈，而是共享所中断程序的内核栈。因此中断上下文切换，并不需要保存和恢复进程的虚拟内存等用户态资源，只需要处理 CPU 寄存器、内核堆栈等内核态的资源即可。</p></li></ul><h1 id="三、进程间通信方式"><a href="#三、进程间通信方式" class="headerlink" title="三、进程间通信方式"></a>三、进程间通信方式</h1><h2 id="3-1-管道"><a href="#3-1-管道" class="headerlink" title="3.1 管道"></a>3.1 管道</h2><ul><li>一种类型是<strong>命名管道</strong>，也被叫做 <code>FIFO</code>，因为数据是先进先出的传输方式。在使用命名管道前，先需要通过 <code>mkfifo</code> 命令来创建，并且指定管道名字。基于 Linux 一切皆文件的理念，所以管道也是以文件的方式存在，我们可以用 ls 看一下，这个文件的类型是 p，也就是 pipe（管道） 的意思。</li><li>另外一种类型是匿名管道，在代码中通过系统调用<code>int pipe(int fd[2])</code>创建，这个匿名管道是特殊的文件，只存在于内存，不存于文件系统中。使用 <code>fork</code> 创建子进程，创建的子进程会复制父进程的文件描述符，这样就做到了两个进程各有两个「 <code>fd[0]</code> 与 <code>fd[1]</code>」，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信了。</li><li>所谓的管道，就是内核里面的一串缓存。从管道的一端写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。</li><li>对于匿名管道，它的通信范围是存在父子关系的进程。对于命名管道，它可以在不相关的进程间也能相互通信。提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。</li></ul><h2 id="3-2-消息队列"><a href="#3-2-消息队列" class="headerlink" title="3.2 消息队列"></a>3.2 消息队列</h2><ul><li>消息队列是保存在内核中的消息链表，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。</li><li>消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。</li><li>消息队列不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 <code>MSGMAX</code> 和 <code>MSGMNB</code>，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。</li><li>消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。</li></ul><h2 id="3-3-共享内存"><a href="#3-3-共享内存" class="headerlink" title="3.3 共享内存"></a>3.3 共享内存</h2><ul><li>消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那共享内存的方式，就很好的解决了这一问题。</li><li>共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。</li></ul><h2 id="3-4-信号量"><a href="#3-4-信号量" class="headerlink" title="3.4 信号量"></a>3.4 信号量</h2><h3 id="3-4-1-基本概念"><a href="#3-4-1-基本概念" class="headerlink" title="3.4.1 基本概念"></a>3.4.1 基本概念</h3><ul><li>信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步。</li><li>信号量表示资源的数量，控制信号量的方式有两种原子操作：<ul><li>一个是 <strong>P 操作</strong>，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;&#x3D; 0，则表明还有资源可使用，进程可正常继续执行。</li><li>另一个是 <strong>V 操作</strong>，这个操作会把信号量加上 1，相加后如果信号量 &lt;&#x3D; 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程；</li></ul></li><li>互斥体（或者说mutex）其实就是计数1的信号量，可以保证共享资源在任何时刻只有一个进程在访问。</li><li>信号初始化为 <code>0</code>，就代表着是同步信号量，它可以保证进程 A 应在进程 B 之前执行。</li></ul><h3 id="3-4-2-信号量实现"><a href="#3-4-2-信号量实现" class="headerlink" title="3.4.2 信号量实现"></a>3.4.2 信号量实现</h3><blockquote><p>参考资料：</p><p><a href="https://blog.csdn.net/weixin_45605341/article/details/137403648">C++20 semaphore(信号量) 详解</a></p><p><a href="https://www.cnblogs.com/lethe1203/p/18113883">进程间通信（4）-信号量</a></p></blockquote><ul><li>按照进程同步和线程同步的区别可以将信号量分为两种：一个是在C++这样的语言层实现的信号量<code>std::counting_semaphore</code>，只能在多线程中使用；另一个是Linux中为多进程提供同步功能的信号量<code>System V</code>信号量和<code>POSIX</code>信号量。</li></ul><h4 id="System-V-信号量"><a href="#System-V-信号量" class="headerlink" title="System V 信号量"></a>System V 信号量</h4><ul><li><code>System V</code> 信号量是最早引入 <code>Linux</code> 的一种进程间通信机制，它使用 <code>semget</code>、<code>semctl</code> 和 <code>semop</code> 等函数进行操作。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">semget</span><span class="hljs-params">(<span class="hljs-type">key_t</span> key, <span class="hljs-type">int</span> num_sems, <span class="hljs-type">int</span> sem_flags)</span></span>; <span class="hljs-comment">// 创建或获取信号量集</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">semctl</span><span class="hljs-params">(<span class="hljs-type">int</span> semid, <span class="hljs-type">int</span> sem_num, <span class="hljs-type">int</span> cmd, ...)</span></span>;<span class="hljs-comment">// 控制信号量集</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">semop</span><span class="hljs-params">(<span class="hljs-type">int</span> semid, <span class="hljs-keyword">struct</span> sembuf *sops, <span class="hljs-type">size_t</span> nsops)</span></span>;<span class="hljs-comment">// 对信号量集进行操作</span><br></code></pre></td></tr></table></figure><h4 id="POSIX-信号量"><a href="#POSIX-信号量" class="headerlink" title="POSIX 信号量"></a>POSIX 信号量</h4><ul><li><code>POSIX</code>信号量是一种较新的信号量实现，它更加简单和易用，更适合于现代的多线程应用程序和多进程应用程序，因为它提供了更简单的接口和更好的可移植性。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 创建或打开信号量，这里的name使用文件路径，这样就可以保证不相关的多进程共同访问了</span><br><span class="hljs-function"><span class="hljs-type">sem_t</span> *<span class="hljs-title">sem_open</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *name, <span class="hljs-type">int</span> oflag, <span class="hljs-type">mode_t</span> mode, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> value)</span></span>;<br><span class="hljs-comment">// 关闭信号量</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">sem_close</span><span class="hljs-params">(<span class="hljs-type">sem_t</span> *sem)</span></span>;<br><span class="hljs-comment">// 销毁信号量</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">sem_unlink</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *name)</span></span>;<br><span class="hljs-comment">// 等待（阻塞）信号量</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">sem_wait</span><span class="hljs-params">(<span class="hljs-type">sem_t</span> *sem)</span></span>;<br><span class="hljs-comment">// 增加信号量的值</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">sem_post</span><span class="hljs-params">(<span class="hljs-type">sem_t</span> *sem)</span></span>;<br></code></pre></td></tr></table></figure><h2 id="3-5-信号"><a href="#3-5-信号" class="headerlink" title="3.5 信号"></a>3.5 信号</h2><ul><li>对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。</li><li>在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 <code>kill -l</code> 命令，查看所有的信号：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">kill</span> -l</span><br> 1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP<br> 6) SIGABRT      7) SIGBUS       8) SIGFPE       9) SIGKILL     10) SIGUSR1<br>11) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM<br>16) SIGSTKFLT   17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP<br>21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU     25) SIGXFSZ<br>26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGIO       30) SIGPWR<br>31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3<br>38) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8<br>43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13<br>48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12<br>53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7<br>58) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2<br>63) SIGRTMAX-1  64) SIGRTMAX<br></code></pre></td></tr></table></figure><ul><li><p>运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如</p><ul><li><p>Ctrl+C 产生 <code>SIGINT</code> 信号，表示终止该进程；</p></li><li><p>Ctrl+Z 产生 <code>SIGTSTP</code> 信号，表示停止该进程，但还未结束；</p></li></ul></li><li><p>如果进程在后台运行，可以通过 <code>kill</code> 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如：</p><ul><li>kill -9 1050 ，表示给 PID 为 1050 的进程发送 <code>SIGKILL</code> 信号，用来立即结束该进程；</li></ul></li><li><p>所以，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。</p></li><li><p>信号是进程间通信机制中<strong>唯一的异步通信机制</strong>，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。</p><ol><li><p>执行默认操作。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。</p></li><li><p>捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。</p></li><li><p>忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 <code>SIGKILL</code> 和 <code>SEGSTOP</code>，它们用于在任何时候中断或结束某一进程。</p></li></ol></li></ul><h2 id="3-6-socket"><a href="#3-6-socket" class="headerlink" title="3.6 socket"></a>3.6 socket</h2><ul><li>创建 socket 的系统调用：</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">socket</span><span class="hljs-params">(<span class="hljs-type">int</span> domain, <span class="hljs-type">int</span> type, <span class="hljs-type">int</span> protocal)</span><br></code></pre></td></tr></table></figure><ul><li><p>三个参数分别代表：</p><ul><li><p>domain 参数用来指定协议族，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL&#x2F;AF_UNIX 用于本机；</p></li><li><p>type 参数用来指定通信特性，比如 SOCK_STREAM 表示的是字节流，对应 TCP；SOCK_DGRAM 表示的是数据报，对应 UDP；SOCK_RAW 表示的是原始套接字。</p></li><li><p>protocal 参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可；</p></li></ul></li><li><p>根据创建 socket 类型的不同，通信的方式也就不同：</p><ul><li><p>实现 TCP 字节流通信： socket 类型是 AF_INET 和 SOCK_STREAM；</p></li><li><p>实现 UDP 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM；</p></li><li><p>实现本地进程间通信： 「本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM，「本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM。另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket；</p></li></ul></li><li><p>本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件。本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux:高速缓存</title>
    <link href="/2024/05/12/Linux-%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98/"/>
    <url>/2024/05/12/Linux-%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本篇作为列存模型的前置内容，主要分析L1,L2,L3 Cache的基本原理</p><p>参考资料：</p><ol><li><a href="https://zhuanlan.zhihu.com/p/102293437">Cache的基本原理</a></li><li><a href="https://zhuanlan.zhihu.com/p/107096130">Cache组织方式</a></li><li><a href="https://zhuanlan.zhihu.com/p/108425561">TLB原理</a></li></ol></blockquote><h1 id="一、Cache"><a href="#一、Cache" class="headerlink" title="一、Cache"></a>一、Cache</h1><div style="text-align:center;">    <img src="cpu缓存架构.png" alt="cpu缓存架构.png" width="475" height="257" class="jop-noMdConv"></div><ul><li>现代的CPU都普遍存在L1、L2、L3三层Cache用于缓解CPU和DRAM之间的较大速度差距</li><li>在Cortex-A53架构上，L1 Cache分为单独的instruction cache（ICache）和data cache（DCache），并且为每个CPU私有；一个cluster内的所有CPU共享一个L2 cache，不区分指令和数据；所有cluster之间共享L3 cache，通过总线和主存相连。</li><li>对Cache的访问只能按照某一特定的块进行，其为Cache Line，一般大小为4-128 Byts。Cache和DRAM之间的数据交换也只能遵守Cache Line的大小。</li></ul><p><strong>硬件访问速度</strong></p><table><thead><tr><th align="center">存储器</th><th align="center">介质</th><th align="center">随机访问时延</th></tr></thead><tbody><tr><td align="center">L<sub>1</sub> Cache</td><td align="center">SRAM</td><td align="center">0.5ns</td></tr><tr><td align="center">L<sub>2</sub> Cache</td><td align="center">SRAM</td><td align="center">4ns</td></tr><tr><td align="center">L<sub>3</sub> Cache</td><td align="center">SRAM</td><td align="center">20ns</td></tr><tr><td align="center">Memory</td><td align="center">DRAM</td><td align="center">100ns</td></tr><tr><td align="center">NVM</td><td align="center"></td><td align="center">1us</td></tr><tr><td align="center">Disk</td><td align="center">SSD</td><td align="center">150us</td></tr><tr><td align="center">Disk</td><td align="center">HDD</td><td align="center">10ms</td></tr></tbody></table><h2 id="1-1-映射模式"><a href="#1-1-映射模式" class="headerlink" title="1.1 映射模式"></a>1.1 映射模式</h2><h3 id="1-1-1-直接映射缓存-Direct-mapped-cache"><a href="#1-1-1-直接映射缓存-Direct-mapped-cache" class="headerlink" title="1.1.1 直接映射缓存(Direct mapped cache)"></a>1.1.1 直接映射缓存(Direct mapped cache)</h3><div style="text-align:center;">    <img src="直接映射.webp" alt="直接映射.webp" width="572" height="293" class="jop-noMdConv"></div><ul><li>首先假设Cache Size为64byte，Cache Line为8byte。在这种情况下我们可以算得一共有8个Cache Line，因此需要3bit对Cache Line进行索引。因此对于一个32位内存地址<code>bit&lt;31:0&gt;</code>，<code>bit&lt;2:0&gt;</code>称为offset用于指定Cache Line中的某个具体字节，<code>bit&lt;5:3&gt;</code>称为index用于索引某个Cache Line</li><li>而每个Cache Line都对应着一个<code>tag</code>，用于存放<code>bit&lt;31:6&gt;</code>，每当对一个地址通过index查询到Cache Line之后需要与<code>tag</code>进行对比以确定该Cache Line中确实存放的这个内存地址中的数据。</li></ul><p><strong>优缺点</strong></p><ul><li>硬件设计最为简单，成本最低</li><li>很显然一个内存地址只会被映射到一个固定的Cache Line位置上，如果反复访问的两个列存地址其index指向同一个Cache Line，那么会造成对这一个缓存位置的争抢，从而造成对缓存的反复排出和读入，即使缓存还有大量的空间。这种现象叫做缓存颠簸（cache thrashing）</li></ul><h3 id="1-1-2-两路组相连缓存-Two-way-set-associative-cache"><a href="#1-1-2-两路组相连缓存-Two-way-set-associative-cache" class="headerlink" title="1.1.2 两路组相连缓存(Two-way set associative cache)"></a>1.1.2 两路组相连缓存(Two-way set associative cache)</h3><div style="text-align:center;">    <img src="两路组相连.webp" alt="两路组相连.webp" width="710" height="251" class="jop-noMdConv"></div><ul><li>为了缓解缓存颠簸的问题，我们可以将缓存进行分组（分成多路），我们依然通过index查询到Cache Line，但是我们此时有多路可以选择，因此需要同时比较多路所对应的多个<code>tag</code>，找到真正对应的那个Cache Line</li><li>从某种程度上来说，直接映射缓存是组相连缓存的一种特殊情况，每个组只有一个cache line而已。因此，直接映射缓存也可以称作单路组相连缓存</li></ul><h3 id="1-1-3-全相连缓存-Full-associative-cache"><a href="#1-1-3-全相连缓存-Full-associative-cache" class="headerlink" title="1.1.3 全相连缓存(Full associative cache)"></a>1.1.3 全相连缓存(Full associative cache)</h3><div style="text-align:center;">    <img src="全相连.webp" alt="全相连.webp" width="480" height="272" class="jop-noMdConv"></div><h2 id="1-2-更新策略"><a href="#1-2-更新策略" class="headerlink" title="1.2 更新策略"></a>1.2 更新策略</h2><h3 id="1-2-1-写直通-write-through"><a href="#1-2-1-写直通-write-through" class="headerlink" title="1.2.1 写直通(write through)"></a>1.2.1 写直通(write through)</h3><ul><li>当CPU执行store指令并在cache命中时，我们更新cache中的数据并且更新主存中的数据。<strong>cache和主存的数据始终保持一致</strong>。</li></ul><h3 id="1-2-2-写回-write-back"><a href="#1-2-2-写回-write-back" class="headerlink" title="1.2.2 写回(write back)"></a>1.2.2 写回(write back)</h3><ul><li>当CPU执行store指令并在cache命中时，我们只更新cache中的数据。并且每个cache line中会有一个bit位记录数据是否被修改过，称之为dirty bit，我们将dirty bit置位。</li><li>主存中的数据只会在cache line被替换或者显示的clean操作时更新。因此，主存中的数据可能是未修改的数据，而修改的数据躺在cache中。<strong>cache和主存的数据可能不一致。</strong></li></ul><h2 id="1-3-组织方式"><a href="#1-3-组织方式" class="headerlink" title="1.3 组织方式"></a>1.3 组织方式</h2><ul><li>以上在讲通过内存地址查询缓存时，绕开了虚拟地址(virtual address，VA)和物理地址(physical address，PA)的问题。</li><li>CPU在发出对某个地址的数据访问，这个地址其实是虚拟地址，虚拟地址经过MMU转换成物理地址，最终从这个物理地址读取数据。</li></ul><h3 id="1-3-1-虚拟高速缓存-VIVT"><a href="#1-3-1-虚拟高速缓存-VIVT" class="headerlink" title="1.3.1 虚拟高速缓存(VIVT)"></a>1.3.1 虚拟高速缓存(VIVT)</h3><div style="text-align:center;">    <img src="VIVT.webp" alt="VIVT.webp" width="556" height="287" class="jop-noMdConv"></div><ul><li><code>Virtually Indexed Virtually Tagged</code>：通过虚拟地址形成<code>tag</code>和<code>index</code></li><li>优点是不需要每次读取或者写入操作的时候把虚拟地址经过MMU转换为物理地址，这在一定的程度上提升了访问cache的速度。</li><li>但是很显然同一个虚拟地址在不同的线程中可能表示了不同的物理地址，这导致操作系统面临歧义(ambiguity)和别名(alias)两个问题</li></ul><p><strong>歧义</strong></p><ul><li>指不同物理地址中的数据在cache中具有相同的tag和index，这个问题肯定只发生在不同的进程中</li><li>操作系统的解决方案是在切换进程时，选择flush所有的Cache Line，然后在清空Cache，保证切换后的进程不会错误的命中上一个进程的缓存数据（但是对于那些多核共享的Cache，这种方法似乎依然不能解决问题）</li><li>但是这样会导致切换后的进程刚开始执行的时候，将会由于大量的cache miss导致性能损失</li></ul><p><strong>别名</strong></p><ul><li>指不同的虚拟地址映射相同的物理地址，相同的物理地址会具有不同的tag和index，这种问题发生在共享数据时</li><li>操作系统的解决方案为对这种共享的页面采用nocache映射，直接绕过缓存访问DRAM。</li><li>还可以有另一种解决方案。这种方法只针对直接映射高速缓存，并且使用了写分配机制有效。在建立共享数据映射时，保证每次分配的虚拟地址都索引到相同的cacheline。</li></ul><h3 id="1-3-2-物理高速缓存-PIPT"><a href="#1-3-2-物理高速缓存-PIPT" class="headerlink" title="1.3.2 物理高速缓存(PIPT)"></a>1.3.2 物理高速缓存(PIPT)</h3><div style="text-align:center;">    <img src="PIPT.webp" alt="PIPT.webp" width="544" height="307" class="jop-noMdConv"></div><ul><li><code>Physically Indexed Physically Tagged</code>：通过物理地址形成<code>tag</code>和<code>index</code></li><li>CPU发出的虚拟地址经过MMU转换成物理地址，物理地址发往Cache控制器查找确认是否命中Cache。但是MMU地址转换会影响到整体的性能</li><li>为了加快MMU翻译虚拟地址的速度，硬件上也会加入一块cache，作用是缓存虚拟地址和物理地址的映射关系，这块cache称之为TLB(Translation Lookaside Buffer)</li></ul><h3 id="1-3-3-物理标记的虚拟高速缓存-VIPT"><a href="#1-3-3-物理标记的虚拟高速缓存-VIPT" class="headerlink" title="1.3.3 物理标记的虚拟高速缓存(VIPT)"></a>1.3.3 物理标记的虚拟高速缓存(VIPT)</h3><div style="text-align:center;">    <img src="VIPT.webp" alt="VIPT.webp" width="537" height="305" class="jop-noMdConv"></div><ul><li><code>Virtually Indexed Physically Tagged</code>：物理地址形成<code>tag</code>，虚拟地址形成<code>index</code>。这样做的主要好处在于查index和MMU可以并行完成，从而提升性能。</li><li>首先<code>VIPT</code>不存在歧义。前面在讲<code>tag</code>的时候，我们都是说对于一个内存地址除去用于定位Cache中位置的<code>index</code>和<code>offset</code>之后，剩下的地址位用于<code>tag</code>。但是对于<code>VIPT</code>我们并不遵守这一规则，而是对内存映射的页（<code>page size 32KB --&gt; bit&lt;11:0&gt;</code>）剩下的位<code>bit&lt;32:12&gt;</code>用于<code>tag</code>。因为虚拟地址到物理地址的映射是按照page的单位进行的，因此必然不会出现歧义问题</li><li>其次<code>VIPT</code>可能存在别名。Linux系统中映射最小的单位是页，一页大小是4KB。那么意味着虚拟地址和其映射的物理地址的<code>bit&lt;11:0&gt;</code>是一样的，如果index取的位刚好在这个范围内，就可以保证虚拟地址的<code>index</code>和<code>offset</code>其实和物理地址的一样。换一种说法其实保证Cache Size小于等于Page Size就可以了</li><li>解决方案其实也很简单，当Cache Size大于Page Size是，我们可以使用分路的方案，可以天然的降低index取的最高位，让其适配Page Size所占的位数</li></ul><h2 id="1-4-TLB"><a href="#1-4-TLB" class="headerlink" title="1.4 TLB"></a>1.4 TLB</h2><div style="text-align:center;">    <img src="TLB.png" alt="TLB.png" width="561" height="275" class="jop-noMdConv"></div><ul><li><p>全称<code>translation lookaside buffer</code>，用于缓存MMU进行地址转换的结果。64位系统一般都是3~5级。分别是PGD、PUD、PMD、PTE四级页表。MMU就是根据页表基地址寄存器从PGD页表一路查到PTE，最终找到物理地址(PTE页表中存储物理地址)。</p></li><li><p>TLB采用了和前文讲的Cache相同的缓存构建方式，但是在也存在些许不同之处：1.假设地址映射的页大小为4KB，那么虚拟地址的<code>bit&lt;11:0&gt;</code>和物理地址是完全相同的，因此这部分可以不用缓存；2.<code>index</code>的位数选择则只由需要缓存多少对地址映射决定了；3.通过index找到的不在是Cache Line，而是映射的物理地址<code>bit&lt;47:12&gt;</code></p></li><li><p>TLB本质是通过虚拟地址查找一个结果，其实属于<code>VIVT Cache</code>，因此依然存在别名和歧义问题。但是因为映射的地址并不会发生修改，别名并不会影响正确性。</p></li></ul><p><strong>ASID</strong></p><ul><li>歧义问题则依然存在，解决方案是我们在<code>tag</code>添加了一个用于区分进程空间的ASID (Address Space ID)。ASID和进程ID肯定是不一样的，进程ID取值范围很大。但是ASID一般是8或16 bit。所以只能区分256或65536个进程</li><li>所以我们不可能将进程ID和ASID一一对应，我们必须为每个进程分配一个ASID，进程ID和每个进程的ASID一般是不相等的。当ASID分配完后，flush所有TLB，重新分配ASID。</li></ul><p><strong>non-global</strong></p><ul><li>内核空间和用户空间是分开的，并且内核空间是所有进程共享。既然内核空间是共享的，进程A切换进程B的时候，如果进程B访问的地址位于内核空间，完全可以使用进程A缓存的TLB。但是现在由于ASID不一样，导致TLB miss。</li><li>针对内核空间这种全局共享的映射关系称之为global映射。针对每个进程的映射称之为non-global映射。</li><li>我们在最后一级页表中引入一个bit(non-global (nG) bit)代表是不是global映射。当虚拟地址映射物理地址关系缓存到TLB时，将nG bit也存储下来。当判断是否命中TLB时，当比较tag相等时，再判断是不是global映射，如果是的话，直接判断TLB hit，无需比较ASID。当不是global映射时，最后比较ASID判断是否TLB hit。</li></ul><h1 id="二、一致性"><a href="#二、一致性" class="headerlink" title="二、一致性"></a>二、一致性</h1><ul><li>因为缓存的使用，会在很多地方出现一致性问题，比如：<ol><li>DMA可以帮我们在I&#x2F;O和主存之间搬运数据，且不需要CPU参与。高速缓存是CPU和主存之间的数据交互的桥梁。而DMA如果和cache之间没有任何关系的话，可能会出现数据不一致。</li><li>iCache和dCache一致性问题。对于某些self-modifying code，在执行的时候会修改自己的指令。修改指令时将需要修改的指令数据加载到dCache中，修改成新指令并写回dCache。如果旧指令已经缓存在iCache中。那么对于程序执行来说依然会命中iCache。</li></ol></li><li>这些一致性问题都会通过一些简单的硬件或者软件方案保证一致性，并不是我们的重点。我们核心还是关注多核下的缓存一致性。</li></ul><h2 id="2-1-多核缓存一致性"><a href="#2-1-多核缓存一致性" class="headerlink" title="2.1 多核缓存一致性"></a>2.1 多核缓存一致性</h2><ul><li>其实问题非常简单，及每个CPU内都用单独的缓存，当两个线程需要访问同一块内存地址时，如果不对两个CPU的缓存做同步操作，就会造成多个副本的问题</li><li>多核的一致性问题其实是可以通过软件来解决的，但是因为软件方案的性能极差，因而现在的系统都是通过硬件来维护的</li></ul><h3 id="2-1-1-缓存同步要求"><a href="#2-1-1-缓存同步要求" class="headerlink" title="2.1.1 缓存同步要求"></a>2.1.1 缓存同步要求</h3><ul><li>某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为写传播（Wreite Propagation）</li><li>某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为事务的串形化（Transaction Serialization）。这里其实涉及到TSO模型了，在x86的架构下是要求指令执行结果要能够满足全局有序的</li></ul><h3 id="2-1-2-Bus-Snooping-Protocol"><a href="#2-1-2-Bus-Snooping-Protocol" class="headerlink" title="2.1.2 Bus Snooping Protocol"></a>2.1.2 Bus Snooping Protocol</h3><ul><li>总线嗅探（Bus Snooping）的工作机制是，当CPU修改自己私有的Cache时，硬件就会广播通知到总线上其他所有的CPU</li><li>每个CPU来说会有特殊的硬件监听广播事件，并检查是否有相同的数据被缓存在自己的CPU。如果私有Cache已经缓存这个即将修改的数据，那么该私有Cache也需要更新对应的cache line</li><li>这种bus snooping方法简单，但要需要每时每刻监听总线上的一切活动。不管别的CPU私有Cache是否缓存相同的数据，都需要发出一次广播事件。这在一定程度上加重了总线负载，也增加了读写延迟</li></ul><h3 id="2-1-3-MESI-Protocol"><a href="#2-1-3-MESI-Protocol" class="headerlink" title="2.1.3 MESI Protocol"></a>2.1.3 MESI Protocol</h3><ul><li><p>需要说明，MESI协议是在总线嗅探的基础上进行构建的，它的核心思想是去标明每一个Cache Line的状态，然后只在需要通知别的核的情况下才去广播事件。在大部分只需要修改自己的私有内存的情况下就不需要通知别的核，自己对缓存的修改情况了。</p></li><li><p>全称来源于四种状态，分别是：</p><ul><li><code>Modified</code>：已修改，表示Cache Line中的数据已经被更改，但是还没有写进内存中，可以直接进行数据更改不通知其他CPU</li><li><code>Exclusive</code>：独占，和内存中的数据是保持一致的，但仅存储于当前CPU的缓存中，可以修改数据并且切换状态，但是不需要通知其他CPU</li><li><code>Shared</code>：共享，和内存中的数据是保持一致的，被多个CPU的缓存所持有，修改数据时需要通知其他CPU将相同位置的缓存改为失效状态</li><li><code>Invalid</code>：已失效，数据已经失效，不可以读取也不可以修改</li></ul></li></ul><div style="text-align:center;">    <img src="mesi.png" alt="mesi.png" width="520" height="281" class="jop-noMdConv"></div><h3 id="2-1-4-伪共享"><a href="#2-1-4-伪共享" class="headerlink" title="2.1.4 伪共享"></a>2.1.4 伪共享</h3><ul><li>如果我们有两个全局变量<code>global_A</code>和<code>global_B</code>，它们同时被存放在了一个CacheLine的范围内。但这两个变量分别只被<code>task_A</code>和<code>task_B</code>两个进程访问</li><li>尽管这两个变量是完全不共享的，但是它们所存放的Cache Line却需要被共享，从而造成了不必要的缓存同步，从而影响性能。这种现象被称为伪共享(false sharing)</li><li>解决方案也很简单，按照Cache Line进行对齐就可以了，在Linux kernel中存在<code>__cacheline_aligned_in_smp</code>宏定义用于解决false sharing问题</li></ul><h2 id="2-2-atomic实现原理"><a href="#2-2-atomic实现原理" class="headerlink" title="2.2 atomic实现原理"></a>2.2 atomic实现原理</h2><ul><li>问题很简单，本质就是要求对多个变量的多个操作是同时完成的。比如对一个整形执行加一操作，需要先读出数据，再进行加一，最后回写。如果不是一次性完成会存在正确性问题，因此需要原子操作保证其正确性</li></ul><h3 id="2-2-1-Bus-Lock"><a href="#2-2-1-Bus-Lock" class="headerlink" title="2.2.1 Bus Lock"></a>2.2.1 Bus Lock</h3><ul><li>当CPU发出一个原子操作时，可以先锁住Bus（总线）。这样就可以防止其他CPU的内存操作。等原子操作结束，释放Bus</li><li>但是锁住Bus会导致后续无关内存操作都不能继续。实际上，我们只关心我们操作的地址数据</li></ul><h3 id="2-2-2-CacheLine-Lock"><a href="#2-2-2-CacheLine-Lock" class="headerlink" title="2.2.2 CacheLine Lock"></a>2.2.2 CacheLine Lock</h3><ul><li>借助多核Cache一致性协议MESI实现原子操作，Cache line的状态处于Exclusive或者Modified时，可以说明该变量只有当前CPU私有Cache缓存了该数据。所以我们可以直接修改Cache line即可更新数据。并且MESI协议可以帮我们保证互斥</li><li>但这不能保证多步操作期间不被打断，因此我们还需要再添加一个locked标志</li><li>当$CPU_0$试图执行原子递增操作时。$CPU_0$发出”Read Invalidate”消息，其他CPU将原子变量所在的缓存无效，并从Cache返回数据。$CPU_0$将Cache line置成Exclusive状态。然后将该<strong>cache line标记locked</strong>。然后$CPU_0$读取原子变量，修改，最后写入cache line。完成所有操作之后将cache line置位unlocked</li><li>如果$CPU_1$尝试执行一个原子递增操作，$CPU_1$会发送一个”Read Invalidate”消息，$CPU_0$收到消息后，检查对应的cache line的状态是locked，暂时不回复消息（$CPU_1$会一直等待$CPU_0$回复Invalidate Acknowledge消息）。直到cache line变成unlocked</li></ul><h2 id="2-3-spinlock"><a href="#2-3-spinlock" class="headerlink" title="2.3 spinlock"></a>2.3 spinlock</h2><ul><li>Linux kernel中常见的互斥原语，适用于不可睡眠上下文环境访问共享数据的互斥，是一种自旋锁</li><li>看上去似乎通过atomic操作可以简单的实现，但其实经历了较多的优化，而这些复杂的优化是和CPU缓存的一致性协议息息相关的</li></ul><h3 id="2-3-1-wild-spinlock"><a href="#2-3-1-wild-spinlock" class="headerlink" title="2.3.1 wild spinlock"></a>2.3.1 wild spinlock</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">spinlock</span> &#123;<br>        <span class="hljs-type">int</span> locked;<br>&#125;;<br><br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">spin_lock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> spinlock *lock)</span></span><br><span class="hljs-function"></span>&#123;<br>        <span class="hljs-keyword">while</span> (<span class="hljs-built_in">test_and_set</span>(&amp;lock-&gt;locked));<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">spin_unlock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> spinlock *lock)</span></span><br><span class="hljs-function"></span>&#123;<br>        lock-&gt;locked = <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>首先我们需要知道<code>test_and_set</code>是无条件置1操作，并且返回原来的值，这个操作在MESI协议中需要发送invalid消息给其他CPU，然后再修改自己缓存中的值。</li><li>当多个CPU竞争时，因为两边都在反复的执行写操作，这块内存空间需要在多个缓存之间来回颠簸，导致的带宽压力和性能损失。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">spin_lock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> spinlock *lock)</span></span><br><span class="hljs-function"></span>&#123;<br>        <span class="hljs-keyword">while</span> (lock-&gt;locked || <span class="hljs-built_in">test_and_set</span>(&amp;lock-&gt;locked));<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>解决方案也非常简单，我们提前读锁的状态，当处于被锁住的状态时，多个CPU缓存因为只在读该变量，因此一直保持<code>shared</code>状态，避免了缓存颠簸</li><li>但这种方式其实依然存在饥饿的问题，可能某个CPU一直无法获得锁</li></ul><h3 id="2-3-2-ticket-spinlock"><a href="#2-3-2-ticket-spinlock" class="headerlink" title="2.3.2 ticket spinlock"></a>2.3.2 ticket spinlock</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">spinlock</span> &#123;<br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">short</span> owner;<br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">short</span> next;<br>&#125;;<br><br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">spin_lock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> spinlock *lock)</span></span><br><span class="hljs-function"></span>&#123;<br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">short</span> next = <span class="hljs-built_in">xadd</span>(&amp;lock-&gt;next, <span class="hljs-number">1</span>);<br>        <span class="hljs-keyword">while</span> (lock-&gt;owner != next);<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">spin_unlock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> spinlock *lock)</span></span><br><span class="hljs-function"></span>&#123;<br>        lock-&gt;owner++;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>主要问题在于，当我们目前有多个CPU在while循环的等待中时，<code>lock-&gt;owner</code>明显是处于<code>shared</code>状态的。而当持有锁的CPU释放锁的时候会执行<code>lock-&gt;owner++</code>，修改这个值会同时将多个CPU中的缓存置为<code>Invalid</code>；之后这多个CPU又会请求释放锁的CPU获取修改后的缓存</li><li>随着CPU数量的增多，总线带宽压力很大。而且延迟也会随着增长，性能也会逐渐下降。而且$CPU_0$释放锁后，$CPU_1 - CPU_7$也只有一个CPU可以获得锁，理论上没有必要影响其他CPU的缓存，只需要影响接下来应该获取锁的CPU（按照FIFO的顺序）。这说明ticket spinlock不具备可扩展性</li></ul><h3 id="2-3-3-qspinlock"><a href="#2-3-3-qspinlock" class="headerlink" title="2.3.3 qspinlock"></a>2.3.3 qspinlock</h3><ul><li>前面的两种spinlock的根本原因就是每个CPU都spin在共享变量上。所以我们只需要保证每个CPU spin的变量是不同的就可以避免这种情况了。这其实就是MCS锁的实现原理。qspinlock的实现是建立在MCS锁的理论基础上</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">mcs_spinlock</span> &#123;<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">mcs_spinlock</span> *next;<br><span class="hljs-type">int</span> locked; <span class="hljs-comment">/* 1 if lock acquired */</span><br><span class="hljs-type">int</span> count;  <span class="hljs-comment">/* nesting count, see qspinlock.c */</span><br>&#125;;<br><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">mcs_spin_lock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> mcs_spinlock **lock, <span class="hljs-keyword">struct</span> mcs_spinlock *node)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">mcs_spinlock</span> *prev;<br><br><span class="hljs-comment">/* Init node */</span><br>node-&gt;locked = <span class="hljs-number">0</span>;<br>node-&gt;next   = <span class="hljs-literal">NULL</span>;<br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * We rely on the full barrier with global transitivity implied by the</span><br><span class="hljs-comment"> * below xchg() to order the initialization stores above against any</span><br><span class="hljs-comment"> * observation of @node. And to provide the ACQUIRE ordering associated</span><br><span class="hljs-comment"> * with a LOCK primitive.</span><br><span class="hljs-comment"> */</span><br>prev = <span class="hljs-built_in">xchg</span>(lock, node);<br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">likely</span>(prev == <span class="hljs-literal">NULL</span>)) &#123;<br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * Lock acquired, don&#x27;t need to set node-&gt;locked to 1. Threads</span><br><span class="hljs-comment"> * only spin on its own node-&gt;locked value for lock acquisition.</span><br><span class="hljs-comment"> * However, since this thread can immediately acquire the lock</span><br><span class="hljs-comment"> * and does not proceed to spin on its own node-&gt;locked, this</span><br><span class="hljs-comment"> * value won&#x27;t be used. If a debug mode is needed to</span><br><span class="hljs-comment"> * audit lock status, then set node-&gt;locked value here.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">return</span>;<br>&#125;<br><span class="hljs-built_in">WRITE_ONCE</span>(prev-&gt;next, node);<br><br><span class="hljs-comment">/* Wait until the lock holder passes the lock down. */</span><br><span class="hljs-built_in">arch_mcs_spin_lock_contended</span>(&amp;node-&gt;locked);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">mcs_spin_unlock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> mcs_spinlock **lock, <span class="hljs-keyword">struct</span> mcs_spinlock *node)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">mcs_spinlock</span> *next = <span class="hljs-built_in">READ_ONCE</span>(node-&gt;next);<br><br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">likely</span>(!next)) &#123;<br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * Release the lock by setting it to NULL</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">likely</span>(<span class="hljs-built_in">cmpxchg_release</span>(lock, node, <span class="hljs-literal">NULL</span>) == node))<br><span class="hljs-keyword">return</span>;<br><span class="hljs-comment">/* Wait until the next pointer is set */</span><br><span class="hljs-keyword">while</span> (!(next = <span class="hljs-built_in">READ_ONCE</span>(node-&gt;next)))<br><span class="hljs-built_in">cpu_relax</span>();<br>&#125;<br><br><span class="hljs-comment">/* Pass lock to next waiter. */</span><br><span class="hljs-built_in">arch_mcs_spin_unlock_contended</span>(&amp;next-&gt;locked);<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>加锁操作只需要将所属自己CPU的mcs_spinlock结构体加入单链表尾部，然后spin，直到自己的mcs_spinlock的locked成员置1（locked初始值是0）</li><li>解锁操作只需要将解锁的CPU对应的mcs_spinlock结构体的next域的lock成员置1，相当于通知下一个CPU退出循环</li></ul>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>memory model</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>协程库</title>
    <link href="/2024/05/12/%E5%8D%8F%E7%A8%8B%E5%BA%93/"/>
    <url>/2024/05/12/%E5%8D%8F%E7%A8%8B%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h1 id="一、协程"><a href="#一、协程" class="headerlink" title="一、协程"></a>一、协程</h1><h2 id="1-1-基本概念"><a href="#1-1-基本概念" class="headerlink" title="1.1 基本概念"></a>1.1 基本概念</h2><ul><li><p>协程可以理解为一种用户态的轻量级线程，一个线程里跑多个协程。</p></li><li><p>协程分为<strong>对称协程</strong>和<strong>非对称协程</strong>，对称协程就是当协程切换的时候他可以切换到任意其他的协程，比如<code>goroutine</code>；而非对称协程只能切换到调用他的调度器。</p></li><li><p><code>C20</code>以前，<code>c/c++</code>不直接支持协程语义，但有不少开源的协程库， 目前大概有三种实现协程的方式：</p><ul><li>利用<code>glibc</code>的<code>ucontext</code>组件：<a href="https://github.com/cloudwu/coroutine/">coroutine</a></li><li>利用汇编代码来切换上下文：<a href="https://github.com/Tencent/libco">libco</a></li><li>利用C语言的<code>setjmp</code>和<code>longjmp</code>：<a href="https://github.com/sustrik/libmill">libmill</a></li></ul></li><li><p>当然在<code>C20</code>的新特性中在语言级别支持了协程</p></li></ul><h2 id="1-2-解决的问题"><a href="#1-2-解决的问题" class="headerlink" title="1.2 解决的问题"></a>1.2 解决的问题</h2><ul><li>在IO密集型的程序中，CPU等待IO结果往往是非常频繁的事情，如果按照我们常规的思维写处理IO的代码，如：<code>accept --&gt; read --&gt; process --&gt; write</code>。这个流程当中三个地方将会面临CPU的阻塞等待问题（如果使用的是阻塞IO的话），而一台服务器是需要处理成千上万的连接请求的，所以这里的阻塞等待是万万不能接受的。</li><li>最早的解决方案就是开新的线程来处理每一个连接请求，这样即使发生阻塞也是在各自的线程中发生阻塞，而不会影响服务器相应别的请求。但是这样带来的问题就是连接多起来之后需要申请很多的线程资源，许多线程发生阻塞之后也会给系统带来额外的负担。</li><li>接着出现的方案是使用<code>epoll</code>在单个线程内同时监听多个连接，当监听到指定的信号之后再执行相应的处理逻辑。这样通过较少的线程就能处理大量的连接，此方案的性能也非常的优秀。但是这种基于事件的异步处理方案的处理流程是打散，我们不能按照顺序思维写整个处理流程。</li><li>最后协程其实就是为了解决异步处理逻辑混乱的方案，可以用顺序思维流程的代码写出异步处理的代码。</li></ul><h1 id="二、coroutine实现"><a href="#二、coroutine实现" class="headerlink" title="二、coroutine实现"></a>二、<code>coroutine</code>实现</h1><blockquote><p>参考资料：</p><p><a href="https://blog.csdn.net/LMFQYJ/article/details/79211084">云风coroutine源码分析</a></p><p><a href="https://blog.csdn.net/qq910894904/article/details/41911175">ucontext-人人都可以实现的简单协程库</a></p></blockquote><ul><li><code>glibc</code>中提供了<code>ucontext</code>库函数用于操作上下文，基于这组提供的函数可以实现上下文的切换，从而可以实现协程。</li></ul><h2 id="2-1-ucontext"><a href="#2-1-ucontext" class="headerlink" title="2.1 ucontext"></a>2.1 <code>ucontext</code></h2><ul><li>在类<code>System V</code>环境中，头文件<code>&lt;ucontext.h&gt;</code>中定义了一个核心结构体和四个函数用以支持用户级的线程切换。</li><li>核心结构体是<code>ucontext_t</code>，它是保存上下文信息的核心数据结构，基本结构如下：<ul><li><code>uc_link</code>的类型是<code>ucontext_t*</code>，其存储的是当前上下文运行完成之后或者被挂起时，应退出到的位置；</li><li><code>uc_sigmask</code>为该上下文中的阻塞信号集合；</li><li><code>uc_stack</code>为该上下文中使用的栈；</li><li><code>uc_mcontext</code>保存上下文的特定机器表示，包括调用线程的特定寄存器等。</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">ucontext</span> &#123;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">ucontext</span> *uc_link;       <span class="hljs-comment">// 该上下文执行完时要恢复的上下文</span><br>    <span class="hljs-type">sigset_t</span>         uc_sigmask;  <br>    <span class="hljs-type">stack_t</span>          uc_stack;      <span class="hljs-comment">//使用的栈</span><br>    <span class="hljs-type">mcontext_t</span>       uc_mcontext;  <br>    ...  <br>&#125; <span class="hljs-type">ucontext_t</span>;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span><br>  &#123;<br>    <span class="hljs-type">void</span> *ss_sp;<br>    <span class="hljs-type">int</span> ss_flags;<br>    <span class="hljs-type">size_t</span> ss_size;<br>  &#125; <span class="hljs-type">stack_t</span>;<br></code></pre></td></tr></table></figure><ul><li>然后是核心的四个函数：<ul><li><code>getcontext</code>：初始化<code>ucp</code>结构体，将当前的上下文保存到<code>ucp</code>中。</li><li><code>makecontext</code>：修改通过<code>getcontext</code>取得的上下文<code>ucp</code>（这意味着**调用<code>makecontext</code>前必须先调用<code>getcontext</code>**）。然后给该上下文指定一个栈空间<code>ucp-&gt;stack</code>，设置后继的上下文<code>ucp-&gt;uc_link</code>。如果这里设置的要返回的上下文为<code>NULL</code>，则当前线程会直接退出。</li><li><code>setcontext</code>：设置当前的上下文为<code>ucp</code>，这里的<code>ucp</code>应该通过<code>getcontext</code>或者<code>makecontext</code>取得，如果调用成功则不返回。其实很好理解这里的直接设置上下文操作，就是直接将执行流程跳转到<code>ucp</code>，这里也没有去保存当前上下文，所以当前的运行环境一定是直接丢失的，也就不会返回了。当然跳转的上下文中可能设置了后继上下文<code>ucp-&gt;uc_link</code>，如果当前运行完之后会返回到这里记录的后继上下文。</li><li><code>swapcontext</code>：不同于前者直接进行跳转，<code>swapcontext</code>会将当前的上下文信息换出并存储到<code>oucp</code>，而我们可以将要跳转的上下文的后继<code>ucp-&gt;uc_link</code>提前设置成<code>oucp</code>（注意这里是写指针，<code>oucp</code>里面当前保存的上下文其实还不是真正的返回位置），然后在调用<code>swapcontext</code>时第一个参数就填<code>oucp</code>，那就将当前上下文写入到<code>oucp</code>中了，于是在<code>ucp</code>上下文挂起或者退出的时候自然能返回当前调用<code>swapcontext</code>的位置了。</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">getcontext</span><span class="hljs-params">(<span class="hljs-type">ucontext_t</span> *ucp)</span></span>; <span class="hljs-comment">//将当前上下文保存到ucp</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">makecontext</span><span class="hljs-params">(<span class="hljs-type">ucontext_t</span> *ucp, <span class="hljs-type">void</span> (*func)(), <span class="hljs-type">int</span> argc, ...)</span></span>; <span class="hljs-comment">//修改上下文入口函数</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">setcontext</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">ucontext_t</span> *ucp)</span></span>; <span class="hljs-comment">//切换到上下文ucp</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">swapcontext</span><span class="hljs-params">(<span class="hljs-type">ucontext_t</span> *oucp, <span class="hljs-type">ucontext_t</span> *ucp)</span></span>; <span class="hljs-comment">//保存当前上下文到oucp，切换到上下文ucp</span><br></code></pre></td></tr></table></figure><ul><li>上下文的核心其实就是当前寄存器状态（这包含了<code>pc, sp</code>以及各种通用寄存器），以及栈空间（每个线程&#x2F;协程都是需要有单独的栈空间的）。当利用<code>ucontext</code>创建新的上下文的时候是需要我们创建新的栈空间的，而栈的大小设置是件很困难的事情。</li></ul><h2 id="2-2-协程库实现"><a href="#2-2-协程库实现" class="headerlink" title="2.2 协程库实现"></a>2.2 协程库实现</h2><ul><li><code>coroutine</code>是云风在2012年利用<code>ucontext</code>实现的一个非常简单的非对称协程库，其只提供了如下的几个函数接口：</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> COROUTINE_DEAD 0  <span class="hljs-comment">//协程状态</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> COROUTINE_READY 1</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> COROUTINE_RUNNING 2</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> COROUTINE_SUSPEND 3</span><br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">schedule</span>; <span class="hljs-comment">//协程调度器</span><br><br><span class="hljs-function"><span class="hljs-keyword">typedef</span> <span class="hljs-title">void</span> <span class="hljs-params">(*coroutine_func)</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule *, <span class="hljs-type">void</span> *ud)</span></span>; <span class="hljs-comment">//协程执行函数</span><br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">schedule</span> * <span class="hljs-built_in">coroutine_open</span>(<span class="hljs-type">void</span>); <span class="hljs-comment">//创建协程调度器</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">coroutine_close</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule *)</span></span>; <span class="hljs-comment">//关闭协程调度器</span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">coroutine_new</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule *, coroutine_func, <span class="hljs-type">void</span> *ud)</span></span>; <span class="hljs-comment">//用协程调度器创建一个协程</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">coroutine_resume</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule *, <span class="hljs-type">int</span> id)</span></span>; <span class="hljs-comment">//恢复id号协程</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">coroutine_status</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule *, <span class="hljs-type">int</span> id)</span></span>; <span class="hljs-comment">//返回id号协程的状态</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">coroutine_running</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule *)</span></span>; <span class="hljs-comment">//返回正在执行的协程id</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">coroutine_yield</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule *)</span></span>; <span class="hljs-comment">//保存上下文后中断当前协程执行</span><br></code></pre></td></tr></table></figure><ul><li>这是一个非对称的协程库，我们创建的协程在运行完之后会退出到<code>&quot;main&quot;</code>的运行流程中，然后再在主流程中选择需要恢复运行的协程。</li></ul><p><strong><code>schedule</code></strong></p><ul><li>首先是<code>schedule</code>结构体，其实就用于操作协程调度的类：<ul><li><code>stack</code>是公共使用的栈空间，每个运行的协程最终都是在这个公共的栈空间中运行的，所以协程切换的时候会涉及到栈的拷贝，后面会详细说明；</li><li><code>main</code>其实就是用于保存主流程上下文的，便于协程发生切换的时候退出到主流程；</li><li><code>co</code>存储协程的数组，<code>nco, cap</code>记录当前数组的容量和使用情况；</li><li><code>running</code>存储当前正在运行的协程。</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">schedule</span> &#123;<br>    <span class="hljs-type">char</span> stack[STACK_SIZE];<br>    <span class="hljs-type">ucontext_t</span> main;<br>    <span class="hljs-type">int</span> nco;<br>    <span class="hljs-type">int</span> cap;<br>    <span class="hljs-type">int</span> running;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">coroutine</span> **co;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong><code>coroutine</code></strong></p><ul><li>然后是<code>coroutine</code>结构体，用于存储协程的基本信息：<ul><li><code>func</code>是这个协程的函数入口，函数的定义必须符合<code>coroutine_func</code>类型定义，<code>ud</code>是入参；</li><li><code>ctx</code>用于保存当前协程上下文，便于在挂起之后能够恢复到协程挂起的位置继续执行；</li><li><code>stack</code>是在协程发生挂起的时候，暂存当前协程的栈信息的。</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">coroutine</span> &#123;<br>    coroutine_func func;<br>    <span class="hljs-type">void</span> *ud;<br>    <span class="hljs-type">ucontext_t</span> ctx;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">schedule</span> * sch;<br>    <span class="hljs-type">ptrdiff_t</span> cap;<br>    <span class="hljs-type">ptrdiff_t</span> size;<br>    <span class="hljs-type">int</span> status;<br>    <span class="hljs-type">char</span> *stack;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong><code>coroutine_new</code></strong></p><ul><li>功能比较简单，其实就是把一个函数注册成协程，并且返回协程标识符。这里可能遇到<code>co</code>数组空间不足的可能需要扩容。</li></ul><p><strong><code>coroutine_resume</code></strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> </span><br><span class="hljs-function"><span class="hljs-title">coroutine_resume</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule * S, <span class="hljs-type">int</span> id)</span> </span>&#123;<br>    <span class="hljs-built_in">assert</span>(S-&gt;running == <span class="hljs-number">-1</span>);<br>    <span class="hljs-built_in">assert</span>(id &gt;=<span class="hljs-number">0</span> &amp;&amp; id &lt; S-&gt;cap);<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">coroutine</span> *C = S-&gt;co[id];<br>    <span class="hljs-keyword">if</span> (C == <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span>;<br>    <span class="hljs-type">int</span> status = C-&gt;status;<br>    <span class="hljs-keyword">switch</span>(status) &#123;<br>    <span class="hljs-keyword">case</span> COROUTINE_READY:<br>        <span class="hljs-built_in">getcontext</span>(&amp;C-&gt;ctx);<br>        C-&gt;ctx.uc_stack.ss_sp = S-&gt;stack;<br>        C-&gt;ctx.uc_stack.ss_size = STACK_SIZE;<br>        C-&gt;ctx.uc_link = &amp;S-&gt;main;<br>        S-&gt;running = id;<br>        C-&gt;status = COROUTINE_RUNNING;<br>        <span class="hljs-type">uintptr_t</span> ptr = (<span class="hljs-type">uintptr_t</span>)S;<br>        <span class="hljs-built_in">makecontext</span>(&amp;C-&gt;ctx, (<span class="hljs-built_in">void</span> (*)(<span class="hljs-type">void</span>)) mainfunc, <span class="hljs-number">2</span>, (<span class="hljs-type">uint32_t</span>)ptr, (<span class="hljs-type">uint32_t</span>)(ptr&gt;&gt;<span class="hljs-number">32</span>));<br>        <span class="hljs-built_in">swapcontext</span>(&amp;S-&gt;main, &amp;C-&gt;ctx);<br>        <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">case</span> COROUTINE_SUSPEND:<br>        <span class="hljs-built_in">memcpy</span>(S-&gt;stack + STACK_SIZE - C-&gt;size, C-&gt;stack, C-&gt;size);<br>        S-&gt;running = id;<br>        C-&gt;status = COROUTINE_RUNNING;<br>        <span class="hljs-built_in">swapcontext</span>(&amp;S-&gt;main, &amp;C-&gt;ctx);<br>        <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">default</span>:<br>        <span class="hljs-built_in">assert</span>(<span class="hljs-number">0</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>恢复指定协程的运行，这里可能遇到两种情况：一种是该协程第一次运行，走<code>COROUTINE_READY</code>分支；第二种情况是该协程被挂起之后再运行，走<code>COROUTINE_SUSPEND</code>分支。</li><li>首次运行需要我们设置<code>ucontext</code>相关的信息，所以需要调用<code>getcontext</code>并设置栈以及返回位置的上下文，然后通过<code>makecontext</code>设置协程的入口函数为<code>mainfunc</code>。这里并没有直接设置成用户注册的函数，是因为需要额外做一些诸如运行后释放资源的操作，所以这里包了一层函数。最后通过<code>swapcontext</code>切换到协程运行。</li><li>如果是挂起之后的恢复，则需要恢复栈数据，就是把<code>coroutine-&gt;stack</code>中暂存的栈数据复制到<code>schedule-&gt;stack</code>公共栈空间中，然后再通过<code>swapcontext</code>切换到协程运行。</li></ul><p><strong><code>coroutine_yield</code></strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span></span><br><span class="hljs-function"><span class="hljs-title">coroutine_yield</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> schedule * S)</span> </span>&#123;<br>    <span class="hljs-type">int</span> id = S-&gt;running;<br>    <span class="hljs-built_in">assert</span>(id &gt;= <span class="hljs-number">0</span>);<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">coroutine</span> * C = S-&gt;co[id];<br>    <span class="hljs-built_in">assert</span>((<span class="hljs-type">char</span> *)&amp;C &gt; S-&gt;stack);<br>    _save_stack(C,S-&gt;stack + STACK_SIZE);<br>    C-&gt;status = COROUTINE_SUSPEND;<br>    S-&gt;running = <span class="hljs-number">-1</span>;<br>    <span class="hljs-built_in">swapcontext</span>(&amp;C-&gt;ctx , &amp;S-&gt;main);<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>挂起操作是在协程流程中调用的，挂起之前需要暂存当前协程的栈空间数据，这是通过<code>_save_stack</code>函数的实现的。</li><li>然后就是更新状态，并通过<code>swapcontext</code>切换到主流程中。</li><li>简单说一下<code>_save_stack</code>函数，用了一个很巧妙的方法，在函数内部定义了一个局部变量<code>dummy</code>，此时<code>dummy</code>的地址应该是栈顶，而栈底是已知的，这样我们就知道当前协程使用的栈的大小。</li></ul><h1 id="三、libco实现"><a href="#三、libco实现" class="headerlink" title="三、libco实现"></a>三、<code>libco</code>实现</h1><ul><li><code>libco</code>是微信后台大规模使用的<code>c/c++</code>协程库，2013年至今稳定运行在微信后台的数万台机器上。</li><li>通过提供<code>socket</code>族函数的<code>hook</code>，使得后台逻辑服务几乎不用修改逻辑代码就可以完成异步化改造。</li><li>上下文切换采用的汇编实现方案，手动保存当前CPU的寄存器状态。</li></ul><h2 id="3-1-动态链接实现hook"><a href="#3-1-动态链接实现hook" class="headerlink" title="3.1 动态链接实现hook"></a>3.1 动态链接实现<code>hook</code></h2><blockquote><p>参考资料：</p><p><a href="https://blog.csdn.net/MOU_IT/article/details/115050472">libco源码阅读（八）：hook机制</a></p><p><a href="http://kaiyuan.me/2017/05/03/function_wrapper/">动态链接黑魔法: Hook 系统函数</a></p></blockquote><h3 id="3-1-1-why…"><a href="#3-1-1-why…" class="headerlink" title="3.1.1 why…?"></a>3.1.1 why…?</h3><ul><li>对于线程来说，当某些系统调用发生阻塞时会被系统自动挂起并等待特定的信号到来，并且把当前的CPU调度给另外的线程，这个过程对用户是完全无感的。</li><li>但协程是用户态的概念，操作系统并不知道它的存在，如果我们在协程中调用了某个会阻塞的接口，则会直接将当前线程阻塞，并不会讲CPU调度给别的协程。协程系统中想要让渡CPU需要手动调用<code>co_resume</code>或<code>co_yield</code>这样的方法。</li><li>因此我们如果想要在原来的代码中引入协程，肯定是需要做很多<strong>侵入式</strong>改造的，即在原来的业务逻辑中加入很多协程相关的调用。</li><li>而基于动态链接实现的<code>hook</code>方案可以在不更改原代码的基础上修改要调用的函数的逻辑。基于此原理我们可以修改各种系统调用函数（<code>libco</code>主要是修改了<code>socket</code>函数族），从而实现非侵入式的异步化改造。</li></ul><h3 id="3-1-2-hook机制"><a href="#3-1-2-hook机制" class="headerlink" title="3.1.2 hook机制"></a>3.1.2 <code>hook</code>机制</h3><ul><li><p><code>hook</code>机制本质上是一种函数的劫持技术，比如我们通常需要调用<code>malloc</code>函数来进行内存分配，那么能不能我们自己封装一个同名、同入参和同返回值的<code>malloc</code>函数来替代系统的<code>malloc</code>函数，在我们自己封装的<code>malloc</code>函数中实现一些特定的功能，而且也能回调系统的<code>malloc</code>，这就是<code>hook</code>机制。</p></li><li><p>系统提供给我们的<code>dlopen</code>、<code>dlsym</code>族函数可以用来操作动态链接库，比如我们要<code>hook</code>系统调用函数<code>read</code>，我们可以使用<code>dlsym</code>族函数获取<code>hook</code>前函数的地址，这样就可以在自己实现的<code>read</code>中回调原函数，并加上一些额外的逻辑，并且在运行是会调用我们的版本了。</p></li></ul><h3 id="3-1-3-动态链接"><a href="#3-1-3-动态链接" class="headerlink" title="3.1.3 动态链接"></a>3.1.3 动态链接</h3><ul><li>动态链接是指在程序编译时并不会被连接动态库到目标代码中，而是在程序运行是才被载入。不同的应用程序如果调用相同的库，那么在内存里只需要有一份该共享库的实例，规避了空间浪费问题。</li><li>动态库在程序运行是才被载入，也解决了静态库对程序的更新、部署和发布页会带来麻烦。用户只需要更新动态库即可。</li><li>在<code>Linux</code>中动态链接库是<code>.so</code>结尾的文件，本质和我们编译生成的<code>.o</code>文件是类似的，在加载程序或者运行程序发现需要访问动态链接库中的函数实现时，会在所有的库空间中去寻找对应的实现。<strong>而如果同一个函数接口在多个动态库中都被实现过，那么到底调用哪个实现就取决于先查找到谁。</strong></li></ul><h3 id="3-1-4-环境变量LD-PRELOAD"><a href="#3-1-4-环境变量LD-PRELOAD" class="headerlink" title="3.1.4 环境变量LD_PRELOAD"></a>3.1.4 环境变量LD_PRELOAD</h3><ul><li><code>LD_PRELOAD</code>是<code>Linux</code>系统的一个环境变量，它可以影响程序的运行时的链接<code>(Runtime linker)</code>，允许你定义在程序运行前优先加载的动态链接库。</li><li>这个功能主要就是用来有选择性的载入不同动态链接库中的相同函数。通过这个环境变量，我们可以在主程序和其动态链接库的中间加载别的动态链接库，甚至覆盖正常的函数库。一方面，我们可以以此功能来使用自己的或是更好的函数（无需更改别人的源码）；而另一方面，我们也可以向别人的程序注入程序，从而达到特定的目的。</li><li>系统寻找动态库时加载顺序为：<ol><li><code>LD_PRELOAD</code></li><li><code>LD_LIBRARY_PATH</code></li><li><code>/etc/ld.so.cache</code></li><li><code>/lib</code></li><li><code>/usr/lib</code></li></ol></li></ul><h3 id="3-1-5-示例"><a href="#3-1-5-示例" class="headerlink" title="3.1.5 示例"></a>3.1.5 示例</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// hookread.cpp</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;dlfcn.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;unistd.h&gt;</span></span><br> <br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br> <br><span class="hljs-function"><span class="hljs-keyword">typedef</span> <span class="hljs-title">ssize_t</span> <span class="hljs-params">(*<span class="hljs-type">read_pfn_t</span>)</span><span class="hljs-params">(<span class="hljs-type">int</span> fildes, <span class="hljs-type">void</span> *buf, <span class="hljs-type">size_t</span> nbyte)</span></span>;<br> <br><span class="hljs-type">static</span> <span class="hljs-type">read_pfn_t</span> g_sys_read_func = (<span class="hljs-type">read_pfn_t</span>)<span class="hljs-built_in">dlsym</span>(RTLD_NEXT,<span class="hljs-string">&quot;read&quot;</span>);<br> <br><span class="hljs-function"><span class="hljs-type">ssize_t</span> <span class="hljs-title">read</span><span class="hljs-params">( <span class="hljs-type">int</span> fd, <span class="hljs-type">void</span> *buf, <span class="hljs-type">size_t</span> nbyte )</span></span>&#123;<br>    std::cout &lt;&lt; <span class="hljs-string">&quot;进入 hook read\n&quot;</span>;<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">g_sys_read_func</span>(fd, buf, nbyte);<br>&#125;<br> <br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">co_enable_hook_sys</span><span class="hljs-params">()</span></span>&#123;<br>    std::cout &lt;&lt; <span class="hljs-string">&quot;可 hook\n&quot;</span>;<br>&#125;<br> <br><span class="hljs-comment">// main.cpp</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;sys/socket.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;netinet/in.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;arpa/inet.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;unistd.h&gt;</span></span><br> <br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br> <br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>    <span class="hljs-type">int</span> fd = <span class="hljs-built_in">socket</span>(PF_INET, SOCK_STREAM, <span class="hljs-number">0</span>);<br>    <span class="hljs-type">char</span> buffer[<span class="hljs-number">10000</span>];<br>    <br>    <span class="hljs-type">int</span> res = <span class="hljs-built_in">read</span>(fd, buffer ,<span class="hljs-number">10000</span>);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">g++ -o main main.cpp<br>g++ -o hookread.so -fPIC -shared -D_GNU_SOURCE hookread.cpp -ldl<br>LD_PRELOAD=./hookread.so ./main<br></code></pre></td></tr></table></figure><ul><li><p>但是libco并不是这样做的，整个<code>libco</code>中你都看不到<code>LD_PRELOAD</code>，<code>libco</code>使用了一种特殊的方法，即通过在用户代码中包含<code>co_hook_sys_call.cpp</code>中定义的函数，这样也可以做到使用我们自己的库去替换系统的库。</p></li><li><p>实现也很简单，就是单独编译得到<code>hookread.o</code>文件，然后再编译<code>main.cpp</code>： <code>g++ main.cpp -ldl hookread.o</code>。但这种方法需要在用户代码中引入头文件<code>hookread.h</code>。</p></li></ul><h2 id="3-2-函数调用过程"><a href="#3-2-函数调用过程" class="headerlink" title="3.2 函数调用过程"></a>3.2 函数调用过程</h2><blockquote><p>参考资料：</p><p><a href="https://cs.pynote.net/hd/asm/202212111/#x64">学习x86-64寄存器（x64 Register Set）</a></p><p><a href="https://zhuanlan.zhihu.com/p/440016053#112-intel-x64%E5%AF%84%E5%AD%98%E5%99%A8">x86-64寄存器和栈帧</a></p><p><a href="https://blog.csdn.net/MOU_IT/article/details/114791921">libco源码阅读（四）：协程的上下文环境</a></p></blockquote><h3 id="3-2-1-栈帧"><a href="#3-2-1-栈帧" class="headerlink" title="3.2.1 栈帧"></a>3.2.1 栈帧</h3><div style="text-align:center;">    <img src="stack-frame.png" alt="stack-frame.png" width="208" height="240" class="jop-noMdConv"></div><ul><li>首先在Linux程序的虚拟地址空间中，栈段是从高地址向低地址增长的，而堆是从低地址向高地址增长，所以我们的手动申请的栈空间是需要设置成从最高地址开始使用的。</li><li>在<code>x86_64</code>架构的CPU中有两个专门用来管理函数栈帧的寄存器，分别是<code>rbp</code>, <code>rsp</code>。前者是当前栈帧的底部（高地址），后者是当前栈帧的顶部（低地址）。</li><li>栈帧需要完成的主要工作是为局部变量开辟空间，此外还需要处理调用函数的一些相关工作。</li></ul><p><strong>函数调用</strong></p><ul><li>首先说函数调用（<code>caller</code>方的工作），我们需要完成的工作主要包括传递参数以及记录函数跳转之后的返回地址。写入参的过程是以当前的<code>rsp</code>为基地址向高地址写入的，并且参数是从右往左以此写入，所以上图青色部分是<code>param N ... param 1</code>。注意这里是以栈顶往高地址写数据，即存储参数的空间是调用者的栈帧空间，这里是需要提前预留出来的。</li><li>参数写完之后紧接的指令就是<code>call func</code>调用跳转，这条指令除了将<code>rip</code>更换成目标函数入口位置还会同时保存函数调用后的返回位置，这个过程是完全自动完成的设置<code>rip</code>的操作没有体现在汇编代码中。返回地址是紧接着在栈顶位置写入。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs assembly">call foo; 等价于下面的指令<br><br>pushq %rip     ; 保存下一条指令（第41行的代码地址）的地址，用于函数返回继续执行<br>jump foo ; 跳转到函数foo<br></code></pre></td></tr></table></figure><p><strong>函数进入</strong></p><ul><li>进入一个新的函数之后首先需要保存当前寄存器中的数据，方便调用完成之后恢复状态。因为每个函数需要用到的寄存器是不同的，所以要保存那些寄存器根据需要决定。但<code>rbp</code>和<code>rsp</code>是肯定需要更改的，所以进入函数和推出时固定需要保存和恢复<code>rbp</code>与<code>rsp</code>。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs asm">push rbp       ; 函数最开始，保存rbp到stack<br>mov  rbp, rsp  ; 扩展stack之前，保存此值，作为新stack frame的底<br>; ...<br>mov  rsp, rbp  ; 最后恢复<br>pop  rbp  <br></code></pre></td></tr></table></figure><ul><li>然后需要扩展当前函数的栈帧空间，即让<code>rsp</code>减去一个值，局部变量需要用到的空间就分配完成了。</li></ul><p><strong>函数退出</strong></p><ul><li>退出的时候需要注意将之前保存过的寄存器值进行恢复，再恢复<code>rbp</code>和<code>rsp</code>；然后调用<code>ret</code>，会自动根据当前<code>sp</code>地址存储的返回位置进行跳转。此时一个函数的调用就完成了。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs assembly">ret; 等价于下面的指令<br><br>popq %rip ; 恢复指令指针寄存器<br></code></pre></td></tr></table></figure><h3 id="3-2-2-传参优化"><a href="#3-2-2-传参优化" class="headerlink" title="3.2.2 传参优化"></a>3.2.2 传参优化</h3><ul><li>根据前面的描述，当我们在为调用函数设置传入参数的时候是通过栈来存储的，但实际上函数的参数比较少的时候会使用寄存器来完成传参，比如函数只有两个参数<code>func(int* arg1, int* arg2)</code>的时候，会使用<code>rdi</code>存<code>arg1</code>，使用<code>rsi</code>存<code>arg2</code>。</li></ul><h2 id="3-3-关键数据结构"><a href="#3-3-关键数据结构" class="headerlink" title="3.3 关键数据结构"></a>3.3 关键数据结构</h2><h3 id="3-3-1-协程实体"><a href="#3-3-1-协程实体" class="headerlink" title="3.3.1 协程实体"></a>3.3.1 协程实体</h3><ul><li><code>stCoRoutine_t</code>相当于<code>Linux</code>中管理线程&#x2F;进程的<code>task_struct</code>结构体，保存这协程的私有数据和协程切换时的上下文信息。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stCoRoutine_t</span><br>&#123;<br>    stCoRoutineEnv_t *env; <span class="hljs-comment">// 协程的执行环境, 运行在同一个线程上的各协程是共享该结构</span><br>    <span class="hljs-type">pfn_co_routine_t</span> pfn;  <span class="hljs-comment">// 一个函数指针, 指向实际待执行的协程函数 </span><br>    <span class="hljs-type">void</span> *arg;             <span class="hljs-comment">// 函数的参数</span><br>    <span class="hljs-type">coctx_t</span> ctx;           <span class="hljs-comment">// 用于协程切换时保存CPU上下文（context）的,即 esp、ebp、eip 和其他通用寄存器的值</span><br>    <span class="hljs-type">char</span> cStart;           <span class="hljs-comment">// 协程是否执行过resume</span><br>    <span class="hljs-type">char</span> cEnd;             <span class="hljs-comment">// 协程是否执行结束</span><br>    <span class="hljs-type">char</span> cIsMain;          <span class="hljs-comment">// 是否为主协程修改</span><br>    <span class="hljs-type">char</span> cEnableSysHook;   <span class="hljs-comment">// 此协程是否hook库函数，即用自己实现的函数替代库函数</span><br>    <span class="hljs-type">char</span> cIsShareStack;    <span class="hljs-comment">// 是否开启共享栈模式</span><br> <br>    <span class="hljs-type">void</span> *pvEnv;           <span class="hljs-comment">// 保存程序系统环境变量的指针</span><br> <br>    <span class="hljs-comment">//char sRunStack[ 1024 * 128 ];</span><br>    stStackMem_t* stack_mem; <span class="hljs-comment">// 协程运行时的栈内存</span><br> <br>    <span class="hljs-comment">//save satck buffer while confilct on same stack_buffer;</span><br>    <span class="hljs-type">char</span>* stack_sp;         <span class="hljs-comment">// 保存栈顶指针sp</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> save_size; <span class="hljs-comment">// 保存协程的栈的buffer的大小</span><br>    <span class="hljs-type">char</span>* save_buffer;      <span class="hljs-comment">// 使用共享栈模式时，用于保存该协程的在共享栈中的内容</span><br> <br>    stCoSpec_t aSpec[<span class="hljs-number">1024</span>];<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="3-3-2-协程上下文信息"><a href="#3-3-2-协程上下文信息" class="headerlink" title="3.3.2 协程上下文信息"></a>3.3.2 协程上下文信息</h3><ul><li><code>coctx_t</code>保存协程的上下文，实际就是寄存器的值，<code>C/C++</code>都没有函数可以直接接触寄存器，所以操作这个参数的时候需要嵌入一点汇编代码。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">coctx_t</span><br>&#123;<br><span class="hljs-meta">#<span class="hljs-keyword">if</span> defined(__i386__)</span><br>    <span class="hljs-type">void</span> *regs[ <span class="hljs-number">8</span> ];  <span class="hljs-comment">// X86 32位架构下有8个通用寄存器</span><br><span class="hljs-meta">#<span class="hljs-keyword">else</span></span><br>    <span class="hljs-type">void</span> *regs[ <span class="hljs-number">14</span> ]; <span class="hljs-comment">// x86 64位下有16个寄存器，这里保存14个</span><br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>    <span class="hljs-type">size_t</span> ss_size;  <span class="hljs-comment">// 栈的大小</span><br>    <span class="hljs-type">char</span> *ss_sp;     <span class="hljs-comment">// 栈顶指针esp</span><br>    <br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="3-3-3-私有栈和共享栈"><a href="#3-3-3-私有栈和共享栈" class="headerlink" title="3.3.3 私有栈和共享栈"></a>3.3.3 私有栈和共享栈</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stStackMem_t</span><br>&#123;<br>    stCoRoutine_t* ocupy_co; <span class="hljs-comment">// 执行时占用的那个协程实体,也就是这个栈现在是那个协程在用</span><br>    <span class="hljs-type">int</span> stack_size;          <span class="hljs-comment">// 当前栈上未使用的空间</span><br>    <span class="hljs-type">char</span>* stack_bp;          <span class="hljs-comment">// stack_buffer + stack_size</span><br>    <span class="hljs-type">char</span>* stack_buffer;      <span class="hljs-comment">// 栈的起始地址,当然对于主协程来说这是堆上的空间</span><br> <br>&#125;;<br> <br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stShareStack_t</span><br>&#123;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> alloc_idx; <span class="hljs-comment">// stack_array中我们在下一次调用中应该使用的那个共享栈的index</span><br>    <span class="hljs-type">int</span> stack_size;         <span class="hljs-comment">// 共享栈的大小，这里的大小指的是一个stStackMem_t*的大小</span><br>    <span class="hljs-type">int</span> count;              <span class="hljs-comment">// 共享栈的个数，共享栈可以为多个，所以以下为共享栈的数组</span><br>    stStackMem_t** stack_array; <span class="hljs-comment">// 栈的内容，这里是个数组，元素是stStackMem_t*</span><br>&#125;;<br></code></pre></td></tr></table></figure><ul><li><code>stStackMem_t</code>是运行协程私有栈的结构，<code>stShareStack_t</code>则是共享栈的结构。<code>libco</code>有两种协程栈的策略：<ul><li>一种是一个协程分配一个栈，这也是默认的配置，因为默认大小为<code>128KB</code>，如果1024个协程就是<code>128MB</code>，这会带来较大空间的浪费。</li><li>另一种策略为共享栈，即所有协程使用同一个栈，然后每个协程使用一个<code>buffer</code>来保存自己的栈内容，这个<code>buffer</code>大小根据具体的需要进行申请，因此可以节省内存。libco在进行协程切换的时候，先把共享栈的内容复制到要换出的协程实体的结构体buffer中，再把即将换入的协程实体的结构体中的buffer内容复制到共享栈中。这种方法是多个协程共用一个栈，但缺点是在协程切换的时候需要拷贝已使用的栈空间。</li></ul></li></ul><h3 id="3-3-4-线程环境"><a href="#3-3-4-线程环境" class="headerlink" title="3.3.4 线程环境"></a>3.3.4 线程环境</h3><ul><li><code>stCoRoutineEnv_t</code>是一个非常关键的结构，是一个线程内所有协程共享的结构。其中存放了一些协程调度相关的数据，当然叫调度有些勉强，因为<code>libco</code>实现的非对称式协程实际上没有什么调度策略，完全就是协程切换会用到。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stCoRoutineEnv_t</span><br>&#123;<br>    stCoRoutine_t *pCallStack[ <span class="hljs-number">128</span> ]; <span class="hljs-comment">// 协程的调用栈</span><br>    <span class="hljs-type">int</span> iCallStackSize;               <span class="hljs-comment">// 调用栈的栈顶指针</span><br>    stCoEpoll_t *pEpoll;              <span class="hljs-comment">// epoll的一个封装结构</span><br> <br>    <span class="hljs-comment">//for copy stack log lastco and nextco</span><br>    stCoRoutine_t* pending_co;       <span class="hljs-comment">// 目前占用共享栈的协程</span><br>    stCoRoutine_t* ocupy_co;         <span class="hljs-comment">// 与pending在同一个共享栈上的上一个协程</span><br>&#125;;<br></code></pre></td></tr></table></figure><ul><li><code>pCallStack</code> ： 如果将协程看成一种特殊的函数，那么这个 <code>pCallStack</code> 就时保存这些函数的调用链的栈。非对称协程最大特点就是协程间存在明确的调用关系；甚至在有些文献中，启动协程被称作 <code>call</code>，挂起协程叫 <code>return</code>。非对称协程机制下的被调协程只能返回到调用者协程，这种调用关系不能乱，因此必须将调用链保存下来。</li><li><code>pending_co</code>和<code>ocupy_co</code>：对上次切换挂起的协程和嵌套调用的协程栈的拷贝，为了减少共享栈上数据的拷贝。在不使用共享栈模式时 <code>pending_co</code> 和 <code>ocupy_co</code> 都是空指针。（大概就是有的情况下共享栈中上次留下来的数据和现在将要重新写入的是一样的，可以省略恢复过程）</li></ul><h3 id="3-3-5-协程属性"><a href="#3-3-5-协程属性" class="headerlink" title="3.3.5 协程属性"></a>3.3.5 协程属性</h3><ul><li>协程属性的结构体<code>stCoRoutineAttr_t</code>标记了栈的大小和是否使用共享栈。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stCoRoutineAttr_t</span><br>&#123;<br>    <span class="hljs-type">int</span> stack_size;   <span class="hljs-comment">// 协程的私有栈或者共享栈大小</span><br>    stShareStack_t*  share_stack; <span class="hljs-comment">// 指向协程的共享栈</span><br>    <span class="hljs-built_in">stCoRoutineAttr_t</span>()<br>    &#123;<br>        stack_size = <span class="hljs-number">128</span> * <span class="hljs-number">1024</span>;<br>        share_stack = <span class="hljs-literal">NULL</span>;<br>    &#125;<br>&#125;__attribute__ ((packed));<br></code></pre></td></tr></table></figure><h2 id="3-4-协程的基本操作"><a href="#3-4-协程的基本操作" class="headerlink" title="3.4 协程的基本操作"></a>3.4 协程的基本操作</h2><blockquote><p>参考文献：</p><p><a href="https://blog.csdn.net/MOU_IT/article/details/114683197">libco源码阅读（三）：协程的创建和运行</a></p><p><a href="https://blog.csdn.net/MOU_IT/article/details/114791921">libco源码阅读（四）：协程的上下文环境</a></p><p><a href="http://kaiyuan.me/2017/07/10/libco/">libco 分析(上)：协程的实现</a></p></blockquote><ul><li>协程的基本操作不外乎创建、恢复运行、挂起切换，这三个操作分别是由<code>co_create, co_resume, co_yield</code>三个函数完成的。</li></ul><h3 id="3-4-1-协程创建"><a href="#3-4-1-协程创建" class="headerlink" title="3.4.1 协程创建"></a>3.4.1 协程创建</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">co_create</span><span class="hljs-params">(stCoRoutine_t **ppco, <span class="hljs-type">const</span> stCoRoutineAttr_t *attr, <span class="hljs-type">pfn_co_routine_t</span> pfn, <span class="hljs-type">void</span> *arg)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">co_get_curr_thread_env</span>()) <br>    &#123;<br>        <span class="hljs-built_in">co_init_curr_thread_env</span>();<br>    &#125;<br>    stCoRoutine_t *co = <span class="hljs-built_in">co_create_env</span>(<span class="hljs-built_in">co_get_curr_thread_env</span>(), attr, pfn, arg);<br>    *ppco = co;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li><code>ppco</code>：是协程的主体结构，存储着一个协程所有的信息；</li><li><code>attr</code>：其实和线程一样，是我们希望创建的协程的一些属性，不过libco中这个参数简单一点，只是标记了栈的大小和是否使用共享栈，传入为NULL时表示不使用共享栈；</li><li><code>pfn</code>：是我们希望协程执行的函数，当然实际执行的是一个封装后的函数；</li><li><code>arg</code>：是传入函数的参数。</li></ul><p><strong><code>co_get_curr_thread_env</code></strong></p><ul><li>用于获取当前线程绑定的协程环境（这里暗含一个线程下的所有协程都是一起管理的，不会出现两个管理单元）。为了保证每个线程下运行时都能拿到指定的<code>stCoRoutineEnv_t</code>，是使用线程私有化实现的。</li></ul><p><strong><code>co_init_curr_thread_env</code></strong></p><ul><li>如果发现当前还没有设置过<code>stCoRoutineEnv_t</code>，则说明是第一次创建此线程下的协程，这个函数用于初始化线程的环境变量，即初始化<code>stCoRoutineEnv_t</code>这个结构，并且创建一个主协程，主协程是线程环境栈中的第一个协程，该协程不执行任何函数。</li><li>会完成几个关键的任务：初始化<code>stCoRoutineEnv_t</code>；调用<code>co_create_env</code>创建主协程实体；并且将其放入协程调用栈中<code>env-&gt;pCallStack</code>；创建<code>epoll对象</code>（本质上<code>libco</code>还是为网络IO服务的，所以在设计上就是和<code>epoll</code>绑定的）</li></ul><p><strong><code>co_create_env</code></strong></p><ul><li>真正创建<code>stCoRoutine_t</code>对象的函数，主要是初始化对象并且分配私有栈或者公共栈</li></ul><h3 id="3-4-2-协程运行"><a href="#3-4-2-协程运行" class="headerlink" title="3.4.2 协程运行"></a>3.4.2 协程运行</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">co_resume</span><span class="hljs-params">( stCoRoutine_t *co )</span></span><br><span class="hljs-function"></span>&#123;<br>    stCoRoutineEnv_t *env = co-&gt;env;<br> <br>    <span class="hljs-comment">/* 获取线程环境中的栈顶协程实体 */</span><br>    stCoRoutine_t *lpCurrRoutine = env-&gt;pCallStack[ env-&gt;iCallStackSize - <span class="hljs-number">1</span> ];<br>    <br>    <span class="hljs-keyword">if</span>( !co-&gt;cStart ) <span class="hljs-comment">// 如果协程没有执行过resume</span><br>    &#123;<br>        <span class="hljs-built_in">coctx_make</span>( &amp;co-&gt;ctx,(<span class="hljs-type">coctx_pfn_t</span>)CoRoutineFunc,co,<span class="hljs-number">0</span> );<br>        co-&gt;cStart = <span class="hljs-number">1</span>;<br>    &#125;<br>    env-&gt;pCallStack[ env-&gt;iCallStackSize++ ] = co; <span class="hljs-comment">// 把当前协程压入线程环境的栈中</span><br>    <span class="hljs-built_in">co_swap</span>( lpCurrRoutine, co ); <span class="hljs-comment">// 进行两个协程的上下文切换</span><br>&#125;<br></code></pre></td></tr></table></figure><ul><li>大概流程就是从<code>env-&gt;pCallStack</code>调用栈中查找到当前协程，然后把要恢复运行的协程写入到调用栈中，最后调用<code>co_swap</code>完成协程的切换。（如果这个这个协程是第一次运行需要我们通过<code>coctx_make</code>创建上下文）</li></ul><p><strong><code>coctx_make</code></strong></p><ul><li>要理解初始化上下文函数的工作需要结合<code>coctx_swap</code>的工作原理，在<code>libco</code>中实现的协程切换是建立在模仿函数调用和返回上实现的，可以注意<code>coctx_swap</code>的最后一条指令是<code>ret</code>，所以为了在<code>coctx_swap</code>返回时跳转到目标函数位置，只需要提前将目标函数入口地址填到<code>sp</code>指向的位置即可。</li><li>当然除了去设置跳转位置外，还需要设定好栈的位置以及入参等，所以这个函数的本质就是初始化<code>coctx_t</code>，后面调用<code>coctx_swap</code>时会将存储在<code>coctx_t</code>中的数据恢复到寄存器中。</li></ul><p><strong><code>coctx_swap</code></strong></p><ul><li>首先<code>coctx_swap</code>的定义是<code>void coctx_swap(coctx_t*, coctx_t*)</code>，两个入参会被放置<code>rdi</code>（第一个参数）和<code>rsi</code>（第二个参数）</li><li>实际在调用的时候是<code>co_swap( lpCurrRoutine, co )</code>，即<code>rdi</code>存当前协程的<code>ctx</code>，<code>rsi</code>存将要切换到的协程的<code>ctx</code>。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs assembly">coctx_swap:<br>    leaq (%rsp),%rax        ; 将栈指针 %rsp 中存储的地址加载到 %rax 中，注意是寄存器中值的copy<br>    movq %rax, 104(%rdi)    ; regs[13]: rsp<br>    movq %rbx, 96(%rdi)     ; regs[12]: rbx<br>    movq %rcx, 88(%rdi)     ; regs[11]: rcx<br>    movq %rdx, 80(%rdi)     ; regs[10]: rdx<br>    movq 0(%rax), %rax      ; 这一句就是将 %rsp 指向的内存中的返回地址取出并存储到 %rax 中<br>    movq %rax, 72(%rdi)     ; regs[9]: ret<br>    movq %rsi, 64(%rdi)     ; regs[8]: rsi<br>    movq %rdi, 56(%rdi)     ; regs[7]: rdi<br>    movq %rbp, 48(%rdi)     ; regs[6]: rbp<br>    movq %r8, 40(%rdi)      ; regs[5]: r8<br>    movq %r9, 32(%rdi)      ; regs[4]: r9<br>    movq %r12, 24(%rdi)     ; regs[3]: r12<br>    movq %r13, 16(%rdi)     ; regs[2]: r13<br>    movq %r14, 8(%rdi)      ; regs[1]: r14<br>    movq %r15, (%rdi)       ; regs[0]: r15<br>    xorq %rax, %rax         ; 清空 %rax<br><br>    movq 48(%rsi), %rbp     ; 后半部分其实就是将第二个参数coctx中缓存的数据重新加载到寄存器中<br>    movq 104(%rsi), %rsp<br>    movq (%rsi), %r15<br>    movq 8(%rsi), %r14<br>    movq 16(%rsi), %r13<br>    movq 24(%rsi), %r12<br>    movq 32(%rsi), %r9<br>    movq 40(%rsi), %r8<br>    movq 56(%rsi), %rdi<br>    movq 80(%rsi), %rdx<br>    movq 88(%rsi), %rcx<br>    movq 96(%rsi), %rbx<br>    leaq 8(%rsp), %rsp<br>    pushq 72(%rsi)<br><br>    movq 64(%rsi), %rsi<br>    ret<br></code></pre></td></tr></table></figure><ul><li><p>注意<code>x86_64</code>架构的CPU其实是有很多寄存器的，但是这里其实只存储了一部分的寄存器值，这是和寄存器的使用规则有关系：如果寄存器遵循被调用者使用规则，那么被调用的函数内部如果需要使用这些寄存器就需要自己去缓存；如果寄存器遵循调用者使用规则，那么调用方要决定在调用前是否需要提前缓存这部分数据。</p><ol><li><code>%rax</code> 作为函数返回值使用。</li><li><code>%rsp</code> 栈指针寄存器，指向栈顶</li><li><code>%rbp</code> 栈桢指针，指向栈基</li><li><code>%rdi，%rsi，%rdx，%rcx，%r8，%r9</code> 用作函数参数，依次对应第1参数，第2参数……</li><li><code>%rbx，%r12，%r13，%14，%15</code> 用作数据存储，遵循<strong>被调用者使用规则</strong>，简单说就是随便用，调用子函数之前要备份它，以防他被修改</li><li><code>%r10，%r11</code> 用作数据存储，遵循<strong>调用者使用规则</strong>，简单说就是使用之前要先保存原值</li><li><code>%rip</code>: 相当于PC指针指向当前的指令地址，指向下一条要执行的指令</li></ol></li><li><p>所有寄存器中<code>%rax, %r10, %r11</code>是永远不需要被调用函数内部做缓存的，如果需要缓存是在调用函数之前就缓存了；而其他的寄存器如果函数内需要使用，则函数内要自己缓存。</p></li></ul><p><strong><code>co_swap</code></strong></p><ul><li>这个函数是<code>co_resume</code>中直接调用的函数，除了在内部调用<code>coctx_swap</code>之外还需要在切出之前和切回之后完成保存栈和恢复栈两个工作。</li></ul><h3 id="3-4-3-协程挂起"><a href="#3-4-3-协程挂起" class="headerlink" title="3.4.3 协程挂起"></a>3.4.3 协程挂起</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">co_yield_env</span><span class="hljs-params">( stCoRoutineEnv_t *env )</span></span><br><span class="hljs-function"></span>&#123;<br>    <br>    stCoRoutine_t *last = env-&gt;pCallStack[ env-&gt;iCallStackSize - <span class="hljs-number">2</span> ];<br>    stCoRoutine_t *curr = env-&gt;pCallStack[ env-&gt;iCallStackSize - <span class="hljs-number">1</span> ];<br><br>    env-&gt;iCallStackSize--;<br><br>    <span class="hljs-built_in">co_swap</span>( curr, last);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">co_yield_ct</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><br>    <span class="hljs-built_in">co_yield_env</span>( <span class="hljs-built_in">co_get_curr_thread_env</span>() );<br>&#125;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">co_yield</span><span class="hljs-params">( stCoRoutine_t *co )</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-built_in">co_yield_env</span>( co-&gt;env );<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>挂起当前协程，并切换到协程栈中的上一个协程，这里的上一个协程其实是恢复当前要挂起的这个协程的协程，每当执行<code>co_resume</code>这个函数的时候，是会将恢复的协程写入到这个协程栈中的。</li><li>挂起操作会将当前协程从这个协程栈中<code>pop</code>出来。</li><li>这里协程栈的操作涉及到了协程实现方案的问题，前面有提到<code>libco</code>实现的协程是非对称的，即有栈协程。协程之间的调用关系是需要协程栈保存下来的，也就意味着协程挂起进行切换的时候必须恢复到调用方；</li><li>还有一种协程的实现是对称的，即无栈协程。那么所有协程之间是平等的，相互之间可以任意进行切换。</li></ul><h2 id="3-5-协程调度"><a href="#3-5-协程调度" class="headerlink" title="3.5 协程调度"></a>3.5 协程调度</h2><h3 id="3-5-1-协程间调度框架"><a href="#3-5-1-协程间调度框架" class="headerlink" title="3.5.1 协程间调度框架"></a>3.5.1 协程间调度框架</h3><ul><li>协程是构建在用户态的一种机制，所有协程的恢复运行和挂起操作都是需要显示在代码中调用相关函数才能实现的，这一点相较于线程是有很大不同的，同时一个协程如果一直不让出CPU，也不会有时间片机制让别的协程有机会开始执行。</li><li>因此在代码中是需要存在一个调度器来在合适的时候让指定的协程恢复运行的，也就是根据事件触发对应协程的恢复运行，这就是<code>libco</code>这个协程框架的基本调度思路了。</li><li>题外话：因为协程的设计本来就是为了解决网络编程中的问题，所以<code>libco</code>的核心是围绕多路复用<code>epoll</code>以及网络套接字<code>socket</code>来实现的。<code>libco</code>实现了对相关的网络编程接口的<code>hook</code>，在<code>hook</code>函数中添加<code>co_yield</code>以及一些封装，比如将<code>epoll</code>封装成<code>poll</code>来对外提供服务，等等。</li><li><code>libco</code>总共支持三种事件：网络事件、超时事件、同步事件。调用<code>libco</code>为我们提供的特定接口并需要进入等待时会自动注册这些事件，然后将当前协程挂起并等待主协程处理事件以及调度。主协程调度功能是由<code>co_eventloop</code>函数支持的。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">co_eventloop</span><span class="hljs-params">( stCoEpoll_t *ctx,<span class="hljs-type">pfn_co_eventloop_t</span> pfn,<span class="hljs-type">void</span> *arg )</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">for</span>(;;)<br>    &#123;<br>        <span class="hljs-type">int</span> ret = <span class="hljs-built_in">co_epoll_wait</span>( ctx-&gt;iEpollFd,result,stCoEpoll_t::_EPOLL_SIZE, <span class="hljs-number">1</span> );<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>;i&lt;ret;i++)<br>        &#123;<br>            item-&gt;<span class="hljs-built_in">pfnPrepare</span>( item,result-&gt;events[i],active );<br>        &#125;<br><br>        <span class="hljs-built_in">TakeAllTimeout</span>( ctx-&gt;pTimeout,now,timeout );<br><br>        <span class="hljs-built_in">Join</span>&lt;stTimeoutItem_t,stTimeoutItemLink_t&gt;( active,timeout );<br><br>        lp = active-&gt;head;<br>        <span class="hljs-keyword">while</span>( lp )<br>        &#123;<br>            lp-&gt;<span class="hljs-built_in">pfnProcess</span>( lp );<br>            lp = active-&gt;head;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>这里只保留了核心逻辑代码，首先<code>co_eventloop</code>函数是一个无限循环，不断等待新的事件到达，然后根据到达的事件恢复运行对应的协程。<ul><li>第一步是调用<code>co_epoll_wait</code>获取满足条件的网络事件，其实内部就是调用<code>epoll_wait</code>获取指定事件已经到达的<code>socket fd</code>。注意这里设置的超时时间是<code>1 ms</code>，这是利用超时机制实现超时事件的触发。</li><li>第二步是对已经准备好的<code>socket fd</code>调用提前设定的<code>pfnPrepare</code>函数，这个和一些统计工作有关系，不是核心逻辑。</li><li>第三步是通过<code>TakeAllTimeout</code>获得已经超时的事件，这里就是简单对比时间完成的。</li><li>第四步会将超时事件和网络事件两个链表合并，然后依次执行提前注册的回调函数<code>pfnProcess</code>，其实回调函数很简答，就是恢复事件绑定的协程，即内部调用<code>co_resume</code>。</li></ul></li><li>以上就是主要逻辑了，会发现缺失了同步事件的处理，这和同步事件的实现有关系。因为条件变量的触发需要另外一个协程在执行流程中调用<code>co_cond_signal</code>完成。这里会完成将该事件激活并放到<code>pstActiveList</code>中。那么下一次<code>co_eventloop</code>的循环就会一并将该事件处理。</li><li>分析源码后我们便清楚了，<code>libco</code>的调度就是建立在<code>epoll</code>之上的，基于事件的一个模型。因此我们使用<code>libco</code>框架写协程代码的时候是必须在主协程（也就是原线程执行流程）的最后调用<code>co_eventloop</code>函数的。在此之前应该把协程创建好并且先运行一些，否则一个刚创建的协程没有等待任何事件，永远不会被调度到。当然一个协程内部也是可以再创建新的协程的，但也是同样的道理，创建完之后要先运行。</li></ul><h3 id="3-5-2-Timeout事件"><a href="#3-5-2-Timeout事件" class="headerlink" title="3.5.2 Timeout事件"></a>3.5.2 <code>Timeout</code>事件</h3><ul><li><code>co_eventloop</code>的第一个参数是<code>stCoEpoll_t</code>，这就是辅助调度的结构体，所以只有一份。其内部的<code>stTimeout_t</code>存储了所有超时等待事件，是用来查询超时事件的结构。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stCoEpoll_t</span><br>&#123;<br>    <span class="hljs-type">int</span> iEpollFd;<br>    <span class="hljs-type">static</span> <span class="hljs-type">const</span> <span class="hljs-type">int</span> _EPOLL_SIZE = <span class="hljs-number">1024</span> * <span class="hljs-number">10</span>;<br><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">stTimeout_t</span> *pTimeout;<br><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">stTimeoutItemLink_t</span> *pstTimeoutList;<br><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">stTimeoutItemLink_t</span> *pstActiveList;<br><br>    co_epoll_res *result; <br><br>&#125;;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stTimeoutItemLink_t</span><br>&#123;<br>    stTimeoutItem_t *head;<br>    stTimeoutItem_t *tail;<br>&#125;;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stTimeout_t</span><br>&#123;<br>    stTimeoutItemLink_t *pItems;<span class="hljs-comment">// 链表头的数组（有多个链表，然后以数组形式存储了所有的链表头）</span><br>    <span class="hljs-type">int</span> iItemSize;<span class="hljs-comment">// 数组大小</span><br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> ullStart;<span class="hljs-comment">// 记录时间</span><br>    <span class="hljs-type">long</span> <span class="hljs-type">long</span> llStartIdx;<span class="hljs-comment">// 记录时间所对应的数组中的位置</span><br>&#125;;<br></code></pre></td></tr></table></figure><ul><li>具体存储超时事件的结构体是<code>stTimeoutItem_t</code>，这是一个双向链表的节点，较为关键的是<code>void *pArg</code>，以及两个回调函数。前者其实<code>stCoRoutine_t*</code>，我们要在回调函数中恢复对应协程运行需要从这里拿到协程。</li><li>回调函数是核心，当<code>co_eventloop</code>拿到已触发的事件了后续该做的事（一般就是恢复对应协程运行）都定义在回调函数中。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stTimeoutItem_t</span><br>&#123;<br><br>    <span class="hljs-keyword">enum</span><br>    &#123;<br>        eMaxTimeout = <span class="hljs-number">40</span> * <span class="hljs-number">1000</span> <span class="hljs-comment">//40s</span><br>    &#125;;<br>    stTimeoutItem_t *pPrev;<br>    stTimeoutItem_t *pNext;<br>    stTimeoutItemLink_t *pLink;<br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> ullExpireTime;<br><br>    OnPreparePfn_t pfnPrepare;<span class="hljs-comment">// 预处理回调函数，在epoll_loop中被调用，只有epoll_wait触发的事件会调用这个回调函数，超时和同步事件都不会调用</span><br>    OnProcessPfn_t pfnProcess;<span class="hljs-comment">// 正式的回调函数，在epoll_loop中被调用</span><br><br>    <span class="hljs-type">void</span> *pArg; <span class="hljs-comment">// routine 指向协程实体</span><br>    <span class="hljs-type">bool</span> bTimeout;<br>&#125;;<br></code></pre></td></tr></table></figure><ul><li>提一下<code>TakeAllTimeout</code>函数，其实就是更新<code>stTimeout_t</code>中的时间记录，然后把已经超时的<code>stTimeoutItem_t</code>取出来。另外将其添加到<code>pstTimeoutList</code>中，等待后面统一处理。</li><li>还有注册超时事件的<code>AddTimeout</code>函数，就是把<code>stTimeoutItem_t</code>添加到 到期时间 对应的链表中。</li></ul><h3 id="3-5-3-Poll事件"><a href="#3-5-3-Poll事件" class="headerlink" title="3.5.3 Poll事件"></a>3.5.3 <code>Poll</code>事件</h3><ul><li><code>libco</code>对网络编程需要用到的接口都做了相应的<code>hook</code>，关键接口主要有三类：<code>read, write, poll</code>，读写都是对一个<code>socket fd</code>的操作，所以一个事件对应一个协程，用<code>stPollItem_t</code>表示：</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stPollItem_t</span> : <span class="hljs-keyword">public</span> stTimeoutItem_t<br>&#123;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">pollfd</span> *pSelf;<br>    stPoll_t *pPoll;<br><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">epoll_event</span> stEvent;<br>&#125;;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stPoll_t</span> : <span class="hljs-keyword">public</span> stTimeoutItem_t <br>&#123;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">pollfd</span> *fds;<br>    <span class="hljs-type">nfds_t</span> nfds; <span class="hljs-comment">// typedef unsigned long int nfds_t;</span><br>    stPollItem_t *pPollItems;<br>    <span class="hljs-type">int</span> iAllEventDetach;<br>    <span class="hljs-type">int</span> iEpollFd;<br>    <span class="hljs-type">int</span> iRaiseCnt;<br>&#125;;<br></code></pre></td></tr></table></figure><ul><li>因为网络事件往往是存在超时时间的，网络事件一般是丢到<code>epoll</code>中内核自己维护，但是超时机制需要我们自己来管理。所以网络事件必须同时也是超时事件，被丢到<code>stTimeout_t</code>中管理。所以<code>stPollItem_t</code>是继承实现的，一些别的变量是处理<code>poll</code>到<code>epoll</code>转换的。（小纠正：其实<code>stPollItem_t</code>是不会被当作超时任务丢到<code>stTimeout_t</code>中的，真正丢进去的是<code>stPoll_t</code>，但这里依然选择继承的原因是能用上回调函数等变量）</li><li>还存在一种接口是对<code>poll</code>的处理，这个接口是需要同时等待多个网络事件，但是这多个网络事件和在一起等待一个超时事件。所以用了<code>stPoll_t</code>存储这一组<code>stPollItem_t</code>（数组<code>pPollItems[nfds]</code>），同时本身又继承<code>stTimeoutItem_t</code>，于是可以被当作是一个超时事件丢到<code>stTimeout_t</code>中管理。</li><li><code>poll</code>还有一个特点是，当任意一个事件触发之后，同一批等待的所有事件都应该退出，这一点和<code>epoll</code>的实现是不同的。而<code>stPollItem_t</code>中注册的<code>pfnPrepare</code>预处理函数就是解决这个问题的，当一个<code>stPollItem_t</code>事件到达之后，需要将注册的<code>stPoll_t</code>超时任务删除。</li><li>关于网络事件的注册，<code>libco</code>库的实现方案是统一使用<code>hook</code>后的<code>poll</code>函数完成注册。这样可以尽量做到用户代码的无侵入性。所有读写接口的<code>hook</code>内部也是先调用<code>poll</code>等到事件到达之后开始真正执行。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">co_poll_inner</span><span class="hljs-params">( stCoEpoll_t *ctx,<span class="hljs-keyword">struct</span> pollfd fds[], <span class="hljs-type">nfds_t</span> nfds, <span class="hljs-type">int</span> timeout, <span class="hljs-type">poll_pfn_t</span> pollfunc)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-comment">//1.struct change</span><br>    stPoll_t&amp; arg = *((stPoll_t*)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(stPoll_t)));<br>    <br>    <span class="hljs-comment">//2. add epoll</span><br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">nfds_t</span> i=<span class="hljs-number">0</span>;i&lt;nfds;i++)<br>    &#123;<br>        <span class="hljs-type">int</span> ret = <span class="hljs-built_in">co_epoll_ctl</span>( epfd,EPOLL_CTL_ADD, fds[i].fd, &amp;ev );<br>    &#125;<br><br>    <span class="hljs-comment">//3.add timeout</span><br>    <span class="hljs-type">int</span> ret = <span class="hljs-built_in">AddTimeout</span>( ctx-&gt;pTimeout,&amp;arg,now );<br>    <span class="hljs-type">int</span> iRaiseCnt = <span class="hljs-number">0</span>;<br>    <br>    <span class="hljs-built_in">co_yield_env</span>( <span class="hljs-built_in">co_get_curr_thread_env</span>() );<br><br>    <span class="hljs-comment">//4.clear epoll status and memory</span><br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">nfds_t</span> i = <span class="hljs-number">0</span>;i &lt; nfds;i++)<br>    &#123;<br>        <span class="hljs-type">int</span> fd = fds[i].fd;<br>        <span class="hljs-built_in">co_epoll_ctl</span>( epfd,EPOLL_CTL_DEL,fd,&amp;arg.pPollItems[i].stEvent );<br>    &#125;<br>    <span class="hljs-keyword">return</span> iRaiseCnt;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li><code>poll</code>函数内部核心是<code>co_poll_inner</code>，其完成三个主要步骤：<ul><li>首先创建<code>stPoll_t</code>对象，并填充对应参数；</li><li>然后把入参的<code>fds</code>依次添加到<code>epoll</code>中；</li><li>接着根据超时时间，将<code>stPoll_t</code>添加到超时事件中，并让出CPU等待事件触发之后回来；</li><li>最后在等到事件到达恢复运行之后，需要将这些<code>fds</code>从<code>epoll</code>中删除，本质上是为了契合<code>poll</code>接口的定义。</li></ul></li></ul><h3 id="3-5-4-Cond事件"><a href="#3-5-4-Cond事件" class="headerlink" title="3.5.4 Cond事件"></a>3.5.4 <code>Cond</code>事件</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stCoCondItem_t</span> <br>&#123;<br>    stCoCondItem_t *pPrev;<br>    stCoCondItem_t *pNext;<br>    stCoCond_t *pLink;<br><br>    stTimeoutItem_t timeout;<br>&#125;;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">stCoCond_t</span><br>&#123;<br>    stCoCondItem_t *head;<br>    stCoCondItem_t *tail;<br>&#125;;<br></code></pre></td></tr></table></figure><ul><li>其实实现很简单，对同一个条件变量<code>stCoCond_t</code>的等待<code>co_cond_timedwait</code>会创建一个<code>stCoCondItem_t</code>并插入到等待链表中。可以注意到这里<code>stTimeoutItem_t</code>是作为成员变量出现的，而不是和之前的<code>stPollItem_t</code>保持一致采用继承的方法。显然同步事件是后来添加的新功能😆</li><li><code>co_cond_signal</code>或者<code>co_cond_broadcast</code>触发等待条件变量的协程，就是把<code>stTimeoutItem_t</code>取出来，并添加到<code>pstActiveList</code>当中，注意这里是用的尾插法<code>AddTail</code>，所以在本轮<code>co_eventloop</code>调度中是可以被调度运行到的。（但我不明白为啥不就地恢复运行，而一定要让<code>co_eventloop</code>去调度。或许是有公平性问题，先来的事件应该先运行？）</li></ul>]]></content>
    
    
    <categories>
      
      <category>插件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>协程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RocksDB:事务管理</title>
    <link href="/2024/05/12/RocksDB-%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86/"/>
    <url>/2024/05/12/RocksDB-%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="一、隔离性（Isolation）"><a href="#一、隔离性（Isolation）" class="headerlink" title="一、隔离性（Isolation）"></a>一、隔离性（Isolation）</h1><h2 id="1-1-隔离所导致的问题"><a href="#1-1-隔离所导致的问题" class="headerlink" title="1.1 隔离所导致的问题"></a>1.1 隔离所导致的问题</h2><p><strong>脏读</strong></p><ul><li>读取到了没有提交的数据，如果之前的事务回滚了，就读到了脏数据</li><li>注意这里的重点是：读取到了<strong>没有提交</strong>的事务的数据</li></ul><p><strong>不可重复读</strong></p><ul><li>一个事务对同一共享数据读取了两次，发现前后两次的数据不一致</li><li>不可重复读主要是针对<code>update</code>操作的描述，即表中的字段值发生了改变</li></ul><p><strong>幻读</strong></p><ul><li>一个事务内读取到了别的事务插入的数据，导致前后读取不一致</li><li>幻读主要用于描述的<code>insert</code> <code>delete</code>这样的操作所造成的影响，即前后两次查询获得的数据量不同</li></ul><h2 id="1-2-事务的隔离级别"><a href="#1-2-事务的隔离级别" class="headerlink" title="1.2 事务的隔离级别"></a>1.2 事务的隔离级别</h2><ul><li>不同的事务隔离级别可以在不同程度上解决在并发执行事务时的问题</li></ul><table><thead><tr><th>隔离级别</th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>未提交读</td><td>✔️</td><td>✔️</td><td>✔️</td></tr><tr><td>提交读</td><td>❌</td><td>✔️</td><td>✔️</td></tr><tr><td>可重复读</td><td>❌</td><td>❌</td><td>✔️</td></tr><tr><td>可串行化</td><td>❌</td><td>❌</td><td>❌</td></tr></tbody></table><h1 id="二、事务实现的基本框架"><a href="#二、事务实现的基本框架" class="headerlink" title="二、事务实现的基本框架"></a>二、事务实现的基本框架</h1><h2 id="2-1-MVCC"><a href="#2-1-MVCC" class="headerlink" title="2.1 MVCC"></a>2.1 MVCC</h2><h3 id="2-1-1-传统并发方案"><a href="#2-1-1-传统并发方案" class="headerlink" title="2.1.1 传统并发方案"></a>2.1.1 传统并发方案</h3><ul><li>以前没有使用多版本控制的时候，在同一个事务中的读取操作是需要加读锁的，而不同的隔离级别就包含着不同的上锁和释放锁策略：<ul><li>未提交读，我们只需要对事务中当前的读写操作进行加锁，单条操作完成之后立刻释放对应的锁；</li><li>提交读，我需要在此基础上对写操作加的写锁进行保留，直到事务完成时进行释放，从而保证了事务中间的修改状态不会被别的事务读取到；</li><li>可重复读，我们就需要延长读锁的释放时间了直到事务结束了，这样可以保证同一个事务的多次读取中间不会出现别的事务修改数据；</li><li>解决幻读问题需要更进一步的间隙锁的支持，本质来说是加大了锁的范围。</li></ul></li></ul><h3 id="2-1-2-MVCC的优势"><a href="#2-1-2-MVCC的优势" class="headerlink" title="2.1.2 MVCC的优势"></a>2.1.2 MVCC的优势</h3><ul><li>需要注意上面讲的加锁策略是对读事务和写事务都适用的，读操作依然需要进行加锁，而MVCC解决的问题就是对于只有读操作的事务可以不再需要加锁。</li><li>MVCC带来了一个非常重要的性质，就是版本快照。通过这项技术的支持我们可以在事务中进行读取操作的时候，设定一个版本号，那么一切的读取操作都是基于这个版本号进行读取的。因此在前面章节所讨论的隔离级别所带来的三种问题其实就都不存在了，一个快照版本所包含的内容永远是不变的。</li><li>但是MVCC其实仅仅解决了读事务的问题，对于写事务（往往既包含读操作又包含写操作）依然是需要进行加锁操作的，而且和传统的加锁模式是相同的。</li></ul><h3 id="2-1-3-MVCC下的并发"><a href="#2-1-3-MVCC下的并发" class="headerlink" title="2.1.3 MVCC下的并发"></a>2.1.3 MVCC下的并发</h3><ul><li>但是MySQL为了更好的性能做了一些实现上的调整，使得用户可以根据需要来进行加锁的操作。首先在MySQL的事务中，所有的普通select操作都是基于版本快照的无锁读操作，当一个事务中的第一条普通select开始时会获取到一个快照，之后当前事务内的所有普通查询都会基于这个快照返回查询结果。如果这期间发生rollback，快照将会清零。</li><li>但是一条insert、delete、update操作的语句是不能在快照的基础上完成的，必须在最新版本的基础上去完成增删改的操作，因此这部分的操作依然会存在加锁。</li><li>我们重新回到前文中提到的三种并发下的问题：脏读、不可重复读、幻读，其描述都是说在一个事务中的两次读操作产生了不同的结果（我们已知这在MVCC下不可能）。但是数据库的很多写入数据是需要基于原来的状态进行变更的，比如经典的银行转账问题。需要先读出数据库中的余额，减去一定金额，再将结果写回数据库。这个过程其实是需要我们保证在写入的时候原数据中的那个金额和我们先前读出的金额保持一致的。而这才是真正内涵的需要两次读操作结果相同，这个例子对应的是可重复读这个隔离级别。</li><li>这样的写事务流程需要根据原数据库中的一些基本状态来完成修改，insert、delete、update是必须在最新版本上进行操作的。但其实，读出的原始状态也是应该保证为最新版本的，为了区分普通的select操作，MySQL提供了两种查询中上锁的机制：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span><span class="hljs-operator">*</span><span class="hljs-operator">*</span> <span class="hljs-keyword">for</span> <span class="hljs-keyword">update</span>;<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span><span class="hljs-operator">*</span><span class="hljs-operator">*</span> lock <span class="hljs-keyword">in</span> share mode;<br></code></pre></td></tr></table></figure><ul><li>前者适用于要对读出的行进行修改，例如转账的事务，因此会加互斥锁。</li><li>后者适用于读这一段数据，但是是用这个结果修改别的地方，因此是加共享锁。</li></ul><h3 id="2-1-4-MVCC的隔离级别"><a href="#2-1-4-MVCC的隔离级别" class="headerlink" title="2.1.4 MVCC的隔离级别"></a>2.1.4 MVCC的隔离级别</h3><ul><li>在多版本机制的支持下，可以轻松的避免脏读、不可重复读、幻读这些问题，但我们的隔离级别是对数据的返回结果存在明确规定的，不能在任何隔离级别下都对读事务采用最高等级的隔离机制</li><li>MVCC由于其实现原理，只支持read committed和repeatable read隔离等级，在读事务下实现两种隔离机制的返回其实也很简单，（猜测是）RC下每条select都开启新的快照，RR下一个事务下的select共用一个快照</li></ul><h2 id="2-2-RocksDB的实现方法"><a href="#2-2-RocksDB的实现方法" class="headerlink" title="2.2 RocksDB的实现方法"></a>2.2 RocksDB的实现方法</h2><h3 id="2-2-1-Read-Uncommitted"><a href="#2-2-1-Read-Uncommitted" class="headerlink" title="2.2.1 Read Uncommitted"></a>2.2.1 Read Uncommitted</h3><ul><li>这个其实很简单，使用没有事务API就可以实现了，任何操作都会直接被写入到数据库中，并可以被所有别的进程查询到</li></ul><h3 id="2-2-2-Read-Committed"><a href="#2-2-2-Read-Committed" class="headerlink" title="2.2.2 Read Committed"></a>2.2.2 Read Committed</h3><ul><li>通过Rocksdb内部WriteBatch实现的，针对不同事务Rocksdb会为其分配对应的WriteBatch，由WriteBatch来处理具体的写入。</li><li>同时针对同一个事务的读操作，会优先从当前事务的WriteBatch中读，来保证能够读到当前写操作之前未提交的更新。提交的时候则依次写入WAL和memtable之中，保证ACID的原子性和一致性。</li><li>那么只要读操作全部都基于最新的版本进行读取就是RC隔离机制下的行为了。</li></ul><p><strong>WBWI(write batch with index) &amp; WB(write batch)</strong></p><ul><li>Put这样的更新接口被调用后会组织成一个WriteBatch 数据结构，将多个更新操作合并成一个请求，从而能够进行原子提交。整体是一个string-buf，将一个一个KV请求拼接进去。因此WB也就是提供了一个存放当前事务写入数据的内存块。</li><li>WBWI用于支持事务功能，其在WriteBatch 基本结构的基础上构造了一个skiplist，用来提供事务操作过程中的 read-your-write 以及 savepoint&#x2F;rollback 等这样的基本功能。</li><li>当前事务内，后续的 txn-&gt;Get 就能够有效得读到之前写入但是还没有提交的请求。</li></ul><div style="text-align:center;">    <img src="WBWI.png" alt="WBWI.png" width="550" height="224" class="jop-noMdConv"></div><ul><li><p>txn-&gt;SetSavePoint 函数会将当前 WriteBatchWithIndex 中的信息保存到一个 <code>std::stack&lt;SavePoint, autovector&lt;SavePoint&gt;&gt; stack</code>中。当前事务经过若干操作之后，后续的 txn-&gt;RollbackToSavePoint() 会进行弹栈，并将之前保存的状态信息更新到现在的WBWI 之中，从而达到事务的回滚的目的。</p></li><li><p>SetSavePoint 和 RollbackToSavePoint 函数的逻辑分别在：<code>WriteBatch::SetSavePoint()</code> ,<code>WriteBatch::RollbackToSavePoint()</code></p></li><li><p>因为WBWI 是在BeginTransaction 的时候构造的，所以每一个事务会有一个自己独立的WBWI，其内部的数据结构不需要考虑同步问题。</p></li></ul><h3 id="2-2-3-Repeatable-Read"><a href="#2-2-3-Repeatable-Read" class="headerlink" title="2.2.3 Repeatable Read"></a>2.2.3 Repeatable Read</h3><ul><li>其实在SQL指定标准之前，可重复读是用<strong>快照隔离</strong>来描述的，通用的关系型数据库都使用MVCC机制来进行多版本管理，多版本的访问也就是通过快照来进行的。</li><li>Rocksdb这里的实现是通过为每一个写入的key-value请求添加一个LSN(Log Sequence Number)，最初是0，每次写入+1，达到全局递增的目的。同时当实现快照隔离时，通过Snapshot设置其与一个LSN绑定，则该snapshot能够访问到小于等于当前LSN的KV数据，而大于该LSN的KV是不可见的。</li><li>注意如果只是普通的Get接口，则是根据我们设定的snapshot或者内部自动产生的snapshot来进行查询；但是要是用GetForUpdate这样的接口，我们是需要根据当前的最新状态来执行修改的，这时返回的是最新版本的值，并且会对查询的KV在后台进行加锁。</li></ul><p><strong>SetSnapshot</strong></p><ul><li>Rocksdb对于加锁的时机是在需要读写某个key之前才加锁，这样的方式可以满足绝大多数的事务隔离场景，当然在有些极端场景下，用户希望在事务一开始就对所有接下来需要读写key加锁，直到事务结束后再释放。这个该如何实现呢？并且无法在事务一开始就知道接下来要读写哪些key，所以无法提前对它们加锁。</li><li>Rocksdb通过SetSnapshot来间接解决，BeginTransaction后，用户可以立刻调用SetSnapshot，这样该事务会记录当前DB的最新Sequence，然后再接下来事务的每一次Put操作时，会检查DB中该key的最新Sequence是否大于事务之前记录的Sequence，如果大于，则证明事务外部有对该key做了写操作，那么事务对应的Put则会返回失败。</li><li>这里查询该key的最新版本是从version系统中取一个local_version ，直接暴力遍历这个version 中的 mem&#x2F;imm,imm-list&#x2F;sst ，拿到当前冲突key 一个最新的seq即可。（这里感觉会要较大的性能开销，因为可能涉及到磁盘IO，当然在RocksDB的内部，会去判断一下我们在事务开始设置的snapshot的LSN是否依然完全在内存中，如果还没有被刷到SST中，那我们在查询时就会只查到imm为止）</li><li>因此Rocksdb采用相对乐观的处理方式，通过对Snapshot来取代提前对所有需要的key加锁，不过这样的处理方式可能会造成事务最终失败（事务外部修改某个key后会导致接下来事务内部修改失败）。</li></ul><h2 id="2-3-SnapShot"><a href="#2-3-SnapShot" class="headerlink" title="2.3 SnapShot"></a>2.3 SnapShot</h2><ul><li>snapshot可以有多个，它的创建和删除是通过操作一个全局的双向链表来进行，天然得根据创建的时间来进行排序SetSnapShot()函数创建一个快照。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SnapshotImpl</span> : <span class="hljs-keyword">public</span> Snapshot &#123;<br> <span class="hljs-keyword">public</span>:<br>  <span class="hljs-comment">//lsn number</span><br>  SequenceNumber number_;  <br>  ......<br>  SnapshotImpl* prev_;<br>  SnapshotImpl* next_;<br>  SnapshotList* list_;                 <span class="hljs-comment">// 链表头指针</span><br>  <span class="hljs-type">int64_t</span> unix_time_; <span class="hljs-comment">//时间戳</span><br>  <span class="hljs-comment">// 用于写冲突的检查</span><br>  <span class="hljs-type">bool</span> is_write_conflict_boundary_;<br>&#125;;<br></code></pre></td></tr></table></figure><ul><li>当前系统中存在的快照会影响compaction时，是否保留某些之前版本的KV，这个后面补充</li></ul><h2 id="2-4-PessimisticTransaction"><a href="#2-4-PessimisticTransaction" class="headerlink" title="2.4 PessimisticTransaction"></a>2.4 PessimisticTransaction</h2><ul><li>使用 TransactionDB 进行事务操作，默认是 PessimisticTransactionDB，每次事务更新操作都会进行加锁，会去检测是否和其他事务有冲突。即 txn1 更新一个key1时会对当前key加锁，事务txn2 在 txn1 提交前尝试更新这个key1 则会失败。</li><li>事务对Key的加锁逻辑是：<code>PessimisticTransaction::TryLock --&gt; PessimisticTransactionDB::TryLock --&gt; PointLockManager::TryLock</code></li><li>比较老的版本 ，最后key 的加锁过程入口是 <code>TransactionLockMgr::TryLock</code>，这里重构成了 <code>LockManager::TryLock</code>，然后两种锁实现了<code>LockManager</code>接口，第三节详细介绍。死锁检测的机制也在第三节介绍。</li></ul><h2 id="2-5-OptimisticTransaction"><a href="#2-5-OptimisticTransaction" class="headerlink" title="2.5 OptimisticTransaction"></a>2.5 OptimisticTransaction</h2><ul><li><p>在乐观事务下，不同事务之间的冲突检测不会在每次更新操作时候进行检测，而是在事务提交的时候进行。</p></li><li><p>在PessimisticTransaction下检测的方法其实就是加锁，而采用OptimisticTransaction的方案是在我们提交的时候进行检测，所以我们需要把事务过程中所有需要加的锁都记录下来。对于一般的点锁，那就是记录key值，如果是范围锁就是记录加锁的范围。</p></li><li><p>需要注意虽然OptimisticTransaction不需要在执行过程中加锁，但是我们应该把他当作是普通的事物流程，其Put、GetForUpdate这些函数内部依然是有TryLock函数的，只是TryLock内部行为变成了将要更新的 key的信息添加到 <code>LockTracker</code> 中。</p></li></ul><p><strong>总结</strong></p><ul><li>悲观事务 和 乐观事务主要就是冲突检测的位置不同，所以悲观事务 在事务冲突概率较高的场景下能够保证提前发现冲突而更早的触发冲突事务的回滚。在冲突概率不高的情况下，悲观事务每一个更新（Put,Delete,Merge,GetForUpdate）都会做冲突检测，会引入较多的竞争开销，从而降低性能，所以冲突概率不高的场景可以尝试乐观事务DB。</li></ul><h1 id="三、锁"><a href="#三、锁" class="headerlink" title="三、锁"></a>三、锁</h1><ul><li>RocksDB中共支持两种锁，分别是点锁<code>PointLockManager</code>和范围锁<code>RangeTreeLockManager</code>。点锁是原生支持的，可以在项目中找到完整的项目代码；范围锁是直接使用了TokuDB中的KV存储引擎<a href="https://github.com/percona/PerconaFT">PerconaFT</a>中的范围锁实现，进行接口封装之后进行使用的</li><li>两者都继承自<code>LockManager</code>，其为C++的虚类，提供了一个通用的锁管理接口，用于在多线程&#x2F;多进程环境下管理对数据的并发访问</li><li>需要注意，范围锁也是能够提供点锁能力的，并且当我选择提供范围锁能力的时候必须选择使用<code>RangeTreeLockManager</code>，两种锁同时使用是不能保证互斥的</li></ul><h2 id="3-1-PointLock"><a href="#3-1-PointLock" class="headerlink" title="3.1 PointLock"></a>3.1 PointLock</h2><ul><li>在以前的实现版本中，因为只支持<code>PointLock</code>，这里不是通过继承<code>LockManager</code>实现的，而是使用<code>TransactionLockMgr</code>完成加锁的操作</li><li>但是后来因为支持了<code>RangeLock</code>，不得已将这里设计成接口的方式，方便两种锁都可以使用，点锁的实现类为<code>PointLockManager</code></li></ul><h3 id="3-1-1-条件变量"><a href="#3-1-1-条件变量" class="headerlink" title="3.1.1 条件变量"></a>3.1.1 条件变量</h3><ul><li>这里需要先提一个问题，多个线程在竞争同一个互斥资源的时候是使用互斥锁来实现互斥访问的，同时<code>Mutex</code>其实顺带完成了排队的工作，当一个线程释放锁时会自然触发一个在该锁上等待的线程恢复运行</li><li>但是如果现在这个互斥的资源更加复杂，不能使用一个简单的互斥锁来实现互斥访问和排队的操作，并且在某些情况需要我们需要唤醒在这个资源上阻塞的线程，那么应该使用什么实现呢？</li><li>这时需要使用条件变量来完成同步操作，<code>C++</code>中提供了两种接口，分别是<code>std::condition_variable</code>和<code>pthread_cond_t</code>，目前查到的区别是<code>pthread_cond_t</code>需要我们在<code>wait</code>之前手动加锁，而<code>std::condition_variable</code>在<code>wait</code>接口中自动完成加锁操作（个人感觉<code>std::condition_variable</code>是对<code>pthread_cond_t</code>的封装，本质上是相同的功能实现）</li><li>在条件变量的帮助下，我们可以让线程对某一个条件进行等待，并形成等待队列，从而可以在未来满足条件的时候唤醒之前等待的线程</li></ul><h3 id="3-1-2-整体结构"><a href="#3-1-2-整体结构" class="headerlink" title="3.1.2 整体结构"></a>3.1.2 整体结构</h3><div style="text-align:center;">    <img src="LockMaps.png" alt="LockMaps.png" width="509" height="240" class="jop-noMdConv"></div><ul><li>整体结构从实现类<code>PointLockManager</code>开始，这里包含了最关键的成员对象<code>LockMaps</code>（其实是<code>UnorderedMap&lt;uint32_t, std::shared_ptr&lt;LockMap&gt;&gt;</code>），每次需要进行加锁时，我们通过<code>ColumnFamilyId</code>查找对应列簇下的<code>LockMap</code>（这里有使用线程私有存储进行优化，在别的章节解释了）</li><li>然后<code>LockMap</code>内部是<code>LockMapStripe</code>的数组，这其实可以认为是哈希桶，每当我们需要对一个<code>key</code>进行加锁时，是通过哈希函数将<code>key</code>映射到其中一个<code>桶(LockMapStripe)</code>中，然后对这个桶进行加锁操作</li><li>注意，这里并不是说对每个桶进行加锁之后，就完成对这个<code>key</code>的上锁操作了，这样是有可能造成某些<code>key</code>同时被锁上而造成意外的死锁的。同时这样的上锁机制粒度显然是非常粗的，不利于高并发的场景</li><li>当对桶上锁完成之后，我们要做的是将上锁的key写入到<code>LockMapStripe</code>中的<code>UnorderedMap&lt;std::string, LockInfo&gt;</code>中，然后释放桶锁，这时才是完成了对某个<code>key</code>的上锁操作。下次有线程对某个key进行上锁时，需要查找<code>UnorderedMap</code>中是否已经存在这个<code>key</code>了。这样在共享<code>mutex</code>的情况下对所有未知可能的<code>key</code>都能进行上锁操作了</li><li>但是这里有一个问题，如果上锁时发现已经被上锁了，我们需要先释放桶的锁，然后等待那个key被释放，即从<code>UnorderedMap</code>中被删除。这里需要用到条件变量来进行等待，对桶中的<code>CondVar</code>进行等待，当某个桶发生释放key的操作时，需要唤醒所有等待的线程</li></ul><h2 id="3-2-RangeLock"><a href="#3-2-RangeLock" class="headerlink" title="3.2 RangeLock"></a>3.2 RangeLock</h2><ul><li>RocksDB一开始并没有支持范围锁，因此在Read Repeatable模式下并不能避免幻读的情况，后来是在直接使用了TokuDB的存储引擎<a href="https://github.com/percona/PerconaFT">PerconaFT</a>的范围锁实现</li><li>PerconaFT提供的locktree是使用二叉树的形式来组织整个锁结构的。需要注意当我们选择支持范围锁时，就不能同时使用PointLock，点锁也需要在RangeLock中完成。因为在真实的负载下点锁和范围锁显然是共存的，并且两者之间是需要实现互斥的</li></ul><h3 id="3-2-1-基本结构"><a href="#3-2-1-基本结构" class="headerlink" title="3.2.1 基本结构"></a>3.2.1 基本结构</h3><p><strong><code>treenode</code>:</strong></p><ul><li>主要包括四个关键部分：<ul><li><code>mutex</code>，并发操作二叉树时保证正确性</li><li><code>keyrange</code>，当前这个<code>node</code>所表示的键范围，左右都是闭区间，当左右值相等时表示<code>pointlock</code></li><li><code>m_txnid</code>和<code>m_owners</code>，表示占用当前这个锁的事务ID；当有多个事务同时持有这个范围的度锁时，<code>m_txnid</code>为一个特殊值，持有共享锁的事务ID集合在<code>m_owners</code>中</li><li><code>m_left_child</code>和<code>m_right_child</code>，构建二叉树的指针</li></ul></li></ul><p><strong><code>concurrent_tree</code>:</strong></p><ul><li>成员变量只有一个根节点<code>treenode m_root</code>，内部类<code>locked_keyrange</code>封装了实现并发访问二叉树的细节。所以<code>concurrent_tree</code>类没有太多东西</li></ul><p><strong><code>locktree</code>:</strong></p><ul><li>局部变量比较多，核心部分是：<ul><li><code>m_dict_id</code>，表示当前这个<code>locktree</code>属于哪一个字典，其实就是属于哪一个<code>ColumnFamily</code></li><li><code>m_rangetree</code>，这个就是<code>concurrent_tree</code>的指针</li><li><code>m_lock_request_info</code>，这是一个很关键的成员变量，其中保存了对当前这个<code>locktree</code>申请锁，但是没有成功的请求，和<code>request</code>的排队有重要关系</li></ul></li></ul><p><strong><code>locktree_manager</code>:</strong></p><ul><li>这个类是管理多个<code>ColumnFamily</code>的，和<code>PointLockManager</code>其实是相同的设计，内部使用<code>Order Maintenance Tree (OMT)</code>管理多个<code>locktree</code></li><li>此外RocksDB在外面还包了一层<code>RangeTreeLockManager</code>，并且在这里实现了和<code>PointLockManager</code>相同的线程局部优化</li></ul><p><strong><code>lt_lock_request_info</code>:</strong></p><ul><li>前面已经提到了核心是保存请求锁暂时失败的<code>request</code>，除此之外当有锁发生释放的时候还需要基于这个结构体唤醒<code>request</code>来重试加锁，因此主要包括三个部分：<ul><li><code>omt&lt;lock_request *&gt; pending_lock_requests</code>，对所有暂时失败请求的缓存</li><li><code>toku_external_mutex_t mutex</code>，操作当前这个结构体的内容需要加锁保证正确性</li><li><code>toku_mutex_t retry_mutex</code>和<code>toku_cond_t retry_cv</code>，管理重试加锁操作的锁和条件变量，当多个锁发生释放时，每次锁的释放都会触发剩余等待request进行重试，但是同一时间只能有一个线程在遍历<code>pending_lock_requests</code>进行重试，所以这里需要进行精细的控制</li></ul></li></ul><p><strong><code>locked_keyrange</code>:</strong></p><ul><li>这个类是定义在<code>concurrent_tree</code>内部的，用来在并发状态下完成查找、插入、删除节点的工作</li><li>并发控制的方式其实比较简单，和<code>B+tree</code>在并发控制时使用的加锁解锁策略是相同的，就是交错释放二叉树链条上的两把锁</li><li>需要注意这里提到的加锁是指在并发访问二叉树的节点时的控制手段，和<code>rangelock</code>是没有关系的，范围锁的实现其实是每一个存储在二叉树中的节点，只要某个节点存在就表示对该范围加锁</li><li>内部总共有三个成员变量：<ul><li><code>concurrent_tree *m_tree</code></li><li><code>keyrange m_range</code>，期望锁住的键范围，需要注意这个值来源于进行加锁操作的<code>locked_keyrange::acquire</code>函数的传入参数，即这个是用户希望加锁的范围</li><li><code>treenode *m_subtree</code>，在查找流程结束时（即经过<code>prepare</code>和<code>acquire</code>两个函数），这个变量存储的是最深的存在范围覆盖的节点；如果没有范围覆盖的节点，会一直往下查找到一个<code>nullptr</code>的指针，这时存的是持有这个<code>nullptr</code>指针的节点（很重要的一点，<code>locked_keyrange</code>这时只持有<code>m_subtree</code>节点的锁）</li></ul></li><li>二叉树还是一个平衡的树，在各种操作中间穿插着各种调整树结构平衡的操作，这部分不是重点没有细看</li></ul><p><strong><code>lock_request</code>:</strong></p><ul><li>真正实现向<code>rangelock</code>加锁的类，较为核心的成员变量为：<ul><li><code>m_left_key</code>和<code>m_right_key</code>，范围的左右边界</li><li><code>locktree *m_lt</code>，实施加锁的二叉树，就是<code>ColumnFamily</code>对应的<code>locktree</code></li><li><code>lt_lock_request_info *m_info</code>，对应<code>locktree</code>内部的，本质来说不用重新存一份，可以通过前面的<code>m_lt</code>访问到</li><li><code>toku_external_cond_t m_wait_cond</code>，这个条件变量比较关键，当无法完成加锁而需要进行等待时，是在这个条件变量上进行等待。同时前面有提到过，当一个<code>rangelock</code>释放之后会遍历<code>requests</code>进行重试加锁，如果重试成功时需要唤醒这个条件变量</li></ul></li></ul><h3 id="3-2-2-代码逻辑"><a href="#3-2-2-代码逻辑" class="headerlink" title="3.2.2 代码逻辑"></a>3.2.2 代码逻辑</h3><p><strong>加锁 <code>RangeTreeLockManager::TryLock</code></strong></p><ul><li>首先创建<code>request</code>，并设置初始值</li><li>接着是调用<code>request.start()</code>，这一步是进行加锁的关键步骤，会尝试在<code>locktree</code>中添加新节点来完成加锁<ul><li>这里会有比较多的调用栈，最后是进入到<code>locktree::acquire_lock</code>，然后创建一个<code>locked_keyrange lkr</code>并调用<code>prepare</code>方法获得根节点的锁</li><li>然后将<code>lkr</code>传入<code>acquire_lock_consolidated</code>函数，通过<code>acquire</code>方法查找目标子树（这个方法的细节在上一小节有提到）</li><li>找到目标子树之后，通过<code>iterate_and_get_overlapping_row_locks()</code>去收集与申请加锁范围存在<code>overlap</code>的节点，注意这里在写锁和读锁的操作上发生了分歧。如果是要加写锁，不可能会存在可以共享的节点；如果是加读锁，有一种情况可以简单完成加锁操作，即当我们找到一个节点的范围和请求的range完全相匹配，并且已经持有的是读锁时，我们可以简单的将当前请求的<code>txnid</code>添加到那个节点中就算完成加锁了。（存在任何差别都不能以这样共享的方式完成加锁操作，所以真正能实现共享锁的情况很少）</li><li>上面收集到存在<code>overlap</code>的节点之后，通过<code>determine_conflicting_txnids()</code>检查存在冲突的节点，其实就是检查这些已经被上锁的节点是否本来就是被当前这个事务所持有的，如果全部<code>overlap</code>节点都是的话需要我们将这些范围进行合并，算是一个小优化减少<code>locktree</code>的规模</li><li>如果是存在加锁冲突的，这时会把当前<code>request</code>的状态设置为<code>DB_LOCK_NOTGRANTED</code>，表示存在互斥需要等待</li><li>然后退回到<code>request.start()</code>，如果当前<code>request</code>的状态为<code>DB_LOCK_NOTGRANTED</code>需要我们将其<strong>添加到<code>lt_lock_request_info</code>中</strong></li></ul></li><li>然后是调用<code>request.wait()</code>，这里是当上一步进行加锁发现存在冲突而失败时，通过<code>request.m_wait_cond</code>来完成等待操作；如果上一步成功加锁了，这个函数会快速经过<ul><li>进入函数之后先对<code>m_info-&gt;mutex</code>加锁，然后会有一次重新进行加锁的尝试，如果加锁成功了就可以不用去等待条件变量了，并且直接成功返回（这里的<code>retry</code>非常重要，单独开小节讲）</li><li>然后就是进入一个<code>while</code>循环中，等待<code>request</code>中的条件变量，等待超时唤醒，或者被别的线程唤醒</li></ul></li></ul><p><strong>为什么在<code>request.wait()</code>需要<code>retry</code></strong></p><ul><li>我们想象一个情况，现在A线程已经对<code>range[1,2]</code>加锁，B线程对相同的范围加锁时必然会冲突，然后将<code>request</code>添加到<code>lt_lock_request_info</code>中，并且开始等待条件变量。</li><li>但是如果在B线程加锁失败和将<code>request</code>添加到<code>lt_lock_request_info</code>的期间，A线程释放了<code>range[1,2]</code>。从后面的释放锁流程我们知道，每次调用<code>UnLock</code>的最后一步是<code>retry</code>所有等待的<code>request</code>。那么A并不会帮助B的<code>request</code>成功申请到锁了，此时这个<code>request</code>还不存在于<code>lt_lock_request_info</code>中，但是B会依然开始等待条件变量，并且不会再有线程能够唤醒这个条件变量，B只能等待超时唤醒</li><li>解决的方法就是重试，我们需要注意代码中关于<code>m_info</code>的操作都需要在<code>m_info-&gt;mutex</code>的锁定下执行。B将<code>request</code>添加到<code>lt_lock_request_info</code>需要加锁，在<code>request.wait</code>中，每次先获得<code>m_info-&gt;mutex</code>之后，进行一次<code>retry</code>，然后再等待条件变量，条件变量的<code>wait</code>语句会释放持有的<code>m_info-&gt;mutex</code>。同样A在<code>UnLock</code>的最后一步<code>retry</code>所有等待的<code>request</code>时，也需要先获得<code>m_info-&gt;mutex</code></li><li>那么A如果是在B将<code>request</code>添加到<code>lt_lock_request_info</code>之前先retry了所有的，B的<code>retry</code>会成功完成加锁；如果A的retry在B的之后，那么A需要等待B等待条件变量，并且释放<code>m_info-&gt;mutex</code>之后，再执行<code>retry_all_lock_requests_info</code>，这时会正常唤醒B</li></ul><p><strong>解锁 <code>RangeTreeLockManager::UnLock</code></strong></p><ul><li>有两种支持方式，一种是直接提告诉要解锁哪一个键范围，这种方式比较符合<code>locktree</code>的实现，可以直接调用对应的接口；还有一种在数据库中比较常用，即当一个事务完成时，我们直接释放和这个事务相关的所有锁，这种和<code>locktree</code>的设计是不匹配的，需要我们单独去保存事物加的所有锁，然后一次性释放，RocksDB实现了一个<code>LockTracker</code>去支持这种功能</li><li>首先是从<code>locktree</code>中释放锁的函数<code>locktree::release_locks</code>，其实就是将所有当初加锁插入的节点全部删除掉，所以只需要保证二叉树的并发控制就可以了。需要注意我们在加锁阶段有个优化是将存在<code>overlap</code>但是不冲突的节点进行合并，但是我们记录的加锁范围还是最初没有合并的样子。</li><li>所以最后在删除节点的时候我们可能发现某些节点的边界是不能和记录值完全对应的，这里代码的处理是只要存在<code>overlap</code>就直接删除这个节点。这会带来两个问题：1. 有的节点删除会发现当前范围的节点不存在；2. 我们将后加锁的某些范围释放之后，前面的一些加锁范围可能就自然释放了，因此我们在使用锁的时候必须遵守事务进行加锁的规范，不能中途释放锁</li><li>然后是重试当前等待的<code>request</code>的函数<code>lock_request::retry_all_lock_requests</code>，首先每一次执行全部重试都是非常繁琐的过程，需要对<code>lt_lock_request_info</code>中的每一个请求都进行重试看看能不能加锁成功，并且只有加锁成功之后才对<code>request</code>中的条件变量进行唤醒。重试意味着查询整个二叉树，是需要不断进行加锁和释放锁操作的，性能会较大程度被影响。</li><li>每一次释放某个事务的锁都会触发整体的重试操作，为了减少重试带来的性能影响，有一个简单的机制来保证，和<code>retry_cv</code>与<code>retry_mutex</code>相关。大概功能就是当目前有很多<code>retry</code>在排队时，我执行一次重试就可以了，因为释放的锁都已经反映到<code>locktree</code>上了，执行一次全部的重试就包含到了所有情况</li><li>然后就是依次重试所有<code>request</code>了，那些成功加锁的会被通过条件变量唤醒，注意一点在<code>PointLock</code>中当发生释放锁操作时是唤醒所有的等待线程自己去竞争重试加锁，而在<code>RangeLock</code>的实现中是通过释放锁的线程去重试的，这是否会较大影响事务的执行尾延迟呢？</li></ul><h3 id="3-2-3-STO优化"><a href="#3-2-3-STO优化" class="headerlink" title="3.2.3 STO优化"></a>3.2.3 STO优化</h3><ul><li>这是对范围锁的一个优化，大概思路是说当目前只有一个事务在申请锁，并不存在多个事务在竞争时，我们直接通过一个缓存保留所有的加锁操作，而不将加锁添加到<code>locktree</code>中。</li><li>当释放锁的时候直接释放缓存即可，大大减少锁处理的时间。但是这只对不存在多事务并行发生的条件下使用</li></ul><h2 id="3-3-Tracker"><a href="#3-3-Tracker" class="headerlink" title="3.3 Tracker"></a>3.3 Tracker</h2><div style="text-align:center;">    <img src="tracker.png" alt="tracker.png" width="678" height="229" class="jop-noMdConv"></div><ul><li>上图是LockTracker中用于管理跟踪的加锁信息的局部变量<code>TrackedKeys tracked_keys_</code>的结构示意图，其实就是两层HashMap，第一层是通过ColumnFamilyData索引，第二层通过key索引，最后找到<code>TrackedKeyInfo</code>，其包含加锁的key的各种信息（这里其实只说了PointLock下的Tracker，在RangeLock下是会不一样的）</li><li>在commit时，冲突检测的主要函数入口是 OptimisticTransaction::CheckTransactionForConflicts()，它会进一步调用 TransactionUtil::CheckKeysForConflicts() 执行冲突检测</li><li>要检测的其实就是每个 Key 在 db 中有没有比当前事务开始的 sequence 号之后更新的写入存在。最笨的办法就是把每个 Key 读一次 db，获得它最近的 sequence 号，与事务的 sequence 号做比较。如果 db 中的 sequence 号更大，事务冲突了。</li><li>简单优化一下就只需要判断近期的数据就可以了，而最近期的数据就是 MemTable，所以做近期的冲突检测，只需要读 MemTable 的数据就足够了，不需要执行 IO。不过事务的开始时间如果比 MemTable 中最老的 Key 还早，就无法判断了，这时 rocksdb 的处理也比较暴力，就直接说这个事务过期了，需要重试。</li><li>在检测的实现上RocksDB是通过<code>WriteWithCallback</code>在写入WriteBatch时通过调用OptimisticTransactionCallback实现，所有的检查逻辑都在回掉函数里面，提供了两种 OCC (optimistic concurrent control)策略: <code>kValidateParallel</code> 和 <code>kValidateSerial</code><ul><li><code>OptimisticTransaction::CommitWithSerialValidate</code>正常进行检查，但是比较慢</li><li><code>OptimisticTransaction::CommitWithParallelValidate</code>后来的优化</li></ul></li><li>Tracker机制也会影响到compaction，当我们需要将delete操作和原有KV数据进行合并时，要考虑将曾经出现过的KV直接删除是否会影响到现有Tracker的信息校验。</li></ul><h2 id="3-4-Deadlock"><a href="#3-4-Deadlock" class="headerlink" title="3.4 Deadlock"></a>3.4 Deadlock</h2><ul><li>采用PessimisticTransaction方式执行事务时，加锁顺序完全是由用户来决定的，因此存在很大的可能出现死锁问题。RocksDB通过记录事务间的等待关系来判定是否存在环，从而判定是否有死锁存在</li><li>死锁检测的核心是想要在一个 <strong>有向无环图</strong> 中检测有没有wait_circle，rocksdb的死锁检测就是拿着当前事务前面尝试获取锁时得到的一个<strong>wait_ids 数组</strong>和已有的wait-circle来构建一个 有向无环图，在这个有向无环图中按照前面用户配置的depth进行wait-circle的检测。</li><li>死锁检测入口是在<code>PointLockManager::IncrementWaiters</code>里面，通过前面对当前 txn 构造好的<code>wait_ids</code>数组构造 <code>wait_txn_map_</code> 和 <code>rev_wait_txn_map_</code> 两个 HashMap。<ul><li><code>HashMap&lt;TransactionID, int&gt; rev_wait_txn_map_</code> 用来保存活跃事务和该事务在被多少个事务所等待</li><li><code>HashMap&lt;TransactionID, TrackedTrxInfo&gt; wait_txn_map_</code> 用来保存整个活跃事务视图，用于广度优先遍历。保存的内容是 当前事务等待哪些事务</li></ul></li><li>接下来就是经典的广度优先遍历的实现了，通过提前resize 好的两个vector queue_values 和 queue_parents ，resize的大小是前面说的 deadlock_detect_depth。 queue_values 保存层序，即每一层的所有节点；queue_parents 用来记录当前层的父节点的下标，方便后面在发现死锁环之后进行死锁路径的回溯。</li><li>结束的条件是：<ul><li>在 deadlock_detect_depth 这个检测深度下如果没有发现 当前事务id 和 已有活跃事务依赖图 中不会有相等的情况，则认为不会死锁，返回未发现死锁。</li><li>如果发现有相等的，也就是在依赖图 下找到了环的存在，则通过 queue_parents 数组来回溯当前事务在依赖图中的依赖路径，保存到 dlock_buffer_ 中，同时将该事务信息从事务依赖图中踢出 DecrementWaitersImpl，也就是将当前txn的<code>wait_ids</code>逆着走一遍初始化的过程，返回发现死锁。</li></ul></li><li>注意一点，就是一个事务是有可能同时等待多个事务的，这个主要出现在使用RangeLock的情况，一个范围锁可能涵盖多个锁，那当然就要等待多个事务了。</li></ul><h1 id="四、两阶段提交（Two-Phase-Commit）"><a href="#四、两阶段提交（Two-Phase-Commit）" class="headerlink" title="四、两阶段提交（Two Phase Commit）"></a>四、两阶段提交（Two Phase Commit）</h1>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RocksDB</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RocksDB:线程私有化</title>
    <link href="/2024/05/12/RocksDB-%E7%BA%BF%E7%A8%8B%E7%A7%81%E6%9C%89%E5%8C%96/"/>
    <url>/2024/05/12/RocksDB-%E7%BA%BF%E7%A8%8B%E7%A7%81%E6%9C%89%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<ul><li>在RocksDB的<code>PointLockManager</code>中有使用到，是系统层面的优化点</li></ul><h1 id="一、线程资源"><a href="#一、线程资源" class="headerlink" title="一、线程资源"></a>一、线程资源</h1><ul><li>这一小节是实现各种系统设计中通过线程私有化实现性能优化的基础</li><li>是由编译器和标准库提供的线程资源的支持，有线程特定数据（Thread Specific Data）和线程局部存储 (Thread Local Storage)两种</li></ul><h2 id="1-1-TLS"><a href="#1-1-TLS" class="headerlink" title="1.1 TLS"></a>1.1 TLS</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-keyword">thread_local</span> var_1 = <span class="hljs-number">0</span>;<br></code></pre></td></tr></table></figure><ul><li>通过<code>thread_local</code>标识符修饰的全局或静态变量是线程独立的，线程对该变量的操作对其它线程来说是不可见的</li></ul><h3 id="线程栈"><a href="#线程栈" class="headerlink" title="线程栈"></a>线程栈</h3><ul><li>在Linux中，并没有真正的线程，而是通过多个进程共享资源的方式实现的。但每个线程自己的线程栈是私有的，通过分配的方式将进程的某一块内存分配给线程使用</li><li>拿到分配的栈空间之后，先将最前面的一段空间初始化为<code>pthread</code>对象，然后就是<code>__thread</code>变量区。代码中所有的 <code>__thread</code>变量是与<code>pthread</code>关联存储的，通过相对于<code>pthread</code>变量地址的偏移实现对变量的寻址</li></ul><h2 id="1-2-TSD"><a href="#1-2-TSD" class="headerlink" title="1.2 TSD"></a>1.2 TSD</h2><ul><li>通过<code>pthread_key_create</code>创建键值映射，每个线程通过键访问线程特定的数据</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 首先声明一个全局的Key</span><br><span class="hljs-type">static</span> <span class="hljs-type">pthread_key_t</span> heap_key_;<br><span class="hljs-comment">// 并且通过接口完成初始化，定义一个序号值（seq）及一个用于释放数据的“析构函数” （destr）</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">pthread_key_create</span> <span class="hljs-params">(<span class="hljs-type">pthread_key_t</span> *key, <span class="hljs-type">void</span> (*destructor)(<span class="hljs-type">void</span> *))</span></span>;<br><span class="hljs-comment">// 线程内通过接口设置某个key对应的值</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">pthread_setspecific</span> <span class="hljs-params">(<span class="hljs-type">pthread_key_t</span> key, <span class="hljs-type">const</span> <span class="hljs-type">void</span> *value)</span></span>;<br><span class="hljs-comment">// 线程内通过接口获取某个key对应的值</span><br><span class="hljs-function"><span class="hljs-type">void</span> *<span class="hljs-title">pthread_getspecific</span> <span class="hljs-params">(<span class="hljs-type">pthread_key_t</span> key)</span></span>;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">pthread_key_delete</span> <span class="hljs-params">(<span class="hljs-type">pthread_key_t</span> key)</span></span>;<br></code></pre></td></tr></table></figure><ul><li>通过TSD可以在每个线程内访问自己私有的变量，同时这些变量在不同的线程中是具有相同的变量名的，即我们在全局声明的<code>pthread_key_t</code>变量</li></ul><h1 id="二、TCMalloc"><a href="#二、TCMalloc" class="headerlink" title="二、TCMalloc"></a>二、TCMalloc</h1><ul><li><code>Golang</code>在设计时借鉴了<code>TCMalloc</code>（线程缓存分配）的设计，实现高速的内存分配</li><li>它的核心理念是使用多级缓存将对象根据大小分类，并按照类别实施不同的分配策略</li></ul><h2 id="2-1-隐式链表分配"><a href="#2-1-隐式链表分配" class="headerlink" title="2.1 隐式链表分配"></a>2.1 隐式链表分配</h2><ul><li>如果要对一整个<code>Page</code>的内存按照相同的单位进行分配，有非常的方法实现，比如可以使用<code>bitmap</code>的方式，如果对4KB的页按照16byte进行分配，只需要4KB &#x2F; 16 &#x2F; 8 &#x3D; 32byte的<code>bitmap</code></li><li>但是出于最大化内存利用率的目的，使用的是另一种经典的方式<code>freelist</code>。因为我们要分配的对象就是内存本身，在构成链表时可以将链表指针放到对象中进行存储，从而不需要额外的内存来存储管理信息了</li></ul><h2 id="2-2-内存对齐的规则"><a href="#2-2-内存对齐的规则" class="headerlink" title="2.2 内存对齐的规则"></a>2.2 内存对齐的规则</h2><ul><li>首先说明，TCMalloc的代码似乎存在多种宏定义可以改变内存的对齐规则，所有下面写的数据不一定是完全不变的</li><li>一共划分了四个档位：<code>(256KB, +∞)</code>按照8KB进行对齐；<code>[128B, 256KB]</code>按照$(1&lt;&lt;LgFloor(size))&#x2F;8$来对齐，$LgFloor$其实就是取size二进制最高位1的位置；<code>(16B, 128B)</code>按照16B进行对其；<code>(0, 16B)</code>按照8B进行对其。</li><li>通过这样设定的对齐方式，对于分配内存小于等于256KB的情况，我们可以将所有的内存size划分穷举出来，被设计成数组方便我们可以直接访问到对应的规则下</li></ul><h2 id="2-3-整体框架"><a href="#2-3-整体框架" class="headerlink" title="2.3 整体框架"></a>2.3 整体框架</h2><ul><li>TCMalloc的整体分配框架分成了<code>Thread Cache</code>, <code>Central List</code>, <code>Page Heap</code>三级</li><li>用户直接向每个线程私有的<code>Thread Cache</code>获取内存块，其基本结构是一个包含所有内存分配单位的数组，每个单元包含这个单位大小的空闲数据块链表，从这里分配内存可以避免多线程的竞争</li><li>如果线程私有的空闲块没有了，需要向全局的<code>Central List</code>申请，每个可能的单位分配大小都有一个<code>Central List</code>实例。每个实例内部是<code>SpanList</code>，存储着用于划分小内存块的<code>span</code>，每个<code>span</code>包含的<code>page</code>数量是不同的，但是同一个<code>Central List</code>下的<code>span</code> size肯定相同</li><li>如果还是没有足够的空间，需要向 <code>Page Heap</code>申请内存块了，内部是一个128长度的数组，用于表示size为1～128个<code>page</code>的<code>span</code>。用多种定长<code>page</code>来实现变长<code>page</code>的分配，初始时只有 128 <code>page</code> 的 <code>span</code>，如果要分配 1 个 <code>page</code> 的 <code>span</code>，就把这个 <code>span</code> 分裂成两个，1 + 127，把127再记录下来。对于 <code>span</code> 的回收，需要考虑<code>span</code>的合并问题，否则在分配回收多次之后，就只剩下很小的 <code>span</code> 了，也就是带来了<strong>外部碎片</strong>问题。</li></ul><h2 id="2-4-分配策略"><a href="#2-4-分配策略" class="headerlink" title="2.4 分配策略"></a>2.4 分配策略</h2><ul><li>每次分配时，从用户申请的对象的size开始，一路发生空间不够向上请求新空间，到最后真正向操作系统申请的内存size是由一些提前设定好的参数决定的</li><li>首先，用户申请的内存size会被进行对齐处理，这里是通过前面说的方法进行对齐的，但是我们还应该得出这是哪一个内存size下的，及得到<code>Index</code>，这是通过<code>ClassIndex(size)</code>实现的</li><li>然后，通过<code>Index</code>访问<code>class_to_size_</code>得到实际该给用户返回多大的内存</li><li>接着，通过<code>Index</code>访问<code>num_objects_to_move_</code>查每次给对应<code>thread_cache</code>分配多少个object，这里有预先多给一部分同样大小的内存块给线程的意思</li><li>最后，通过<code>Index</code>访问<code>class_to_pages_</code>查每次给不同<code>central_freelist</code>分包含多少个页的<code>span</code></li><li>超过256KB的大内存的分配会绕过其他结构直接访问<code>Page Heap</code>，并且单独管理</li></ul><h2 id="2-5-线程私有"><a href="#2-5-线程私有" class="headerlink" title="2.5 线程私有"></a>2.5 线程私有</h2><ul><li>在<code>TCMalloc</code>的三层结构中，<code>Thread Cache</code>这一层为了避免多线程的竞争从而带来的性能影响，选择了使用线程私有的方式实现</li><li>代码中使用了TSD的方式，为每个线程在需要通过<code>TCMalloc</code>申请内存时，构建一个线程私有的<code>Thread Cache</code>，实现内存分配上的线程私有话，避免了线程之间的竞争</li><li>但是因为TSD方式对局部变量的访问需要通过<code>pthread_getspecific()</code>，速度比较慢，因此<code>Thread Cache</code>中还有<code>__thread</code>变量存储每个线程对象的副本</li><li>但是因为需要注册清理函数，所以必须要TSD的方式创建线程局部变量</li></ul><h1 id="三、ThreadLocalPtr"><a href="#三、ThreadLocalPtr" class="headerlink" title="三、ThreadLocalPtr"></a>三、ThreadLocalPtr</h1><ul><li>RocksDB对线程私有存储的封装</li><li>实现线程私有的方法也非常简单，就是使用<code>pthread_key_t</code>，但是这样的实现方式较为原生，对于每一个需要私有化的变量都需要我们声明并创建。并且当我们不能事先知道需要多少私有变量个数时，会更加不方便</li><li>可以在全局就用一个<code>pthread_key_t</code>，这样所有线程都能知道它并通过它来访问自己的私有存储，然后在这个私有存储上做文章，让它支持维护多个变量就可以了</li></ul><h2 id="3-1-使用方法"><a href="#3-1-使用方法" class="headerlink" title="3.1 使用方法"></a>3.1 使用方法</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 1.首先定义线程退出时的回掉函数，用于释放存储的局部对象</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">UnrefHandle</span><span class="hljs-params">(<span class="hljs-type">void</span> *ptr)</span> </span>&#123;<br>  <span class="hljs-comment">//当线程退出的时候会回调UnrefHandle来释放该线程的私有存储，ptr指向该私有存储地址</span><br>  <span class="hljs-comment">//所以这里需要定义这块私有存储该如何释放，比如最简单的:</span><br>  <span class="hljs-keyword">delete</span> <span class="hljs-built_in">static_cast</span>&lt;Object&gt;(ptr);<br>&#125;<br><br><span class="hljs-comment">// 2.创建一个私有的存储变量，对应着pthread_key_create</span><br>ThreadLocalPtr *local_1 = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ThreadLocalPtr</span>(&amp;UnrefHandle);<br><br><span class="hljs-comment">// 3.设置本线程对应的该私有存储变量的值，对应pthread_setspecific</span><br>Object *ptr_1 = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Object</span>();<br><span class="hljs-type">void</span> *old_ptr_1 = local_1-&gt;<span class="hljs-built_in">Swap</span>(ptr_1);<br><span class="hljs-comment">// 或者使用reset，其实和swap是一样的，差别在是否返回原来位置上的值</span><br>local_1-&gt;<span class="hljs-built_in">Reset</span>(ptr_1);<br><br><span class="hljs-comment">// 4.读取本线程对应的私有存储变量的值，对应pthread_getspecific</span><br><span class="hljs-type">void</span> *cur_ptr_1 = local_l-&gt;<span class="hljs-built_in">Get</span>();<br></code></pre></td></tr></table></figure><h2 id="3-2-实现过程"><a href="#3-2-实现过程" class="headerlink" title="3.2 实现过程"></a>3.2 实现过程</h2><ul><li><p>首先所有真正被存放在<code>ThreadLocalPtr</code>中的都是指针，而不是数据本身，并且都是被转换成<code>void*</code>类型被包装在<code>Entry</code>对象中的，不用的线程只要能够获取到不同的指针就能访问到私有的内存了</p></li><li><p>然后是<code>ThreadData</code>包含<code>std::vector&lt;Entry&gt;</code>，这里其实存放了用户的多个私有内存的指针，因此只要我们能够实现每个线程都单独具有一个<code>ThreadData</code>对象，然后将每个线程需要私有化的内容放到<code>ThreadData</code>的数组中就可以了</p></li><li><p>接着是最重要的<code>StaticMeta</code>，其在整个程序中只存在一份，是单例模式。其内部包含了<code>static thread_local ThreadData* tls_;</code>和<code>pthread_key_t pthread_key_;</code>两个变量，都是存储的<code>ThreadData</code>指针，其中TLS方式是为了加速访问存储的副本</p></li><li><p>最后<code>ThreadLocalPtr</code>对象只存储了一个<code>ID</code>值，这是用于访问在<code>ThreadData</code>中保存的私有变量时，用于索引<code>std::vector&lt;Entry&gt;</code>的，其实就是通过下标的方式标明是哪一个变量。因为数组的长度不能无限的增长，因此<code>ID</code>其实是会进行回收使用的</p></li><li><p>关于对象的释放操作，目前存在两个维度的对象释放：</p><ol><li>当某个线程结束之后，其下管理的所有私有对象都应该被释放。这是由注册线程私有<code>ThreadData</code>时，通过<code>pthread_key_create</code>传入的回掉函数<code>OnThreadExit</code>完成。线程退出时自动调用回掉函数，会遍历<code>ThreadData</code>中的数组，并对每一个变量调用它的释放函数</li><li>当我们主动删除某一个线程私有变量时（也就是删除某个<code>ThreadLocalPtr</code>对象），我们需要将所有线程下的该私有对象都进行释放处理。这里是通过<code>ThreadData</code>自己构成的双向链表，找出所有线程下的变量进行释放</li></ol></li></ul><h1 id="四、线程私有优化案例"><a href="#四、线程私有优化案例" class="headerlink" title="四、线程私有优化案例"></a>四、线程私有优化案例</h1><h2 id="4-1-PointLockManager优化"><a href="#4-1-PointLockManager优化" class="headerlink" title="4.1 PointLockManager优化"></a>4.1 PointLockManager优化</h2><ul><li><p>在RocksDB的点锁实现<code>PointLockManager</code>中，不同<code>ColumnFamily</code>拥有不同的<code>LockMap</code>，而所有的<code>LockMap</code>是被集中存储在一个<code>LockMaps</code>下的</p></li><li><p>因此当我们需要对某个<code>ColumnFamily</code>下的Key加锁时，需要先将整个<code>PointLockManager</code>锁起来，然后从<code>LockMaps</code>中取出对应<code>ColumnFamily</code>的<code>LockMap</code>，然后再执行后续的操作</p></li><li><p>这里为了获得<code>ColumnFamily</code>对应的<code>LockMap</code>需要对整个<code>PointLockManager</code>对象进行加锁显然会造成较大的竞争。因此这里采用了线程优化的方式，在每个线程中都准备了一个<code>LockMaps</code>，并且把当前线程需要用到的<code>ColumnFamily</code>的<code>LockMap</code>放入其中</p></li><li><p>在线程私有化<code>LockMaps</code>之后，进行加锁时只需要访问线程本地的<code>LockMaps</code>，并查询<code>ColumnFamily</code>对应的<code>LockMap</code>，不需要加整个<code>PointLockManager</code>对象中的大锁</p></li><li><p>当然也有可能出现当前线程本地的<code>LockMaps</code>中不存在某个<code>ColumnFamily</code>的<code>LockMap</code>的问题，这个时候就需要加大锁从全局的<code>LockMaps</code>中查询结果，并添加到本地的<code>LockMaps</code>中</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RocksDB</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
